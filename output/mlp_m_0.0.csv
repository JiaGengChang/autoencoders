#params: learningRate 0.010, momentum 0.000, numIterations 100000, printEvery 1000, printFirst 2000
iteration 0, loss 0.47508399
iteration 1, loss 0.48000536
iteration 2, loss 0.48469416
iteration 3, loss 0.48935209
iteration 4, loss 0.49381022
iteration 5, loss 0.49814124
iteration 6, loss 0.50234209
iteration 7, loss 0.50652071
iteration 8, loss 0.51049221
iteration 9, loss 0.51434655
iteration 10, loss 0.51801576
iteration 11, loss 0.52163286
iteration 12, loss 0.52518861
iteration 13, loss 0.52855701
iteration 14, loss 0.53183311
iteration 15, loss 0.53501790
iteration 16, loss 0.53807082
iteration 17, loss 0.54097513
iteration 18, loss 0.54388410
iteration 19, loss 0.54665171
iteration 20, loss 0.54933605
iteration 21, loss 0.55192545
iteration 22, loss 0.55445746
iteration 23, loss 0.55688929
iteration 24, loss 0.55918222
iteration 25, loss 0.56144159
iteration 26, loss 0.56364743
iteration 27, loss 0.56572415
iteration 28, loss 0.56775892
iteration 29, loss 0.56973209
iteration 30, loss 0.57163459
iteration 31, loss 0.57349455
iteration 32, loss 0.57529062
iteration 33, loss 0.57699123
iteration 34, loss 0.57865268
iteration 35, loss 0.58024291
iteration 36, loss 0.58179848
iteration 37, loss 0.58329194
iteration 38, loss 0.58472953
iteration 39, loss 0.58613159
iteration 40, loss 0.58750193
iteration 41, loss 0.58881136
iteration 42, loss 0.59007177
iteration 43, loss 0.59130176
iteration 44, loss 0.59248481
iteration 45, loss 0.59363354
iteration 46, loss 0.59474882
iteration 47, loss 0.59583343
iteration 48, loss 0.59686149
iteration 49, loss 0.59788489
iteration 50, loss 0.59886889
iteration 51, loss 0.59982845
iteration 52, loss 0.60073350
iteration 53, loss 0.60160456
iteration 54, loss 0.60247915
iteration 55, loss 0.60330329
iteration 56, loss 0.60411822
iteration 57, loss 0.60490301
iteration 58, loss 0.60566501
iteration 59, loss 0.60640553
iteration 60, loss 0.60711663
iteration 61, loss 0.60781859
iteration 62, loss 0.60848721
iteration 63, loss 0.60913716
iteration 64, loss 0.60976438
iteration 65, loss 0.61038312
iteration 66, loss 0.61097806
iteration 67, loss 0.61155913
iteration 68, loss 0.61211936
iteration 69, loss 0.61265986
iteration 70, loss 0.61319948
iteration 71, loss 0.61371460
iteration 72, loss 0.61420934
iteration 73, loss 0.61469763
iteration 74, loss 0.61517200
iteration 75, loss 0.61562524
iteration 76, loss 0.61606963
iteration 77, loss 0.61650024
iteration 78, loss 0.61692963
iteration 79, loss 0.61733467
iteration 80, loss 0.61773514
iteration 81, loss 0.61811810
iteration 82, loss 0.61849541
iteration 83, loss 0.61885739
iteration 84, loss 0.61921387
iteration 85, loss 0.61955924
iteration 86, loss 0.61989628
iteration 87, loss 0.62022687
iteration 88, loss 0.62054278
iteration 89, loss 0.62085420
iteration 90, loss 0.62115570
iteration 91, loss 0.62145001
iteration 92, loss 0.62173268
iteration 93, loss 0.62201221
iteration 94, loss 0.62228255
iteration 95, loss 0.62254662
iteration 96, loss 0.62280586
iteration 97, loss 0.62305793
iteration 98, loss 0.62329934
iteration 99, loss 0.62353341
iteration 100, loss 0.62376346
iteration 101, loss 0.62398979
iteration 102, loss 0.62420599
iteration 103, loss 0.62441766
iteration 104, loss 0.62463209
iteration 105, loss 0.62483456
iteration 106, loss 0.62503434
iteration 107, loss 0.62522453
iteration 108, loss 0.62540590
iteration 109, loss 0.62558916
iteration 110, loss 0.62576694
iteration 111, loss 0.62594100
iteration 112, loss 0.62611541
iteration 113, loss 0.62627838
iteration 114, loss 0.62643897
iteration 115, loss 0.62659780
iteration 116, loss 0.62674901
iteration 117, loss 0.62689722
iteration 118, loss 0.62704091
iteration 119, loss 0.62718298
iteration 120, loss 0.62732015
iteration 121, loss 0.62745451
iteration 122, loss 0.62758749
iteration 123, loss 0.62771560
iteration 124, loss 0.62784143
iteration 125, loss 0.62796434
iteration 126, loss 0.62808151
iteration 127, loss 0.62819710
iteration 128, loss 0.62830957
iteration 129, loss 0.62842023
iteration 130, loss 0.62852734
iteration 131, loss 0.62863364
iteration 132, loss 0.62873530
iteration 133, loss 0.62883390
iteration 134, loss 0.62893223
iteration 135, loss 0.62902966
iteration 136, loss 0.62912216
iteration 137, loss 0.62921100
iteration 138, loss 0.62930082
iteration 139, loss 0.62938887
iteration 140, loss 0.62947195
iteration 141, loss 0.62955434
iteration 142, loss 0.62963369
iteration 143, loss 0.62971291
iteration 144, loss 0.62978810
iteration 145, loss 0.62986297
iteration 146, loss 0.62993580
iteration 147, loss 0.63000593
iteration 148, loss 0.63007526
iteration 149, loss 0.63014223
iteration 150, loss 0.63020975
iteration 151, loss 0.63027301
iteration 152, loss 0.63033831
iteration 153, loss 0.63039767
iteration 154, loss 0.63045939
iteration 155, loss 0.63051798
iteration 156, loss 0.63057257
iteration 157, loss 0.63062931
iteration 158, loss 0.63068545
iteration 159, loss 0.63073929
iteration 160, loss 0.63078864
iteration 161, loss 0.63083565
iteration 162, loss 0.63088872
iteration 163, loss 0.63093517
iteration 164, loss 0.63098179
iteration 165, loss 0.63103070
iteration 166, loss 0.63107355
iteration 167, loss 0.63111972
iteration 168, loss 0.63116067
iteration 169, loss 0.63120309
iteration 170, loss 0.63124285
iteration 171, loss 0.63128273
iteration 172, loss 0.63132104
iteration 173, loss 0.63136121
iteration 174, loss 0.63139654
iteration 175, loss 0.63143089
iteration 176, loss 0.63147075
iteration 177, loss 0.63150322
iteration 178, loss 0.63153759
iteration 179, loss 0.63157008
iteration 180, loss 0.63160040
iteration 181, loss 0.63163346
iteration 182, loss 0.63166374
iteration 183, loss 0.63169272
iteration 184, loss 0.63172082
iteration 185, loss 0.63175297
iteration 186, loss 0.63177923
iteration 187, loss 0.63180544
iteration 188, loss 0.63183348
iteration 189, loss 0.63186103
iteration 190, loss 0.63188368
iteration 191, loss 0.63190738
iteration 192, loss 0.63193502
iteration 193, loss 0.63195428
iteration 194, loss 0.63197765
iteration 195, loss 0.63200082
iteration 196, loss 0.63202089
iteration 197, loss 0.63204458
iteration 198, loss 0.63206598
iteration 199, loss 0.63208500
iteration 200, loss 0.63210302
iteration 201, loss 0.63212369
iteration 202, loss 0.63214358
iteration 203, loss 0.63216175
iteration 204, loss 0.63218027
iteration 205, loss 0.63219816
iteration 206, loss 0.63221526
iteration 207, loss 0.63222974
iteration 208, loss 0.63224847
iteration 209, loss 0.63226402
iteration 210, loss 0.63228004
iteration 211, loss 0.63229235
iteration 212, loss 0.63230882
iteration 213, loss 0.63232431
iteration 214, loss 0.63233642
iteration 215, loss 0.63235222
iteration 216, loss 0.63236514
iteration 217, loss 0.63237843
iteration 218, loss 0.63239055
iteration 219, loss 0.63240290
iteration 220, loss 0.63241611
iteration 221, loss 0.63242489
iteration 222, loss 0.63243974
iteration 223, loss 0.63244843
iteration 224, loss 0.63245795
iteration 225, loss 0.63247185
iteration 226, loss 0.63248133
iteration 227, loss 0.63249046
iteration 228, loss 0.63250137
iteration 229, loss 0.63251220
iteration 230, loss 0.63251767
iteration 231, loss 0.63252818
iteration 232, loss 0.63253892
iteration 233, loss 0.63254745
iteration 234, loss 0.63255561
iteration 235, loss 0.63256485
iteration 236, loss 0.63257274
iteration 237, loss 0.63258113
iteration 238, loss 0.63258886
iteration 239, loss 0.63259858
iteration 240, loss 0.63260060
iteration 241, loss 0.63261064
iteration 242, loss 0.63261830
iteration 243, loss 0.63262420
iteration 244, loss 0.63263201
iteration 245, loss 0.63263687
iteration 246, loss 0.63264239
iteration 247, loss 0.63264973
iteration 248, loss 0.63265212
iteration 249, loss 0.63265804
iteration 250, loss 0.63266393
iteration 251, loss 0.63266919
iteration 252, loss 0.63267684
iteration 253, loss 0.63268209
iteration 254, loss 0.63268531
iteration 255, loss 0.63268881
iteration 256, loss 0.63269531
iteration 257, loss 0.63270087
iteration 258, loss 0.63270427
iteration 259, loss 0.63270994
iteration 260, loss 0.63271327
iteration 261, loss 0.63271643
iteration 262, loss 0.63272197
iteration 263, loss 0.63272450
iteration 264, loss 0.63272913
iteration 265, loss 0.63273122
iteration 266, loss 0.63273439
iteration 267, loss 0.63274039
iteration 268, loss 0.63274376
iteration 269, loss 0.63274779
iteration 270, loss 0.63274974
iteration 271, loss 0.63275089
iteration 272, loss 0.63275596
iteration 273, loss 0.63275918
iteration 274, loss 0.63276181
iteration 275, loss 0.63276521
iteration 276, loss 0.63276722
iteration 277, loss 0.63276352
iteration 278, loss 0.63276955
iteration 279, loss 0.63277015
iteration 280, loss 0.63277300
iteration 281, loss 0.63277936
iteration 282, loss 0.63277915
iteration 283, loss 0.63278171
iteration 284, loss 0.63277939
iteration 285, loss 0.63278067
iteration 286, loss 0.63278475
iteration 287, loss 0.63278723
iteration 288, loss 0.63279046
iteration 289, loss 0.63279397
iteration 290, loss 0.63279383
iteration 291, loss 0.63279359
iteration 292, loss 0.63279611
iteration 293, loss 0.63279860
iteration 294, loss 0.63279751
iteration 295, loss 0.63280121
iteration 296, loss 0.63280262
iteration 297, loss 0.63280336
iteration 298, loss 0.63280225
iteration 299, loss 0.63280502
iteration 300, loss 0.63280698
iteration 301, loss 0.63280527
iteration 302, loss 0.63280751
iteration 303, loss 0.63280647
iteration 304, loss 0.63280772
iteration 305, loss 0.63280841
iteration 306, loss 0.63280993
iteration 307, loss 0.63280998
iteration 308, loss 0.63281023
iteration 309, loss 0.63281046
iteration 310, loss 0.63281123
iteration 311, loss 0.63281236
iteration 312, loss 0.63280993
iteration 313, loss 0.63280849
iteration 314, loss 0.63280709
iteration 315, loss 0.63280830
iteration 316, loss 0.63281161
iteration 317, loss 0.63281151
iteration 318, loss 0.63281320
iteration 319, loss 0.63280946
iteration 320, loss 0.63281046
iteration 321, loss 0.63281122
iteration 322, loss 0.63280940
iteration 323, loss 0.63281266
iteration 324, loss 0.63281227
iteration 325, loss 0.63281003
iteration 326, loss 0.63281106
iteration 327, loss 0.63281213
iteration 328, loss 0.63281027
iteration 329, loss 0.63281293
iteration 330, loss 0.63281186
iteration 331, loss 0.63280895
iteration 332, loss 0.63280895
iteration 333, loss 0.63280678
iteration 334, loss 0.63280704
iteration 335, loss 0.63280720
iteration 336, loss 0.63280727
iteration 337, loss 0.63280624
iteration 338, loss 0.63280567
iteration 339, loss 0.63280462
iteration 340, loss 0.63280418
iteration 341, loss 0.63280472
iteration 342, loss 0.63280392
iteration 343, loss 0.63280503
iteration 344, loss 0.63280440
iteration 345, loss 0.63280228
iteration 346, loss 0.63280251
iteration 347, loss 0.63280031
iteration 348, loss 0.63280065
iteration 349, loss 0.63279784
iteration 350, loss 0.63279907
iteration 351, loss 0.63279800
iteration 352, loss 0.63279738
iteration 353, loss 0.63279884
iteration 354, loss 0.63279768
iteration 355, loss 0.63279616
iteration 356, loss 0.63279525
iteration 357, loss 0.63279050
iteration 358, loss 0.63279168
iteration 359, loss 0.63279198
iteration 360, loss 0.63279012
iteration 361, loss 0.63278784
iteration 362, loss 0.63278796
iteration 363, loss 0.63278596
iteration 364, loss 0.63278525
iteration 365, loss 0.63278544
iteration 366, loss 0.63278395
iteration 367, loss 0.63278243
iteration 368, loss 0.63278022
iteration 369, loss 0.63278057
iteration 370, loss 0.63278022
iteration 371, loss 0.63277791
iteration 372, loss 0.63277674
iteration 373, loss 0.63277513
iteration 374, loss 0.63277220
iteration 375, loss 0.63276878
iteration 376, loss 0.63277063
iteration 377, loss 0.63277009
iteration 378, loss 0.63276845
iteration 379, loss 0.63276583
iteration 380, loss 0.63276555
iteration 381, loss 0.63276347
iteration 382, loss 0.63276252
iteration 383, loss 0.63276121
iteration 384, loss 0.63276022
iteration 385, loss 0.63275933
iteration 386, loss 0.63275455
iteration 387, loss 0.63275418
iteration 388, loss 0.63275282
iteration 389, loss 0.63275212
iteration 390, loss 0.63275083
iteration 391, loss 0.63274992
iteration 392, loss 0.63274736
iteration 393, loss 0.63274640
iteration 394, loss 0.63274548
iteration 395, loss 0.63274435
iteration 396, loss 0.63274254
iteration 397, loss 0.63274125
iteration 398, loss 0.63273718
iteration 399, loss 0.63273363
iteration 400, loss 0.63273521
iteration 401, loss 0.63273395
iteration 402, loss 0.63273055
iteration 403, loss 0.63273354
iteration 404, loss 0.63273002
iteration 405, loss 0.63272609
iteration 406, loss 0.63272227
iteration 407, loss 0.63272139
iteration 408, loss 0.63272002
iteration 409, loss 0.63271843
iteration 410, loss 0.63271793
iteration 411, loss 0.63271702
iteration 412, loss 0.63271601
iteration 413, loss 0.63271338
iteration 414, loss 0.63271474
iteration 415, loss 0.63270916
iteration 416, loss 0.63270760
iteration 417, loss 0.63270634
iteration 418, loss 0.63270429
iteration 419, loss 0.63270246
iteration 420, loss 0.63270157
iteration 421, loss 0.63269799
iteration 422, loss 0.63269695
iteration 423, loss 0.63269739
iteration 424, loss 0.63269499
iteration 425, loss 0.63269407
iteration 426, loss 0.63268958
iteration 427, loss 0.63268731
iteration 428, loss 0.63268624
iteration 429, loss 0.63268454
iteration 430, loss 0.63268231
iteration 431, loss 0.63267945
iteration 432, loss 0.63267681
iteration 433, loss 0.63267509
iteration 434, loss 0.63267308
iteration 435, loss 0.63267019
iteration 436, loss 0.63266778
iteration 437, loss 0.63266597
iteration 438, loss 0.63266221
iteration 439, loss 0.63266284
iteration 440, loss 0.63265948
iteration 441, loss 0.63265911
iteration 442, loss 0.63265626
iteration 443, loss 0.63265405
iteration 444, loss 0.63264981
iteration 445, loss 0.63264818
iteration 446, loss 0.63264697
iteration 447, loss 0.63264256
iteration 448, loss 0.63264033
iteration 449, loss 0.63264054
iteration 450, loss 0.63263886
iteration 451, loss 0.63263374
iteration 452, loss 0.63263139
iteration 453, loss 0.63263126
iteration 454, loss 0.63263148
iteration 455, loss 0.63262690
iteration 456, loss 0.63262463
iteration 457, loss 0.63262092
iteration 458, loss 0.63262260
iteration 459, loss 0.63261784
iteration 460, loss 0.63261568
iteration 461, loss 0.63261499
iteration 462, loss 0.63261209
iteration 463, loss 0.63260778
iteration 464, loss 0.63260611
iteration 465, loss 0.63260451
iteration 466, loss 0.63259985
iteration 467, loss 0.63259827
iteration 468, loss 0.63259636
iteration 469, loss 0.63259243
iteration 470, loss 0.63259224
iteration 471, loss 0.63259040
iteration 472, loss 0.63258820
iteration 473, loss 0.63258594
iteration 474, loss 0.63258267
iteration 475, loss 0.63257806
iteration 476, loss 0.63257453
iteration 477, loss 0.63257471
iteration 478, loss 0.63257118
iteration 479, loss 0.63256874
iteration 480, loss 0.63256512
iteration 481, loss 0.63255972
iteration 482, loss 0.63255855
iteration 483, loss 0.63255618
iteration 484, loss 0.63255319
iteration 485, loss 0.63254945
iteration 486, loss 0.63254959
iteration 487, loss 0.63254954
iteration 488, loss 0.63254712
iteration 489, loss 0.63254284
iteration 490, loss 0.63253486
iteration 491, loss 0.63253384
iteration 492, loss 0.63253245
iteration 493, loss 0.63253350
iteration 494, loss 0.63252865
iteration 495, loss 0.63252571
iteration 496, loss 0.63252161
iteration 497, loss 0.63251880
iteration 498, loss 0.63251746
iteration 499, loss 0.63251183
iteration 500, loss 0.63251053
iteration 501, loss 0.63250613
iteration 502, loss 0.63250408
iteration 503, loss 0.63250374
iteration 504, loss 0.63250070
iteration 505, loss 0.63249659
iteration 506, loss 0.63249132
iteration 507, loss 0.63248709
iteration 508, loss 0.63248669
iteration 509, loss 0.63248325
iteration 510, loss 0.63247921
iteration 511, loss 0.63247760
iteration 512, loss 0.63247373
iteration 513, loss 0.63246843
iteration 514, loss 0.63246696
iteration 515, loss 0.63246311
iteration 516, loss 0.63246020
iteration 517, loss 0.63245632
iteration 518, loss 0.63245573
iteration 519, loss 0.63245031
iteration 520, loss 0.63245161
iteration 521, loss 0.63244824
iteration 522, loss 0.63244340
iteration 523, loss 0.63244175
iteration 524, loss 0.63243975
iteration 525, loss 0.63243704
iteration 526, loss 0.63243368
iteration 527, loss 0.63242977
iteration 528, loss 0.63242262
iteration 529, loss 0.63241768
iteration 530, loss 0.63241857
iteration 531, loss 0.63241611
iteration 532, loss 0.63241307
iteration 533, loss 0.63240604
iteration 534, loss 0.63240463
iteration 535, loss 0.63240124
iteration 536, loss 0.63239531
iteration 537, loss 0.63239491
iteration 538, loss 0.63239168
iteration 539, loss 0.63238681
iteration 540, loss 0.63238429
iteration 541, loss 0.63237947
iteration 542, loss 0.63237445
iteration 543, loss 0.63237010
iteration 544, loss 0.63236670
iteration 545, loss 0.63236628
iteration 546, loss 0.63236248
iteration 547, loss 0.63235796
iteration 548, loss 0.63235575
iteration 549, loss 0.63235403
iteration 550, loss 0.63234873
iteration 551, loss 0.63234407
iteration 552, loss 0.63234351
iteration 553, loss 0.63233838
iteration 554, loss 0.63233401
iteration 555, loss 0.63232894
iteration 556, loss 0.63232713
iteration 557, loss 0.63232280
iteration 558, loss 0.63231819
iteration 559, loss 0.63231470
iteration 560, loss 0.63230709
iteration 561, loss 0.63230752
iteration 562, loss 0.63230384
iteration 563, loss 0.63229777
iteration 564, loss 0.63229704
iteration 565, loss 0.63229356
iteration 566, loss 0.63228951
iteration 567, loss 0.63228095
iteration 568, loss 0.63227918
iteration 569, loss 0.63227549
iteration 570, loss 0.63227180
iteration 571, loss 0.63226840
iteration 572, loss 0.63226443
iteration 573, loss 0.63225971
iteration 574, loss 0.63225571
iteration 575, loss 0.63225093
iteration 576, loss 0.63224798
iteration 577, loss 0.63224031
iteration 578, loss 0.63223857
iteration 579, loss 0.63223141
iteration 580, loss 0.63223148
iteration 581, loss 0.63222557
iteration 582, loss 0.63222400
iteration 583, loss 0.63222013
iteration 584, loss 0.63221488
iteration 585, loss 0.63220934
iteration 586, loss 0.63220304
iteration 587, loss 0.63220261
iteration 588, loss 0.63219899
iteration 589, loss 0.63219040
iteration 590, loss 0.63218799
iteration 591, loss 0.63218096
iteration 592, loss 0.63217763
iteration 593, loss 0.63217572
iteration 594, loss 0.63217010
iteration 595, loss 0.63216670
iteration 596, loss 0.63216084
iteration 597, loss 0.63215850
iteration 598, loss 0.63215308
iteration 599, loss 0.63214949
iteration 600, loss 0.63214166
iteration 601, loss 0.63213570
iteration 602, loss 0.63213374
iteration 603, loss 0.63213158
iteration 604, loss 0.63212391
iteration 605, loss 0.63211888
iteration 606, loss 0.63211365
iteration 607, loss 0.63211081
iteration 608, loss 0.63210533
iteration 609, loss 0.63210266
iteration 610, loss 0.63209894
iteration 611, loss 0.63209134
iteration 612, loss 0.63208403
iteration 613, loss 0.63208256
iteration 614, loss 0.63207492
iteration 615, loss 0.63207041
iteration 616, loss 0.63206688
iteration 617, loss 0.63206067
iteration 618, loss 0.63205674
iteration 619, loss 0.63204937
iteration 620, loss 0.63204766
iteration 621, loss 0.63204066
iteration 622, loss 0.63203879
iteration 623, loss 0.63202956
iteration 624, loss 0.63202539
iteration 625, loss 0.63201945
iteration 626, loss 0.63201604
iteration 627, loss 0.63201223
iteration 628, loss 0.63200615
iteration 629, loss 0.63200413
iteration 630, loss 0.63199772
iteration 631, loss 0.63198877
iteration 632, loss 0.63198228
iteration 633, loss 0.63198013
iteration 634, loss 0.63197494
iteration 635, loss 0.63197003
iteration 636, loss 0.63196157
iteration 637, loss 0.63195771
iteration 638, loss 0.63195269
iteration 639, loss 0.63194942
iteration 640, loss 0.63194177
iteration 641, loss 0.63193506
iteration 642, loss 0.63193237
iteration 643, loss 0.63192937
iteration 644, loss 0.63192080
iteration 645, loss 0.63191597
iteration 646, loss 0.63190934
iteration 647, loss 0.63190368
iteration 648, loss 0.63190096
iteration 649, loss 0.63189046
iteration 650, loss 0.63188691
iteration 651, loss 0.63188361
iteration 652, loss 0.63187777
iteration 653, loss 0.63187070
iteration 654, loss 0.63186364
iteration 655, loss 0.63185409
iteration 656, loss 0.63185150
iteration 657, loss 0.63184319
iteration 658, loss 0.63183709
iteration 659, loss 0.63183440
iteration 660, loss 0.63182923
iteration 661, loss 0.63182224
iteration 662, loss 0.63181420
iteration 663, loss 0.63180834
iteration 664, loss 0.63180074
iteration 665, loss 0.63179528
iteration 666, loss 0.63178733
iteration 667, loss 0.63178286
iteration 668, loss 0.63177950
iteration 669, loss 0.63176909
iteration 670, loss 0.63176385
iteration 671, loss 0.63175917
iteration 672, loss 0.63175495
iteration 673, loss 0.63174850
iteration 674, loss 0.63173994
iteration 675, loss 0.63173285
iteration 676, loss 0.63172717
iteration 677, loss 0.63172062
iteration 678, loss 0.63171234
iteration 679, loss 0.63170618
iteration 680, loss 0.63169836
iteration 681, loss 0.63169244
iteration 682, loss 0.63168691
iteration 683, loss 0.63168243
iteration 684, loss 0.63167666
iteration 685, loss 0.63166927
iteration 686, loss 0.63166337
iteration 687, loss 0.63165675
iteration 688, loss 0.63164896
iteration 689, loss 0.63164254
iteration 690, loss 0.63163479
iteration 691, loss 0.63162962
iteration 692, loss 0.63162171
iteration 693, loss 0.63161181
iteration 694, loss 0.63160811
iteration 695, loss 0.63159879
iteration 696, loss 0.63158790
iteration 697, loss 0.63158102
iteration 698, loss 0.63157578
iteration 699, loss 0.63157069
iteration 700, loss 0.63156474
iteration 701, loss 0.63155477
iteration 702, loss 0.63154716
iteration 703, loss 0.63153868
iteration 704, loss 0.63153163
iteration 705, loss 0.63152366
iteration 706, loss 0.63151637
iteration 707, loss 0.63151206
iteration 708, loss 0.63150531
iteration 709, loss 0.63149757
iteration 710, loss 0.63148838
iteration 711, loss 0.63148208
iteration 712, loss 0.63147683
iteration 713, loss 0.63147053
iteration 714, loss 0.63145910
iteration 715, loss 0.63145221
iteration 716, loss 0.63144490
iteration 717, loss 0.63143767
iteration 718, loss 0.63142964
iteration 719, loss 0.63142212
iteration 720, loss 0.63140879
iteration 721, loss 0.63140314
iteration 722, loss 0.63139843
iteration 723, loss 0.63139131
iteration 724, loss 0.63138218
iteration 725, loss 0.63137405
iteration 726, loss 0.63136272
iteration 727, loss 0.63135160
iteration 728, loss 0.63134587
iteration 729, loss 0.63134047
iteration 730, loss 0.63133082
iteration 731, loss 0.63132247
iteration 732, loss 0.63131833
iteration 733, loss 0.63130488
iteration 734, loss 0.63129947
iteration 735, loss 0.63129111
iteration 736, loss 0.63128486
iteration 737, loss 0.63127285
iteration 738, loss 0.63126182
iteration 739, loss 0.63125331
iteration 740, loss 0.63124755
iteration 741, loss 0.63123756
iteration 742, loss 0.63123135
iteration 743, loss 0.63122038
iteration 744, loss 0.63121179
iteration 745, loss 0.63120481
iteration 746, loss 0.63119692
iteration 747, loss 0.63118587
iteration 748, loss 0.63117696
iteration 749, loss 0.63116680
iteration 750, loss 0.63116048
iteration 751, loss 0.63115029
iteration 752, loss 0.63114022
iteration 753, loss 0.63113318
iteration 754, loss 0.63111813
iteration 755, loss 0.63111115
iteration 756, loss 0.63110356
iteration 757, loss 0.63109429
iteration 758, loss 0.63108347
iteration 759, loss 0.63107379
iteration 760, loss 0.63106769
iteration 761, loss 0.63105765
iteration 762, loss 0.63104490
iteration 763, loss 0.63103353
iteration 764, loss 0.63102433
iteration 765, loss 0.63101481
iteration 766, loss 0.63100550
iteration 767, loss 0.63099643
iteration 768, loss 0.63099189
iteration 769, loss 0.63097917
iteration 770, loss 0.63096971
iteration 771, loss 0.63095873
iteration 772, loss 0.63094536
iteration 773, loss 0.63093693
iteration 774, loss 0.63092898
iteration 775, loss 0.63092037
iteration 776, loss 0.63090855
iteration 777, loss 0.63090268
iteration 778, loss 0.63089078
iteration 779, loss 0.63087643
iteration 780, loss 0.63086598
iteration 781, loss 0.63085402
iteration 782, loss 0.63084896
iteration 783, loss 0.63083800
iteration 784, loss 0.63082708
iteration 785, loss 0.63081626
iteration 786, loss 0.63080415
iteration 787, loss 0.63079475
iteration 788, loss 0.63077977
iteration 789, loss 0.63077044
iteration 790, loss 0.63075985
iteration 791, loss 0.63074926
iteration 792, loss 0.63074068
iteration 793, loss 0.63073030
iteration 794, loss 0.63071648
iteration 795, loss 0.63070587
iteration 796, loss 0.63069579
iteration 797, loss 0.63068574
iteration 798, loss 0.63066976
iteration 799, loss 0.63066321
iteration 800, loss 0.63065258
iteration 801, loss 0.63063939
iteration 802, loss 0.63062817
iteration 803, loss 0.63061681
iteration 804, loss 0.63060382
iteration 805, loss 0.63059338
iteration 806, loss 0.63057893
iteration 807, loss 0.63056738
iteration 808, loss 0.63056228
iteration 809, loss 0.63054620
iteration 810, loss 0.63053689
iteration 811, loss 0.63052232
iteration 812, loss 0.63051188
iteration 813, loss 0.63050047
iteration 814, loss 0.63049153
iteration 815, loss 0.63047714
iteration 816, loss 0.63046640
iteration 817, loss 0.63044999
iteration 818, loss 0.63044140
iteration 819, loss 0.63042963
iteration 820, loss 0.63041298
iteration 821, loss 0.63040201
iteration 822, loss 0.63038780
iteration 823, loss 0.63038077
iteration 824, loss 0.63036808
iteration 825, loss 0.63035272
iteration 826, loss 0.63034193
iteration 827, loss 0.63032333
iteration 828, loss 0.63031485
iteration 829, loss 0.63030040
iteration 830, loss 0.63028387
iteration 831, loss 0.63027171
iteration 832, loss 0.63026146
iteration 833, loss 0.63024581
iteration 834, loss 0.63023931
iteration 835, loss 0.63021844
iteration 836, loss 0.63020869
iteration 837, loss 0.63019483
iteration 838, loss 0.63018149
iteration 839, loss 0.63016808
iteration 840, loss 0.63015016
iteration 841, loss 0.63013896
iteration 842, loss 0.63012863
iteration 843, loss 0.63011841
iteration 844, loss 0.63010005
iteration 845, loss 0.63008736
iteration 846, loss 0.63006971
iteration 847, loss 0.63005609
iteration 848, loss 0.63004004
iteration 849, loss 0.63002900
iteration 850, loss 0.63001888
iteration 851, loss 0.63000298
iteration 852, loss 0.62999218
iteration 853, loss 0.62997543
iteration 854, loss 0.62995870
iteration 855, loss 0.62994183
iteration 856, loss 0.62992404
iteration 857, loss 0.62991615
iteration 858, loss 0.62989994
iteration 859, loss 0.62988876
iteration 860, loss 0.62987430
iteration 861, loss 0.62986325
iteration 862, loss 0.62984473
iteration 863, loss 0.62982839
iteration 864, loss 0.62981264
iteration 865, loss 0.62979425
iteration 866, loss 0.62977764
iteration 867, loss 0.62976767
iteration 868, loss 0.62975304
iteration 869, loss 0.62973746
iteration 870, loss 0.62971949
iteration 871, loss 0.62970336
iteration 872, loss 0.62969485
iteration 873, loss 0.62968104
iteration 874, loss 0.62966268
iteration 875, loss 0.62964305
iteration 876, loss 0.62962442
iteration 877, loss 0.62960525
iteration 878, loss 0.62959656
iteration 879, loss 0.62957738
iteration 880, loss 0.62956063
iteration 881, loss 0.62954631
iteration 882, loss 0.62953343
iteration 883, loss 0.62951307
iteration 884, loss 0.62950046
iteration 885, loss 0.62948233
iteration 886, loss 0.62947447
iteration 887, loss 0.62945340
iteration 888, loss 0.62943049
iteration 889, loss 0.62941450
iteration 890, loss 0.62940171
iteration 891, loss 0.62938803
iteration 892, loss 0.62936887
iteration 893, loss 0.62934819
iteration 894, loss 0.62933316
iteration 895, loss 0.62932038
iteration 896, loss 0.62930474
iteration 897, loss 0.62928240
iteration 898, loss 0.62926577
iteration 899, loss 0.62924853
iteration 900, loss 0.62923027
iteration 901, loss 0.62920492
iteration 902, loss 0.62919142
iteration 903, loss 0.62917540
iteration 904, loss 0.62915679
iteration 905, loss 0.62913515
iteration 906, loss 0.62911643
iteration 907, loss 0.62909857
iteration 908, loss 0.62908050
iteration 909, loss 0.62906382
iteration 910, loss 0.62904596
iteration 911, loss 0.62903050
iteration 912, loss 0.62901007
iteration 913, loss 0.62899144
iteration 914, loss 0.62897248
iteration 915, loss 0.62895978
iteration 916, loss 0.62894140
iteration 917, loss 0.62891893
iteration 918, loss 0.62890195
iteration 919, loss 0.62887863
iteration 920, loss 0.62886557
iteration 921, loss 0.62884388
iteration 922, loss 0.62882449
iteration 923, loss 0.62880562
iteration 924, loss 0.62878472
iteration 925, loss 0.62876537
iteration 926, loss 0.62874139
iteration 927, loss 0.62872141
iteration 928, loss 0.62870040
iteration 929, loss 0.62868187
iteration 930, loss 0.62866715
iteration 931, loss 0.62864611
iteration 932, loss 0.62863104
iteration 933, loss 0.62861087
iteration 934, loss 0.62859606
iteration 935, loss 0.62856793
iteration 936, loss 0.62854642
iteration 937, loss 0.62852896
iteration 938, loss 0.62850288
iteration 939, loss 0.62848518
iteration 940, loss 0.62846799
iteration 941, loss 0.62844838
iteration 942, loss 0.62841636
iteration 943, loss 0.62840166
iteration 944, loss 0.62837936
iteration 945, loss 0.62835940
iteration 946, loss 0.62833884
iteration 947, loss 0.62831839
iteration 948, loss 0.62828918
iteration 949, loss 0.62827146
iteration 950, loss 0.62824586
iteration 951, loss 0.62822892
iteration 952, loss 0.62820918
iteration 953, loss 0.62818931
iteration 954, loss 0.62817056
iteration 955, loss 0.62814825
iteration 956, loss 0.62812630
iteration 957, loss 0.62809702
iteration 958, loss 0.62808249
iteration 959, loss 0.62805309
iteration 960, loss 0.62802873
iteration 961, loss 0.62801127
iteration 962, loss 0.62798430
iteration 963, loss 0.62796308
iteration 964, loss 0.62793999
iteration 965, loss 0.62791698
iteration 966, loss 0.62789837
iteration 967, loss 0.62787975
iteration 968, loss 0.62785154
iteration 969, loss 0.62782772
iteration 970, loss 0.62780221
iteration 971, loss 0.62777838
iteration 972, loss 0.62775690
iteration 973, loss 0.62774002
iteration 974, loss 0.62770878
iteration 975, loss 0.62767952
iteration 976, loss 0.62766090
iteration 977, loss 0.62763802
iteration 978, loss 0.62761581
iteration 979, loss 0.62758472
iteration 980, loss 0.62755765
iteration 981, loss 0.62753130
iteration 982, loss 0.62750645
iteration 983, loss 0.62749154
iteration 984, loss 0.62746549
iteration 985, loss 0.62743961
iteration 986, loss 0.62740599
iteration 987, loss 0.62738067
iteration 988, loss 0.62736306
iteration 989, loss 0.62734238
iteration 990, loss 0.62732196
iteration 991, loss 0.62728977
iteration 992, loss 0.62726440
iteration 993, loss 0.62724944
iteration 994, loss 0.62721194
iteration 995, loss 0.62718782
iteration 996, loss 0.62716167
iteration 997, loss 0.62712875
iteration 998, loss 0.62711568
iteration 999, loss 0.62707582
iteration 1000, loss 0.62705162
iteration 1001, loss 0.62702768
iteration 1002, loss 0.62699813
iteration 1003, loss 0.62698437
iteration 1004, loss 0.62695500
iteration 1005, loss 0.62692224
iteration 1006, loss 0.62689552
iteration 1007, loss 0.62686985
iteration 1008, loss 0.62684402
iteration 1009, loss 0.62681559
iteration 1010, loss 0.62678779
iteration 1011, loss 0.62675618
iteration 1012, loss 0.62673444
iteration 1013, loss 0.62670439
iteration 1014, loss 0.62667541
iteration 1015, loss 0.62664758
iteration 1016, loss 0.62661600
iteration 1017, loss 0.62659237
iteration 1018, loss 0.62656871
iteration 1019, loss 0.62653530
iteration 1020, loss 0.62650280
iteration 1021, loss 0.62647606
iteration 1022, loss 0.62643838
iteration 1023, loss 0.62642113
iteration 1024, loss 0.62639528
iteration 1025, loss 0.62635937
iteration 1026, loss 0.62632665
iteration 1027, loss 0.62630497
iteration 1028, loss 0.62627383
iteration 1029, loss 0.62624381
iteration 1030, loss 0.62621813
iteration 1031, loss 0.62619547
iteration 1032, loss 0.62616352
iteration 1033, loss 0.62611686
iteration 1034, loss 0.62609288
iteration 1035, loss 0.62605972
iteration 1036, loss 0.62603053
iteration 1037, loss 0.62600836
iteration 1038, loss 0.62597700
iteration 1039, loss 0.62594604
iteration 1040, loss 0.62591013
iteration 1041, loss 0.62587950
iteration 1042, loss 0.62585026
iteration 1043, loss 0.62581688
iteration 1044, loss 0.62578347
iteration 1045, loss 0.62575688
iteration 1046, loss 0.62573148
iteration 1047, loss 0.62569843
iteration 1048, loss 0.62566675
iteration 1049, loss 0.62563537
iteration 1050, loss 0.62560947
iteration 1051, loss 0.62556966
iteration 1052, loss 0.62552725
iteration 1053, loss 0.62549126
iteration 1054, loss 0.62547271
iteration 1055, loss 0.62544276
iteration 1056, loss 0.62539972
iteration 1057, loss 0.62537214
iteration 1058, loss 0.62533173
iteration 1059, loss 0.62530834
iteration 1060, loss 0.62526830
iteration 1061, loss 0.62524075
iteration 1062, loss 0.62521266
iteration 1063, loss 0.62517901
iteration 1064, loss 0.62513990
iteration 1065, loss 0.62511144
iteration 1066, loss 0.62507017
iteration 1067, loss 0.62504956
iteration 1068, loss 0.62500208
iteration 1069, loss 0.62497621
iteration 1070, loss 0.62493674
iteration 1071, loss 0.62490094
iteration 1072, loss 0.62486218
iteration 1073, loss 0.62482906
iteration 1074, loss 0.62478865
iteration 1075, loss 0.62476489
iteration 1076, loss 0.62472280
iteration 1077, loss 0.62468798
iteration 1078, loss 0.62466686
iteration 1079, loss 0.62461347
iteration 1080, loss 0.62457804
iteration 1081, loss 0.62454137
iteration 1082, loss 0.62449756
iteration 1083, loss 0.62446185
iteration 1084, loss 0.62442834
iteration 1085, loss 0.62440823
iteration 1086, loss 0.62437594
iteration 1087, loss 0.62432861
iteration 1088, loss 0.62428253
iteration 1089, loss 0.62425381
iteration 1090, loss 0.62423173
iteration 1091, loss 0.62419022
iteration 1092, loss 0.62415246
iteration 1093, loss 0.62410341
iteration 1094, loss 0.62406811
iteration 1095, loss 0.62403508
iteration 1096, loss 0.62398814
iteration 1097, loss 0.62396238
iteration 1098, loss 0.62391227
iteration 1099, loss 0.62387070
iteration 1100, loss 0.62383953
iteration 1101, loss 0.62380511
iteration 1102, loss 0.62376900
iteration 1103, loss 0.62372781
iteration 1104, loss 0.62368674
iteration 1105, loss 0.62364879
iteration 1106, loss 0.62360989
iteration 1107, loss 0.62356967
iteration 1108, loss 0.62353226
iteration 1109, loss 0.62348935
iteration 1110, loss 0.62345276
iteration 1111, loss 0.62340217
iteration 1112, loss 0.62336383
iteration 1113, loss 0.62334019
iteration 1114, loss 0.62329692
iteration 1115, loss 0.62326197
iteration 1116, loss 0.62321616
iteration 1117, loss 0.62316215
iteration 1118, loss 0.62312148
iteration 1119, loss 0.62309087
iteration 1120, loss 0.62304738
iteration 1121, loss 0.62301605
iteration 1122, loss 0.62296477
iteration 1123, loss 0.62294443
iteration 1124, loss 0.62288881
iteration 1125, loss 0.62285449
iteration 1126, loss 0.62280583
iteration 1127, loss 0.62277129
iteration 1128, loss 0.62272295
iteration 1129, loss 0.62267887
iteration 1130, loss 0.62263308
iteration 1131, loss 0.62259777
iteration 1132, loss 0.62256228
iteration 1133, loss 0.62251318
iteration 1134, loss 0.62247739
iteration 1135, loss 0.62242025
iteration 1136, loss 0.62238205
iteration 1137, loss 0.62234209
iteration 1138, loss 0.62229905
iteration 1139, loss 0.62224187
iteration 1140, loss 0.62222373
iteration 1141, loss 0.62216239
iteration 1142, loss 0.62212423
iteration 1143, loss 0.62207184
iteration 1144, loss 0.62203146
iteration 1145, loss 0.62199155
iteration 1146, loss 0.62194393
iteration 1147, loss 0.62189176
iteration 1148, loss 0.62185706
iteration 1149, loss 0.62182233
iteration 1150, loss 0.62177005
iteration 1151, loss 0.62171941
iteration 1152, loss 0.62167227
iteration 1153, loss 0.62161392
iteration 1154, loss 0.62158031
iteration 1155, loss 0.62153096
iteration 1156, loss 0.62148572
iteration 1157, loss 0.62144129
iteration 1158, loss 0.62140013
iteration 1159, loss 0.62136153
iteration 1160, loss 0.62131596
iteration 1161, loss 0.62126179
iteration 1162, loss 0.62121961
iteration 1163, loss 0.62117223
iteration 1164, loss 0.62111890
iteration 1165, loss 0.62106764
iteration 1166, loss 0.62101765
iteration 1167, loss 0.62098285
iteration 1168, loss 0.62091852
iteration 1169, loss 0.62087122
iteration 1170, loss 0.62083488
iteration 1171, loss 0.62078719
iteration 1172, loss 0.62073267
iteration 1173, loss 0.62068559
iteration 1174, loss 0.62065372
iteration 1175, loss 0.62060873
iteration 1176, loss 0.62055668
iteration 1177, loss 0.62050132
iteration 1178, loss 0.62045520
iteration 1179, loss 0.62040020
iteration 1180, loss 0.62034669
iteration 1181, loss 0.62029849
iteration 1182, loss 0.62023620
iteration 1183, loss 0.62019755
iteration 1184, loss 0.62014864
iteration 1185, loss 0.62010331
iteration 1186, loss 0.62004726
iteration 1187, loss 0.61999717
iteration 1188, loss 0.61995311
iteration 1189, loss 0.61988192
iteration 1190, loss 0.61984644
iteration 1191, loss 0.61980075
iteration 1192, loss 0.61974677
iteration 1193, loss 0.61968059
iteration 1194, loss 0.61964235
iteration 1195, loss 0.61959991
iteration 1196, loss 0.61953312
iteration 1197, loss 0.61947601
iteration 1198, loss 0.61944789
iteration 1199, loss 0.61940146
iteration 1200, loss 0.61932329
iteration 1201, loss 0.61927773
iteration 1202, loss 0.61922654
iteration 1203, loss 0.61917937
iteration 1204, loss 0.61912351
iteration 1205, loss 0.61907697
iteration 1206, loss 0.61902347
iteration 1207, loss 0.61894638
iteration 1208, loss 0.61890538
iteration 1209, loss 0.61885532
iteration 1210, loss 0.61879828
iteration 1211, loss 0.61874267
iteration 1212, loss 0.61869158
iteration 1213, loss 0.61865509
iteration 1214, loss 0.61860002
iteration 1215, loss 0.61852349
iteration 1216, loss 0.61847899
iteration 1217, loss 0.61842800
iteration 1218, loss 0.61835573
iteration 1219, loss 0.61832329
iteration 1220, loss 0.61826706
iteration 1221, loss 0.61820645
iteration 1222, loss 0.61814906
iteration 1223, loss 0.61808732
iteration 1224, loss 0.61805415
iteration 1225, loss 0.61796616
iteration 1226, loss 0.61791966
iteration 1227, loss 0.61785748
iteration 1228, loss 0.61781586
iteration 1229, loss 0.61774182
iteration 1230, loss 0.61769651
iteration 1231, loss 0.61764756
iteration 1232, loss 0.61758831
iteration 1233, loss 0.61752276
iteration 1234, loss 0.61748208
iteration 1235, loss 0.61742502
iteration 1236, loss 0.61736209
iteration 1237, loss 0.61730510
iteration 1238, loss 0.61724737
iteration 1239, loss 0.61719639
iteration 1240, loss 0.61713128
iteration 1241, loss 0.61706806
iteration 1242, loss 0.61702318
iteration 1243, loss 0.61693176
iteration 1244, loss 0.61688332
iteration 1245, loss 0.61681001
iteration 1246, loss 0.61676807
iteration 1247, loss 0.61670932
iteration 1248, loss 0.61667016
iteration 1249, loss 0.61661386
iteration 1250, loss 0.61655379
iteration 1251, loss 0.61647314
iteration 1252, loss 0.61641012
iteration 1253, loss 0.61635551
iteration 1254, loss 0.61628452
iteration 1255, loss 0.61624458
iteration 1256, loss 0.61618328
iteration 1257, loss 0.61611794
iteration 1258, loss 0.61606159
iteration 1259, loss 0.61598516
iteration 1260, loss 0.61592869
iteration 1261, loss 0.61586633
iteration 1262, loss 0.61581044
iteration 1263, loss 0.61575810
iteration 1264, loss 0.61568211
iteration 1265, loss 0.61562317
iteration 1266, loss 0.61555374
iteration 1267, loss 0.61547616
iteration 1268, loss 0.61540943
iteration 1269, loss 0.61536870
iteration 1270, loss 0.61530576
iteration 1271, loss 0.61524358
iteration 1272, loss 0.61519151
iteration 1273, loss 0.61512199
iteration 1274, loss 0.61504840
iteration 1275, loss 0.61500704
iteration 1276, loss 0.61493115
iteration 1277, loss 0.61486378
iteration 1278, loss 0.61478765
iteration 1279, loss 0.61472996
iteration 1280, loss 0.61466288
iteration 1281, loss 0.61461617
iteration 1282, loss 0.61455387
iteration 1283, loss 0.61448941
iteration 1284, loss 0.61442942
iteration 1285, loss 0.61434301
iteration 1286, loss 0.61428151
iteration 1287, loss 0.61421708
iteration 1288, loss 0.61414603
iteration 1289, loss 0.61411545
iteration 1290, loss 0.61402242
iteration 1291, loss 0.61395757
iteration 1292, loss 0.61390714
iteration 1293, loss 0.61383552
iteration 1294, loss 0.61379523
iteration 1295, loss 0.61372972
iteration 1296, loss 0.61366054
iteration 1297, loss 0.61357741
iteration 1298, loss 0.61349973
iteration 1299, loss 0.61343569
iteration 1300, loss 0.61337689
iteration 1301, loss 0.61331537
iteration 1302, loss 0.61325788
iteration 1303, loss 0.61317699
iteration 1304, loss 0.61312655
iteration 1305, loss 0.61306160
iteration 1306, loss 0.61296217
iteration 1307, loss 0.61289031
iteration 1308, loss 0.61284193
iteration 1309, loss 0.61274921
iteration 1310, loss 0.61269050
iteration 1311, loss 0.61261721
iteration 1312, loss 0.61256922
iteration 1313, loss 0.61248870
iteration 1314, loss 0.61242916
iteration 1315, loss 0.61237752
iteration 1316, loss 0.61230312
iteration 1317, loss 0.61221503
iteration 1318, loss 0.61214647
iteration 1319, loss 0.61207469
iteration 1320, loss 0.61202425
iteration 1321, loss 0.61192366
iteration 1322, loss 0.61187197
iteration 1323, loss 0.61180833
iteration 1324, loss 0.61172445
iteration 1325, loss 0.61164167
iteration 1326, loss 0.61158557
iteration 1327, loss 0.61151646
iteration 1328, loss 0.61147368
iteration 1329, loss 0.61140260
iteration 1330, loss 0.61132397
iteration 1331, loss 0.61123452
iteration 1332, loss 0.61115253
iteration 1333, loss 0.61109207
iteration 1334, loss 0.61104379
iteration 1335, loss 0.61094777
iteration 1336, loss 0.61088976
iteration 1337, loss 0.61082782
iteration 1338, loss 0.61072128
iteration 1339, loss 0.61065859
iteration 1340, loss 0.61060097
iteration 1341, loss 0.61053993
iteration 1342, loss 0.61046674
iteration 1343, loss 0.61038543
iteration 1344, loss 0.61030716
iteration 1345, loss 0.61024699
iteration 1346, loss 0.61015765
iteration 1347, loss 0.61009851
iteration 1348, loss 0.61001414
iteration 1349, loss 0.60993915
iteration 1350, loss 0.60987781
iteration 1351, loss 0.60979188
iteration 1352, loss 0.60968902
iteration 1353, loss 0.60962133
iteration 1354, loss 0.60955128
iteration 1355, loss 0.60948967
iteration 1356, loss 0.60939561
iteration 1357, loss 0.60933457
iteration 1358, loss 0.60924788
iteration 1359, loss 0.60917819
iteration 1360, loss 0.60911720
iteration 1361, loss 0.60906505
iteration 1362, loss 0.60898674
iteration 1363, loss 0.60889638
iteration 1364, loss 0.60881583
iteration 1365, loss 0.60873563
iteration 1366, loss 0.60867114
iteration 1367, loss 0.60858573
iteration 1368, loss 0.60851178
iteration 1369, loss 0.60846088
iteration 1370, loss 0.60836258
iteration 1371, loss 0.60828929
iteration 1372, loss 0.60819961
iteration 1373, loss 0.60811982
iteration 1374, loss 0.60804581
iteration 1375, loss 0.60796572
iteration 1376, loss 0.60790035
iteration 1377, loss 0.60782705
iteration 1378, loss 0.60774072
iteration 1379, loss 0.60766871
iteration 1380, loss 0.60757702
iteration 1381, loss 0.60749601
iteration 1382, loss 0.60742235
iteration 1383, loss 0.60737034
iteration 1384, loss 0.60727236
iteration 1385, loss 0.60718981
iteration 1386, loss 0.60712473
iteration 1387, loss 0.60705006
iteration 1388, loss 0.60695843
iteration 1389, loss 0.60687904
iteration 1390, loss 0.60680972
iteration 1391, loss 0.60673863
iteration 1392, loss 0.60665514
iteration 1393, loss 0.60660143
iteration 1394, loss 0.60652655
iteration 1395, loss 0.60645027
iteration 1396, loss 0.60637195
iteration 1397, loss 0.60627313
iteration 1398, loss 0.60620038
iteration 1399, loss 0.60611383
iteration 1400, loss 0.60601607
iteration 1401, loss 0.60592827
iteration 1402, loss 0.60585635
iteration 1403, loss 0.60578766
iteration 1404, loss 0.60573249
iteration 1405, loss 0.60564102
iteration 1406, loss 0.60555140
iteration 1407, loss 0.60545070
iteration 1408, loss 0.60538738
iteration 1409, loss 0.60530705
iteration 1410, loss 0.60523250
iteration 1411, loss 0.60515075
iteration 1412, loss 0.60508692
iteration 1413, loss 0.60499064
iteration 1414, loss 0.60490054
iteration 1415, loss 0.60482018
iteration 1416, loss 0.60473775
iteration 1417, loss 0.60465923
iteration 1418, loss 0.60458539
iteration 1419, loss 0.60449289
iteration 1420, loss 0.60441009
iteration 1421, loss 0.60432488
iteration 1422, loss 0.60423947
iteration 1423, loss 0.60416835
iteration 1424, loss 0.60410861
iteration 1425, loss 0.60401219
iteration 1426, loss 0.60390783
iteration 1427, loss 0.60382543
iteration 1428, loss 0.60376729
iteration 1429, loss 0.60369486
iteration 1430, loss 0.60362887
iteration 1431, loss 0.60351675
iteration 1432, loss 0.60344238
iteration 1433, loss 0.60337016
iteration 1434, loss 0.60328863
iteration 1435, loss 0.60319531
iteration 1436, loss 0.60309403
iteration 1437, loss 0.60301049
iteration 1438, loss 0.60292753
iteration 1439, loss 0.60284453
iteration 1440, loss 0.60276237
iteration 1441, loss 0.60269625
iteration 1442, loss 0.60262312
iteration 1443, loss 0.60252581
iteration 1444, loss 0.60243465
iteration 1445, loss 0.60235949
iteration 1446, loss 0.60227257
iteration 1447, loss 0.60220774
iteration 1448, loss 0.60208777
iteration 1449, loss 0.60200830
iteration 1450, loss 0.60193924
iteration 1451, loss 0.60184370
iteration 1452, loss 0.60176418
iteration 1453, loss 0.60164971
iteration 1454, loss 0.60156698
iteration 1455, loss 0.60149399
iteration 1456, loss 0.60144356
iteration 1457, loss 0.60136046
iteration 1458, loss 0.60126852
iteration 1459, loss 0.60118475
iteration 1460, loss 0.60109788
iteration 1461, loss 0.60102120
iteration 1462, loss 0.60090795
iteration 1463, loss 0.60082958
iteration 1464, loss 0.60073355
iteration 1465, loss 0.60063413
iteration 1466, loss 0.60054490
iteration 1467, loss 0.60049409
iteration 1468, loss 0.60040282
iteration 1469, loss 0.60028412
iteration 1470, loss 0.60020153
iteration 1471, loss 0.60010841
iteration 1472, loss 0.60001923
iteration 1473, loss 0.59993123
iteration 1474, loss 0.59984884
iteration 1475, loss 0.59980183
iteration 1476, loss 0.59970042
iteration 1477, loss 0.59962151
iteration 1478, loss 0.59951025
iteration 1479, loss 0.59943344
iteration 1480, loss 0.59935246
iteration 1481, loss 0.59928726
iteration 1482, loss 0.59917880
iteration 1483, loss 0.59908047
iteration 1484, loss 0.59901529
iteration 1485, loss 0.59892580
iteration 1486, loss 0.59880825
iteration 1487, loss 0.59873558
iteration 1488, loss 0.59865688
iteration 1489, loss 0.59854676
iteration 1490, loss 0.59848402
iteration 1491, loss 0.59839510
iteration 1492, loss 0.59830084
iteration 1493, loss 0.59820081
iteration 1494, loss 0.59812629
iteration 1495, loss 0.59803236
iteration 1496, loss 0.59795039
iteration 1497, loss 0.59787366
iteration 1498, loss 0.59778097
iteration 1499, loss 0.59768820
iteration 1500, loss 0.59760866
iteration 1501, loss 0.59752239
iteration 1502, loss 0.59744174
iteration 1503, loss 0.59733218
iteration 1504, loss 0.59725251
iteration 1505, loss 0.59715881
iteration 1506, loss 0.59707612
iteration 1507, loss 0.59697026
iteration 1508, loss 0.59687927
iteration 1509, loss 0.59678596
iteration 1510, loss 0.59669912
iteration 1511, loss 0.59665604
iteration 1512, loss 0.59655938
iteration 1513, loss 0.59644038
iteration 1514, loss 0.59635435
iteration 1515, loss 0.59625017
iteration 1516, loss 0.59616207
iteration 1517, loss 0.59608114
iteration 1518, loss 0.59600391
iteration 1519, loss 0.59592584
iteration 1520, loss 0.59581984
iteration 1521, loss 0.59573726
iteration 1522, loss 0.59563712
iteration 1523, loss 0.59555425
iteration 1524, loss 0.59545048
iteration 1525, loss 0.59535717
iteration 1526, loss 0.59528845
iteration 1527, loss 0.59520804
iteration 1528, loss 0.59512234
iteration 1529, loss 0.59502025
iteration 1530, loss 0.59492276
iteration 1531, loss 0.59485942
iteration 1532, loss 0.59474042
iteration 1533, loss 0.59466578
iteration 1534, loss 0.59458702
iteration 1535, loss 0.59449634
iteration 1536, loss 0.59437125
iteration 1537, loss 0.59430601
iteration 1538, loss 0.59421538
iteration 1539, loss 0.59413382
iteration 1540, loss 0.59404484
iteration 1541, loss 0.59392272
iteration 1542, loss 0.59383090
iteration 1543, loss 0.59373344
iteration 1544, loss 0.59364278
iteration 1545, loss 0.59355083
iteration 1546, loss 0.59347480
iteration 1547, loss 0.59337782
iteration 1548, loss 0.59329086
iteration 1549, loss 0.59318866
iteration 1550, loss 0.59312381
iteration 1551, loss 0.59302304
iteration 1552, loss 0.59292665
iteration 1553, loss 0.59285336
iteration 1554, loss 0.59275733
iteration 1555, loss 0.59266286
iteration 1556, loss 0.59255949
iteration 1557, loss 0.59247622
iteration 1558, loss 0.59239156
iteration 1559, loss 0.59228580
iteration 1560, loss 0.59218570
iteration 1561, loss 0.59212012
iteration 1562, loss 0.59202643
iteration 1563, loss 0.59191250
iteration 1564, loss 0.59183605
iteration 1565, loss 0.59173830
iteration 1566, loss 0.59162002
iteration 1567, loss 0.59158357
iteration 1568, loss 0.59148181
iteration 1569, loss 0.59137044
iteration 1570, loss 0.59129624
iteration 1571, loss 0.59118917
iteration 1572, loss 0.59107995
iteration 1573, loss 0.59099323
iteration 1574, loss 0.59090856
iteration 1575, loss 0.59081500
iteration 1576, loss 0.59071342
iteration 1577, loss 0.59062169
iteration 1578, loss 0.59053450
iteration 1579, loss 0.59043405
iteration 1580, loss 0.59034755
iteration 1581, loss 0.59025886
iteration 1582, loss 0.59016896
iteration 1583, loss 0.59007393
iteration 1584, loss 0.58998125
iteration 1585, loss 0.58990629
iteration 1586, loss 0.58980176
iteration 1587, loss 0.58971855
iteration 1588, loss 0.58962594
iteration 1589, loss 0.58954127
iteration 1590, loss 0.58944572
iteration 1591, loss 0.58934764
iteration 1592, loss 0.58924406
iteration 1593, loss 0.58914131
iteration 1594, loss 0.58907299
iteration 1595, loss 0.58895337
iteration 1596, loss 0.58886235
iteration 1597, loss 0.58877287
iteration 1598, loss 0.58870543
iteration 1599, loss 0.58859993
iteration 1600, loss 0.58849951
iteration 1601, loss 0.58840386
iteration 1602, loss 0.58832233
iteration 1603, loss 0.58823475
iteration 1604, loss 0.58812007
iteration 1605, loss 0.58806837
iteration 1606, loss 0.58796510
iteration 1607, loss 0.58788266
iteration 1608, loss 0.58778627
iteration 1609, loss 0.58768091
iteration 1610, loss 0.58759266
iteration 1611, loss 0.58749753
iteration 1612, loss 0.58738038
iteration 1613, loss 0.58730818
iteration 1614, loss 0.58721668
iteration 1615, loss 0.58711089
iteration 1616, loss 0.58702445
iteration 1617, loss 0.58694654
iteration 1618, loss 0.58683620
iteration 1619, loss 0.58673895
iteration 1620, loss 0.58663255
iteration 1621, loss 0.58652972
iteration 1622, loss 0.58643688
iteration 1623, loss 0.58637494
iteration 1624, loss 0.58626314
iteration 1625, loss 0.58616903
iteration 1626, loss 0.58607415
iteration 1627, loss 0.58600576
iteration 1628, loss 0.58590248
iteration 1629, loss 0.58580225
iteration 1630, loss 0.58572324
iteration 1631, loss 0.58563119
iteration 1632, loss 0.58554974
iteration 1633, loss 0.58545617
iteration 1634, loss 0.58534158
iteration 1635, loss 0.58525751
iteration 1636, loss 0.58515944
iteration 1637, loss 0.58507916
iteration 1638, loss 0.58496891
iteration 1639, loss 0.58489364
iteration 1640, loss 0.58480239
iteration 1641, loss 0.58470137
iteration 1642, loss 0.58460302
iteration 1643, loss 0.58449591
iteration 1644, loss 0.58439658
iteration 1645, loss 0.58429291
iteration 1646, loss 0.58422237
iteration 1647, loss 0.58412694
iteration 1648, loss 0.58403152
iteration 1649, loss 0.58395844
iteration 1650, loss 0.58386633
iteration 1651, loss 0.58377943
iteration 1652, loss 0.58366467
iteration 1653, loss 0.58357032
iteration 1654, loss 0.58348812
iteration 1655, loss 0.58339853
iteration 1656, loss 0.58328461
iteration 1657, loss 0.58320181
iteration 1658, loss 0.58308069
iteration 1659, loss 0.58299160
iteration 1660, loss 0.58290882
iteration 1661, loss 0.58281442
iteration 1662, loss 0.58275602
iteration 1663, loss 0.58264236
iteration 1664, loss 0.58253549
iteration 1665, loss 0.58243806
iteration 1666, loss 0.58238262
iteration 1667, loss 0.58227122
iteration 1668, loss 0.58219663
iteration 1669, loss 0.58208987
iteration 1670, loss 0.58198376
iteration 1671, loss 0.58189585
iteration 1672, loss 0.58177730
iteration 1673, loss 0.58168856
iteration 1674, loss 0.58160866
iteration 1675, loss 0.58149173
iteration 1676, loss 0.58140642
iteration 1677, loss 0.58131805
iteration 1678, loss 0.58122950
iteration 1679, loss 0.58113003
iteration 1680, loss 0.58103817
iteration 1681, loss 0.58096856
iteration 1682, loss 0.58085917
iteration 1683, loss 0.58076092
iteration 1684, loss 0.58067011
iteration 1685, loss 0.58058116
iteration 1686, loss 0.58051070
iteration 1687, loss 0.58042095
iteration 1688, loss 0.58031124
iteration 1689, loss 0.58019404
iteration 1690, loss 0.58013732
iteration 1691, loss 0.58004499
iteration 1692, loss 0.57995484
iteration 1693, loss 0.57984954
iteration 1694, loss 0.57976449
iteration 1695, loss 0.57966490
iteration 1696, loss 0.57957265
iteration 1697, loss 0.57945331
iteration 1698, loss 0.57936083
iteration 1699, loss 0.57929185
iteration 1700, loss 0.57918113
iteration 1701, loss 0.57908543
iteration 1702, loss 0.57898563
iteration 1703, loss 0.57889943
iteration 1704, loss 0.57879856
iteration 1705, loss 0.57870413
iteration 1706, loss 0.57863264
iteration 1707, loss 0.57854960
iteration 1708, loss 0.57845757
iteration 1709, loss 0.57834213
iteration 1710, loss 0.57825204
iteration 1711, loss 0.57815383
iteration 1712, loss 0.57806807
iteration 1713, loss 0.57797221
iteration 1714, loss 0.57787502
iteration 1715, loss 0.57780830
iteration 1716, loss 0.57771837
iteration 1717, loss 0.57761560
iteration 1718, loss 0.57753547
iteration 1719, loss 0.57741441
iteration 1720, loss 0.57731327
iteration 1721, loss 0.57723420
iteration 1722, loss 0.57714110
iteration 1723, loss 0.57706208
iteration 1724, loss 0.57697246
iteration 1725, loss 0.57688057
iteration 1726, loss 0.57675603
iteration 1727, loss 0.57666921
iteration 1728, loss 0.57656847
iteration 1729, loss 0.57648032
iteration 1730, loss 0.57639600
iteration 1731, loss 0.57631347
iteration 1732, loss 0.57624443
iteration 1733, loss 0.57614587
iteration 1734, loss 0.57605461
iteration 1735, loss 0.57592065
iteration 1736, loss 0.57585072
iteration 1737, loss 0.57576875
iteration 1738, loss 0.57568204
iteration 1739, loss 0.57556996
iteration 1740, loss 0.57547588
iteration 1741, loss 0.57536495
iteration 1742, loss 0.57529640
iteration 1743, loss 0.57520873
iteration 1744, loss 0.57510119
iteration 1745, loss 0.57499986
iteration 1746, loss 0.57492393
iteration 1747, loss 0.57484923
iteration 1748, loss 0.57474601
iteration 1749, loss 0.57464955
iteration 1750, loss 0.57455007
iteration 1751, loss 0.57448966
iteration 1752, loss 0.57439315
iteration 1753, loss 0.57430616
iteration 1754, loss 0.57421417
iteration 1755, loss 0.57411661
iteration 1756, loss 0.57403098
iteration 1757, loss 0.57393981
iteration 1758, loss 0.57382447
iteration 1759, loss 0.57376589
iteration 1760, loss 0.57365585
iteration 1761, loss 0.57353398
iteration 1762, loss 0.57346113
iteration 1763, loss 0.57335469
iteration 1764, loss 0.57326133
iteration 1765, loss 0.57318397
iteration 1766, loss 0.57310872
iteration 1767, loss 0.57301281
iteration 1768, loss 0.57292418
iteration 1769, loss 0.57279912
iteration 1770, loss 0.57272500
iteration 1771, loss 0.57261337
iteration 1772, loss 0.57252563
iteration 1773, loss 0.57244691
iteration 1774, loss 0.57235738
iteration 1775, loss 0.57226903
iteration 1776, loss 0.57218147
iteration 1777, loss 0.57212126
iteration 1778, loss 0.57202649
iteration 1779, loss 0.57189966
iteration 1780, loss 0.57183657
iteration 1781, loss 0.57173627
iteration 1782, loss 0.57162983
iteration 1783, loss 0.57153177
iteration 1784, loss 0.57143977
iteration 1785, loss 0.57138254
iteration 1786, loss 0.57127937
iteration 1787, loss 0.57118983
iteration 1788, loss 0.57112445
iteration 1789, loss 0.57103370
iteration 1790, loss 0.57092526
iteration 1791, loss 0.57083646
iteration 1792, loss 0.57071328
iteration 1793, loss 0.57063452
iteration 1794, loss 0.57056076
iteration 1795, loss 0.57046917
iteration 1796, loss 0.57036895
iteration 1797, loss 0.57028353
iteration 1798, loss 0.57017821
iteration 1799, loss 0.57011474
iteration 1800, loss 0.57001112
iteration 1801, loss 0.56991521
iteration 1802, loss 0.56982204
iteration 1803, loss 0.56973032
iteration 1804, loss 0.56963731
iteration 1805, loss 0.56957256
iteration 1806, loss 0.56948285
iteration 1807, loss 0.56937748
iteration 1808, loss 0.56930252
iteration 1809, loss 0.56920543
iteration 1810, loss 0.56910105
iteration 1811, loss 0.56901328
iteration 1812, loss 0.56890288
iteration 1813, loss 0.56884451
iteration 1814, loss 0.56875654
iteration 1815, loss 0.56864565
iteration 1816, loss 0.56856458
iteration 1817, loss 0.56848180
iteration 1818, loss 0.56838499
iteration 1819, loss 0.56829249
iteration 1820, loss 0.56821473
iteration 1821, loss 0.56811447
iteration 1822, loss 0.56801868
iteration 1823, loss 0.56793472
iteration 1824, loss 0.56784337
iteration 1825, loss 0.56777743
iteration 1826, loss 0.56767883
iteration 1827, loss 0.56761695
iteration 1828, loss 0.56750065
iteration 1829, loss 0.56740635
iteration 1830, loss 0.56730466
iteration 1831, loss 0.56722768
iteration 1832, loss 0.56716152
iteration 1833, loss 0.56710395
iteration 1834, loss 0.56698743
iteration 1835, loss 0.56689167
iteration 1836, loss 0.56678077
iteration 1837, loss 0.56671234
iteration 1838, loss 0.56664914
iteration 1839, loss 0.56652665
iteration 1840, loss 0.56642651
iteration 1841, loss 0.56635952
iteration 1842, loss 0.56627011
iteration 1843, loss 0.56617886
iteration 1844, loss 0.56610649
iteration 1845, loss 0.56600070
iteration 1846, loss 0.56593547
iteration 1847, loss 0.56585212
iteration 1848, loss 0.56575956
iteration 1849, loss 0.56566656
iteration 1850, loss 0.56558445
iteration 1851, loss 0.56548296
iteration 1852, loss 0.56539103
iteration 1853, loss 0.56530421
iteration 1854, loss 0.56520548
iteration 1855, loss 0.56513103
iteration 1856, loss 0.56503148
iteration 1857, loss 0.56494286
iteration 1858, loss 0.56487988
iteration 1859, loss 0.56478894
iteration 1860, loss 0.56471670
iteration 1861, loss 0.56460136
iteration 1862, loss 0.56452330
iteration 1863, loss 0.56441788
iteration 1864, loss 0.56432991
iteration 1865, loss 0.56428107
iteration 1866, loss 0.56419375
iteration 1867, loss 0.56408653
iteration 1868, loss 0.56402095
iteration 1869, loss 0.56391119
iteration 1870, loss 0.56382603
iteration 1871, loss 0.56374163
iteration 1872, loss 0.56365116
iteration 1873, loss 0.56356321
iteration 1874, loss 0.56347562
iteration 1875, loss 0.56338960
iteration 1876, loss 0.56330595
iteration 1877, loss 0.56320241
iteration 1878, loss 0.56314877
iteration 1879, loss 0.56304529
iteration 1880, loss 0.56297463
iteration 1881, loss 0.56289351
iteration 1882, loss 0.56279010
iteration 1883, loss 0.56271220
iteration 1884, loss 0.56259990
iteration 1885, loss 0.56251462
iteration 1886, loss 0.56245251
iteration 1887, loss 0.56236669
iteration 1888, loss 0.56227783
iteration 1889, loss 0.56221063
iteration 1890, loss 0.56212484
iteration 1891, loss 0.56204024
iteration 1892, loss 0.56194343
iteration 1893, loss 0.56186396
iteration 1894, loss 0.56177150
iteration 1895, loss 0.56165646
iteration 1896, loss 0.56161688
iteration 1897, loss 0.56153514
iteration 1898, loss 0.56142777
iteration 1899, loss 0.56133268
iteration 1900, loss 0.56127332
iteration 1901, loss 0.56117574
iteration 1902, loss 0.56107577
iteration 1903, loss 0.56102987
iteration 1904, loss 0.56090998
iteration 1905, loss 0.56082157
iteration 1906, loss 0.56072454
iteration 1907, loss 0.56063895
iteration 1908, loss 0.56055702
iteration 1909, loss 0.56051143
iteration 1910, loss 0.56039041
iteration 1911, loss 0.56032721
iteration 1912, loss 0.56024258
iteration 1913, loss 0.56016567
iteration 1914, loss 0.56008612
iteration 1915, loss 0.56000179
iteration 1916, loss 0.55989293
iteration 1917, loss 0.55979985
iteration 1918, loss 0.55972017
iteration 1919, loss 0.55963259
iteration 1920, loss 0.55956790
iteration 1921, loss 0.55950161
iteration 1922, loss 0.55942707
iteration 1923, loss 0.55933042
iteration 1924, loss 0.55924289
iteration 1925, loss 0.55915331
iteration 1926, loss 0.55908466
iteration 1927, loss 0.55899810
iteration 1928, loss 0.55890231
iteration 1929, loss 0.55879244
iteration 1930, loss 0.55870977
iteration 1931, loss 0.55865761
iteration 1932, loss 0.55856650
iteration 1933, loss 0.55851415
iteration 1934, loss 0.55839667
iteration 1935, loss 0.55831800
iteration 1936, loss 0.55823809
iteration 1937, loss 0.55815848
iteration 1938, loss 0.55807040
iteration 1939, loss 0.55799477
iteration 1940, loss 0.55789311
iteration 1941, loss 0.55779625
iteration 1942, loss 0.55771442
iteration 1943, loss 0.55765601
iteration 1944, loss 0.55756107
iteration 1945, loss 0.55747746
iteration 1946, loss 0.55741073
iteration 1947, loss 0.55732300
iteration 1948, loss 0.55724765
iteration 1949, loss 0.55714904
iteration 1950, loss 0.55707862
iteration 1951, loss 0.55700942
iteration 1952, loss 0.55692367
iteration 1953, loss 0.55685285
iteration 1954, loss 0.55676209
iteration 1955, loss 0.55667699
iteration 1956, loss 0.55658716
iteration 1957, loss 0.55652057
iteration 1958, loss 0.55641739
iteration 1959, loss 0.55636224
iteration 1960, loss 0.55628614
iteration 1961, loss 0.55618370
iteration 1962, loss 0.55612882
iteration 1963, loss 0.55604348
iteration 1964, loss 0.55595424
iteration 1965, loss 0.55588467
iteration 1966, loss 0.55576558
iteration 1967, loss 0.55571125
iteration 1968, loss 0.55563781
iteration 1969, loss 0.55552873
iteration 1970, loss 0.55545284
iteration 1971, loss 0.55538510
iteration 1972, loss 0.55528586
iteration 1973, loss 0.55523016
iteration 1974, loss 0.55514869
iteration 1975, loss 0.55504874
iteration 1976, loss 0.55498138
iteration 1977, loss 0.55488715
iteration 1978, loss 0.55481728
iteration 1979, loss 0.55477025
iteration 1980, loss 0.55467881
iteration 1981, loss 0.55461261
iteration 1982, loss 0.55449720
iteration 1983, loss 0.55442139
iteration 1984, loss 0.55434583
iteration 1985, loss 0.55425178
iteration 1986, loss 0.55416779
iteration 1987, loss 0.55409005
iteration 1988, loss 0.55399834
iteration 1989, loss 0.55392260
iteration 1990, loss 0.55382849
iteration 1991, loss 0.55377426
iteration 1992, loss 0.55371655
iteration 1993, loss 0.55364813
iteration 1994, loss 0.55353927
iteration 1995, loss 0.55350160
iteration 1996, loss 0.55339327
iteration 1997, loss 0.55334525
iteration 1998, loss 0.55325105
iteration 1999, loss 0.55317096
iteration 2000, loss 0.55306908
iteration 3000, loss 0.49725856
iteration 4000, loss 0.46340151
iteration 5000, loss 0.43244714
iteration 6000, loss 0.40865513
iteration 7000, loss 0.39217222
iteration 8000, loss 0.38006475
iteration 9000, loss 0.37058715
iteration 10000, loss 0.36286831
iteration 11000, loss 0.35654115
iteration 12000, loss 0.35133433
iteration 13000, loss 0.34702170
iteration 14000, loss 0.34348341
iteration 15000, loss 0.34055245
iteration 16000, loss 0.33809392
iteration 17000, loss 0.33602000
iteration 18000, loss 0.33424506
iteration 19000, loss 0.33272228
iteration 20000, loss 0.33138453
iteration 21000, loss 0.33021715
iteration 22000, loss 0.32918189
iteration 23000, loss 0.32826005
iteration 24000, loss 0.32743012
iteration 25000, loss 0.32668572
iteration 26000, loss 0.32601099
iteration 27000, loss 0.32539949
iteration 28000, loss 0.32484351
iteration 29000, loss 0.32433383
iteration 30000, loss 0.32386681
iteration 31000, loss 0.32343639
iteration 32000, loss 0.32303791
iteration 33000, loss 0.32267134
iteration 34000, loss 0.32233153
iteration 35000, loss 0.32201447
iteration 36000, loss 0.32171952
iteration 37000, loss 0.32144361
iteration 38000, loss 0.32118543
iteration 39000, loss 0.32094251
iteration 40000, loss 0.32071501
iteration 41000, loss 0.32049985
iteration 42000, loss 0.32029801
iteration 43000, loss 0.32010647
iteration 44000, loss 0.31992510
iteration 45000, loss 0.31975353
iteration 46000, loss 0.31959125
iteration 47000, loss 0.31943600
iteration 48000, loss 0.31928769
iteration 49000, loss 0.31914789
iteration 50000, loss 0.31901416
iteration 51000, loss 0.31888541
iteration 52000, loss 0.31876334
iteration 53000, loss 0.31864618
iteration 54000, loss 0.31853379
iteration 55000, loss 0.31842646
iteration 56000, loss 0.31832334
iteration 57000, loss 0.31822369
iteration 58000, loss 0.31812851
iteration 59000, loss 0.31803670
iteration 60000, loss 0.31794853
iteration 61000, loss 0.31786328
iteration 62000, loss 0.31778119
iteration 63000, loss 0.31770194
iteration 64000, loss 0.31762567
iteration 65000, loss 0.31755168
iteration 66000, loss 0.31748044
iteration 67000, loss 0.31741140
iteration 68000, loss 0.31734428
iteration 69000, loss 0.31727972
iteration 70000, loss 0.31721690
iteration 71000, loss 0.31715607
iteration 72000, loss 0.31709725
iteration 73000, loss 0.31704007
iteration 74000, loss 0.31698454
iteration 75000, loss 0.31693075
iteration 76000, loss 0.31687836
iteration 77000, loss 0.31682732
iteration 78000, loss 0.31677777
iteration 79000, loss 0.31672962
iteration 80000, loss 0.31668271
iteration 81000, loss 0.31663711
iteration 82000, loss 0.31659275
iteration 83000, loss 0.31654951
iteration 84000, loss 0.31650725
iteration 85000, loss 0.31646634
iteration 86000, loss 0.31642600
iteration 87000, loss 0.31638708
iteration 88000, loss 0.31634877
iteration 89000, loss 0.31631165
iteration 90000, loss 0.31627526
iteration 91000, loss 0.31623990
iteration 92000, loss 0.31620519
iteration 93000, loss 0.31617110
iteration 94000, loss 0.31613823
iteration 95000, loss 0.31610583
iteration 96000, loss 0.31607396
iteration 97000, loss 0.31604306
iteration 98000, loss 0.31601277
iteration 99000, loss 0.31598316
