#params: learningRate 0.500, momentum 0.900, numIterations 10000, printEvery 100, printFirst 10000
iteration 0, loss 3.07051206
iteration 1, loss 3.79459183
iteration 2, loss 2.08253795
iteration 3, loss 2.80043081
iteration 4, loss 2.65950002
iteration 5, loss 2.35563967
iteration 6, loss 2.49121597
iteration 7, loss 2.83249650
iteration 8, loss 2.44097294
iteration 9, loss 2.43334662
iteration 10, loss 2.45872117
iteration 11, loss 2.58300099
iteration 12, loss 2.71515835
iteration 13, loss 2.73699649
iteration 14, loss 2.76195228
iteration 15, loss 2.61753701
iteration 16, loss 2.59599173
iteration 17, loss 2.65950451
iteration 18, loss 2.92031015
iteration 19, loss 2.48437781
iteration 20, loss 2.36135583
iteration 21, loss 2.49897600
iteration 22, loss 2.66971626
iteration 23, loss 2.56188585
iteration 24, loss 2.53331544
iteration 25, loss 2.48845166
iteration 26, loss 2.53668117
iteration 27, loss 2.62436435
iteration 28, loss 2.48076182
iteration 29, loss 2.58604236
iteration 30, loss 2.46888526
iteration 31, loss 2.59015034
iteration 32, loss 2.57532565
iteration 33, loss 2.64051496
iteration 34, loss 2.63639533
iteration 35, loss 2.47050667
iteration 36, loss 2.42756691
iteration 37, loss 2.46825193
iteration 38, loss 2.46196381
iteration 39, loss 2.52345443
iteration 40, loss 2.46777174
iteration 41, loss 2.48272681
iteration 42, loss 2.67466615
iteration 43, loss 2.50807651
iteration 44, loss 2.46864402
iteration 45, loss 2.47025773
iteration 46, loss 2.47323677
iteration 47, loss 2.52337241
iteration 48, loss 2.56839009
iteration 49, loss 2.49469294
iteration 50, loss 2.52784815
iteration 51, loss 2.51792554
iteration 52, loss 2.49587320
iteration 53, loss 2.55412452
iteration 54, loss 2.63137228
iteration 55, loss 2.66771305
iteration 56, loss 2.50342385
iteration 57, loss 2.59779162
iteration 58, loss 2.57541459
iteration 59, loss 2.68463241
iteration 60, loss 2.56254512
iteration 61, loss 2.63556940
iteration 62, loss 2.76824265
iteration 63, loss 2.67966969
iteration 64, loss 2.49321717
iteration 65, loss 2.52238768
iteration 66, loss 2.25157647
iteration 67, loss 2.12383615
iteration 68, loss 2.12848841
iteration 69, loss 2.12476663
iteration 70, loss 2.16989712
iteration 71, loss 2.14451880
iteration 72, loss 2.50074133
iteration 73, loss 2.32185633
iteration 74, loss 2.19613201
iteration 75, loss 2.00900938
iteration 76, loss 2.12861850
iteration 77, loss 2.04110568
iteration 78, loss 2.20575443
iteration 79, loss 2.20727507
iteration 80, loss 1.95182852
iteration 81, loss 1.84771870
iteration 82, loss 1.75520847
iteration 83, loss 1.75588192
iteration 84, loss 1.78044057
iteration 85, loss 1.50990129
iteration 86, loss 1.62460975
iteration 87, loss 1.40120666
iteration 88, loss 1.33262924
iteration 89, loss 1.28708732
iteration 90, loss 1.16980763
iteration 91, loss 1.61293096
iteration 92, loss 1.40219239
iteration 93, loss 1.20840252
iteration 94, loss 1.24721976
iteration 95, loss 1.47747885
iteration 96, loss 1.36482059
iteration 97, loss 1.21588524
iteration 98, loss 1.22435899
iteration 99, loss 1.21465560
iteration 100, loss 1.10369282
iteration 101, loss 1.15172049
iteration 102, loss 1.24313430
iteration 103, loss 1.18124473
iteration 104, loss 1.13156204
iteration 105, loss 1.35419715
iteration 106, loss 1.09186709
iteration 107, loss 0.97592310
iteration 108, loss 1.20830500
iteration 109, loss 1.48179133
iteration 110, loss 1.08272029
iteration 111, loss 1.30562307
iteration 112, loss 1.24455595
iteration 113, loss 1.22853148
iteration 114, loss 1.08755143
iteration 115, loss 1.62791193
iteration 116, loss 1.36256376
iteration 117, loss 1.17122539
iteration 118, loss 1.45077292
iteration 119, loss 1.29812203
iteration 120, loss 1.48891073
iteration 121, loss 1.37178813
iteration 122, loss 1.60774236
iteration 123, loss 1.22070080
iteration 124, loss 1.27574026
iteration 125, loss 1.22394629
iteration 126, loss 1.50352228
iteration 127, loss 1.21393986
iteration 128, loss 1.47520130
iteration 129, loss 1.34379618
iteration 130, loss 1.18570798
iteration 131, loss 1.20687097
iteration 132, loss 1.24454590
iteration 133, loss 1.22135073
iteration 134, loss 1.16742947
iteration 135, loss 1.16344948
iteration 136, loss 1.37945250
iteration 137, loss 1.14104095
iteration 138, loss 1.20706797
iteration 139, loss 1.21195868
iteration 140, loss 1.36380891
iteration 141, loss 1.41297721
iteration 142, loss 1.48359071
iteration 143, loss 1.19307374
iteration 144, loss 1.40926501
iteration 145, loss 1.18281445
iteration 146, loss 1.19553220
iteration 147, loss 1.22122367
iteration 148, loss 1.26173920
iteration 149, loss 1.41219957
iteration 150, loss 1.72514392
iteration 151, loss 1.42596425
iteration 152, loss 1.51767159
iteration 153, loss 1.30140564
iteration 154, loss 1.17648132
iteration 155, loss 1.23966473
iteration 156, loss 1.26889119
iteration 157, loss 1.28839916
iteration 158, loss 1.33949237
iteration 159, loss 1.18546275
iteration 160, loss 1.23701905
iteration 161, loss 1.19480334
iteration 162, loss 1.26041350
iteration 163, loss 1.45155343
iteration 164, loss 1.22609481
iteration 165, loss 1.29253693
iteration 166, loss 1.39590463
iteration 167, loss 1.35956591
iteration 168, loss 1.22404274
iteration 169, loss 1.33404364
iteration 170, loss 1.26101820
iteration 171, loss 1.15247052
iteration 172, loss 1.37877478
iteration 173, loss 0.91699858
iteration 174, loss 1.35114065
iteration 175, loss 1.32570388
iteration 176, loss 1.71009830
iteration 177, loss 1.65452673
iteration 178, loss 1.36482470
iteration 179, loss 1.14146273
iteration 180, loss 1.33251538
iteration 181, loss 1.40787497
iteration 182, loss 1.26519177
iteration 183, loss 1.31477028
iteration 184, loss 1.32483414
iteration 185, loss 1.32401123
iteration 186, loss 1.34086428
iteration 187, loss 1.18139219
iteration 188, loss 1.22643664
iteration 189, loss 1.19528300
iteration 190, loss 1.21269399
iteration 191, loss 1.31713904
iteration 192, loss 1.30289346
iteration 193, loss 1.44467241
iteration 194, loss 1.10840333
iteration 195, loss 1.23955645
iteration 196, loss 1.38587042
iteration 197, loss 1.36730065
iteration 198, loss 1.27735402
iteration 199, loss 1.24393421
iteration 200, loss 1.18336484
iteration 201, loss 1.17927670
iteration 202, loss 1.33351339
iteration 203, loss 1.22946031
iteration 204, loss 1.29076205
iteration 205, loss 1.23214953
iteration 206, loss 1.18314385
iteration 207, loss 1.19049161
iteration 208, loss 1.25044435
iteration 209, loss 1.24688348
iteration 210, loss 1.34056907
iteration 211, loss 1.19050349
iteration 212, loss 0.95991639
iteration 213, loss 0.96341159
iteration 214, loss 0.93364320
iteration 215, loss 0.85272723
iteration 216, loss 0.94315825
iteration 217, loss 1.24304630
iteration 218, loss 1.10621913
iteration 219, loss 1.08636835
iteration 220, loss 1.03778074
iteration 221, loss 0.87140800
iteration 222, loss 0.95660447
iteration 223, loss 0.90634690
iteration 224, loss 0.93136014
iteration 225, loss 1.02854142
iteration 226, loss 0.84684680
iteration 227, loss 0.97459333
iteration 228, loss 0.86020714
iteration 229, loss 1.03235155
iteration 230, loss 1.01221835
iteration 231, loss 0.94069684
iteration 232, loss 1.03353672
iteration 233, loss 1.01429878
iteration 234, loss 0.99183084
iteration 235, loss 0.88294191
iteration 236, loss 0.93623370
iteration 237, loss 0.92111030
iteration 238, loss 0.83990410
iteration 239, loss 0.83697943
iteration 240, loss 0.87500420
iteration 241, loss 0.86167578
iteration 242, loss 0.83381046
iteration 243, loss 0.96702256
iteration 244, loss 0.89661270
iteration 245, loss 0.88339407
iteration 246, loss 0.74569329
iteration 247, loss 0.91988674
iteration 248, loss 0.98518152
iteration 249, loss 0.82283936
iteration 250, loss 0.77302563
iteration 251, loss 1.11379013
iteration 252, loss 1.03925334
iteration 253, loss 0.86366678
iteration 254, loss 0.84094038
iteration 255, loss 0.76794427
iteration 256, loss 0.91774250
iteration 257, loss 0.89373792
iteration 258, loss 0.83271450
iteration 259, loss 0.82330919
iteration 260, loss 0.89021417
iteration 261, loss 0.85605926
iteration 262, loss 0.88070724
iteration 263, loss 0.84122233
iteration 264, loss 0.92419569
iteration 265, loss 0.81028371
iteration 266, loss 0.83343649
iteration 267, loss 0.91990965
iteration 268, loss 1.00668097
iteration 269, loss 0.88467525
iteration 270, loss 1.02375913
iteration 271, loss 0.93044710
iteration 272, loss 0.96899107
iteration 273, loss 0.87954579
iteration 274, loss 0.90958360
iteration 275, loss 0.77096314
iteration 276, loss 0.97608542
iteration 277, loss 0.84831815
iteration 278, loss 0.86045540
iteration 279, loss 0.88290742
iteration 280, loss 0.85729315
iteration 281, loss 0.84665904
iteration 282, loss 0.82542531
iteration 283, loss 0.97247233
iteration 284, loss 1.00185241
iteration 285, loss 0.91956417
iteration 286, loss 0.77184987
iteration 287, loss 0.81498378
iteration 288, loss 0.94421662
iteration 289, loss 0.84199736
iteration 290, loss 0.98510437
iteration 291, loss 0.83185444
iteration 292, loss 0.88497728
iteration 293, loss 0.90916168
iteration 294, loss 0.84649736
iteration 295, loss 0.89480141
iteration 296, loss 0.82780758
iteration 297, loss 0.85883697
iteration 298, loss 0.82007001
iteration 299, loss 0.87445523
iteration 300, loss 0.92042250
iteration 301, loss 1.06909621
iteration 302, loss 0.89063456
iteration 303, loss 0.93972328
iteration 304, loss 0.86748231
iteration 305, loss 0.85527835
iteration 306, loss 0.81678196
iteration 307, loss 0.83898766
iteration 308, loss 0.85527075
iteration 309, loss 0.92221789
iteration 310, loss 0.80308527
iteration 311, loss 0.80802188
iteration 312, loss 0.88307048
iteration 313, loss 0.75827986
iteration 314, loss 0.91216733
iteration 315, loss 0.93848355
iteration 316, loss 0.75447020
iteration 317, loss 0.85672812
iteration 318, loss 0.75313332
iteration 319, loss 0.78036575
iteration 320, loss 0.79969888
iteration 321, loss 0.79479290
iteration 322, loss 1.00519468
iteration 323, loss 1.07374918
iteration 324, loss 1.16678139
iteration 325, loss 0.92202314
iteration 326, loss 1.14948814
iteration 327, loss 0.89657442
iteration 328, loss 0.96583184
iteration 329, loss 0.94585651
iteration 330, loss 1.10676660
iteration 331, loss 0.92220613
iteration 332, loss 1.00598030
iteration 333, loss 1.09033827
iteration 334, loss 1.09919457
iteration 335, loss 0.89573415
iteration 336, loss 0.82612672
iteration 337, loss 0.93214619
iteration 338, loss 0.96248128
iteration 339, loss 1.02586155
iteration 340, loss 0.87619619
iteration 341, loss 0.89209139
iteration 342, loss 0.83054911
iteration 343, loss 1.16402738
iteration 344, loss 0.97733119
iteration 345, loss 0.80892437
iteration 346, loss 0.82393020
iteration 347, loss 0.71607509
iteration 348, loss 0.73108173
iteration 349, loss 0.71799792
iteration 350, loss 1.05763462
iteration 351, loss 0.93600592
iteration 352, loss 0.81436658
iteration 353, loss 0.88493053
iteration 354, loss 0.84354268
iteration 355, loss 0.86889177
iteration 356, loss 1.01549218
iteration 357, loss 0.97102483
iteration 358, loss 0.96503290
iteration 359, loss 0.95894353
iteration 360, loss 0.93004915
iteration 361, loss 0.85689449
iteration 362, loss 0.83025798
iteration 363, loss 0.84145960
iteration 364, loss 0.67684146
iteration 365, loss 0.95782933
iteration 366, loss 1.05600273
iteration 367, loss 0.99602645
iteration 368, loss 0.81664814
iteration 369, loss 0.90387018
iteration 370, loss 0.85169491
iteration 371, loss 0.87055343
iteration 372, loss 0.81105375
iteration 373, loss 0.88040705
iteration 374, loss 0.80916058
iteration 375, loss 0.91361881
iteration 376, loss 0.86575219
iteration 377, loss 0.70074969
iteration 378, loss 0.50402352
iteration 379, loss 0.55299366
iteration 380, loss 0.52651898
iteration 381, loss 0.64533154
iteration 382, loss 0.62944280
iteration 383, loss 0.45244607
iteration 384, loss 0.48211402
iteration 385, loss 0.52978560
iteration 386, loss 0.52960051
iteration 387, loss 0.68025403
iteration 388, loss 0.47568211
iteration 389, loss 0.44930258
iteration 390, loss 0.52451377
iteration 391, loss 0.46143123
iteration 392, loss 0.71603916
iteration 393, loss 0.43395992
iteration 394, loss 0.38328291
iteration 395, loss 0.70332776
iteration 396, loss 0.70928075
iteration 397, loss 0.73032704
iteration 398, loss 0.63535335
iteration 399, loss 0.54456584
iteration 400, loss 0.52509963
iteration 401, loss 0.45788481
iteration 402, loss 0.43874148
iteration 403, loss 0.45498608
iteration 404, loss 0.45241443
iteration 405, loss 0.40914973
iteration 406, loss 0.46578172
iteration 407, loss 0.46512958
iteration 408, loss 0.59314404
iteration 409, loss 0.63013564
iteration 410, loss 0.60668369
iteration 411, loss 0.51039155
iteration 412, loss 0.54413461
iteration 413, loss 0.52978891
iteration 414, loss 0.51221716
iteration 415, loss 0.50137216
iteration 416, loss 0.52390570
iteration 417, loss 0.47499927
iteration 418, loss 0.48892362
iteration 419, loss 0.52066208
iteration 420, loss 0.53570302
iteration 421, loss 0.47075006
iteration 422, loss 0.48566096
iteration 423, loss 0.49643254
iteration 424, loss 0.53729125
iteration 425, loss 0.50204218
iteration 426, loss 0.47470212
iteration 427, loss 0.50466348
iteration 428, loss 0.49562701
iteration 429, loss 0.51213964
iteration 430, loss 0.56446778
iteration 431, loss 0.54699841
iteration 432, loss 0.37899303
iteration 433, loss 0.47532875
iteration 434, loss 0.53080071
iteration 435, loss 0.46677589
iteration 436, loss 0.56597823
iteration 437, loss 0.51539707
iteration 438, loss 0.44937646
iteration 439, loss 0.52167092
iteration 440, loss 0.57202279
iteration 441, loss 0.57487918
iteration 442, loss 0.54374464
iteration 443, loss 0.45115599
iteration 444, loss 0.63353690
iteration 445, loss 0.62007480
iteration 446, loss 0.68460114
iteration 447, loss 0.49587938
iteration 448, loss 0.50500698
iteration 449, loss 0.52421248
iteration 450, loss 0.51030820
iteration 451, loss 0.49007484
iteration 452, loss 0.46880695
iteration 453, loss 0.54367408
iteration 454, loss 0.53354431
iteration 455, loss 0.46506907
iteration 456, loss 0.50144427
iteration 457, loss 0.48902364
iteration 458, loss 0.54541921
iteration 459, loss 0.52485309
iteration 460, loss 0.51802663
iteration 461, loss 0.48316391
iteration 462, loss 0.48967357
iteration 463, loss 0.51467723
iteration 464, loss 0.50641608
iteration 465, loss 0.47216827
iteration 466, loss 0.50354097
iteration 467, loss 0.49836583
iteration 468, loss 0.52379929
iteration 469, loss 0.63190594
iteration 470, loss 0.46222023
iteration 471, loss 0.47666683
iteration 472, loss 0.37239463
iteration 473, loss 0.43106138
iteration 474, loss 0.46982868
iteration 475, loss 0.54235496
iteration 476, loss 0.43097269
iteration 477, loss 0.46765545
iteration 478, loss 0.68835542
iteration 479, loss 0.58792295
iteration 480, loss 0.42950402
iteration 481, loss 0.47002997
iteration 482, loss 0.59419632
iteration 483, loss 0.49569253
iteration 484, loss 0.56341167
iteration 485, loss 0.46430390
iteration 486, loss 0.59322278
iteration 487, loss 0.51724290
iteration 488, loss 0.58409080
iteration 489, loss 0.72252679
iteration 490, loss 0.50845514
iteration 491, loss 0.62176956
iteration 492, loss 0.62248748
iteration 493, loss 0.55236180
iteration 494, loss 0.56998257
iteration 495, loss 0.46784980
iteration 496, loss 0.49494668
iteration 497, loss 0.52821236
iteration 498, loss 0.57398765
iteration 499, loss 0.56266443
iteration 500, loss 0.64506643
iteration 501, loss 0.47008666
iteration 502, loss 0.50662043
iteration 503, loss 0.52633634
iteration 504, loss 0.55215898
iteration 505, loss 0.64929613
iteration 506, loss 0.54755084
iteration 507, loss 0.64144149
iteration 508, loss 0.48219946
iteration 509, loss 0.74512349
iteration 510, loss 0.77278329
iteration 511, loss 0.63704473
iteration 512, loss 0.46659017
iteration 513, loss 0.53482921
iteration 514, loss 0.48497606
iteration 515, loss 0.47761686
iteration 516, loss 0.50263434
iteration 517, loss 0.51833022
iteration 518, loss 0.53087477
iteration 519, loss 0.51269709
iteration 520, loss 0.49835243
iteration 521, loss 0.47166914
iteration 522, loss 0.48395088
iteration 523, loss 0.47690177
iteration 524, loss 0.57654140
iteration 525, loss 0.48739731
iteration 526, loss 0.51206648
iteration 527, loss 0.54658781
iteration 528, loss 0.53432484
iteration 529, loss 0.71373450
iteration 530, loss 0.50358471
iteration 531, loss 1.50856725
iteration 532, loss 0.70819816
iteration 533, loss 0.57501448
iteration 534, loss 0.40101099
iteration 535, loss 0.49350930
iteration 536, loss 0.66458082
iteration 537, loss 0.51344834
iteration 538, loss 0.44701800
iteration 539, loss 0.53796604
iteration 540, loss 0.50757683
iteration 541, loss 0.51769382
iteration 542, loss 0.49174493
iteration 543, loss 0.53227911
iteration 544, loss 0.53305211
iteration 545, loss 0.59214334
iteration 546, loss 0.50365770
iteration 547, loss 0.51999801
iteration 548, loss 0.60844824
iteration 549, loss 0.53172577
iteration 550, loss 0.48900582
iteration 551, loss 0.48234481
iteration 552, loss 0.49715057
iteration 553, loss 0.57335877
iteration 554, loss 0.68541108
iteration 555, loss 0.53958949
iteration 556, loss 0.53768526
iteration 557, loss 0.49982445
iteration 558, loss 0.56463186
iteration 559, loss 0.72147014
iteration 560, loss 0.57387787
iteration 561, loss 0.54896215
iteration 562, loss 0.51523302
iteration 563, loss 0.50478487
iteration 564, loss 0.62080599
iteration 565, loss 0.69823651
iteration 566, loss 0.66372963
iteration 567, loss 0.49824283
iteration 568, loss 0.46222241
iteration 569, loss 0.56104682
iteration 570, loss 0.54609050
iteration 571, loss 0.51391520
iteration 572, loss 0.43408814
iteration 573, loss 0.55162503
iteration 574, loss 0.47058369
iteration 575, loss 0.63797232
iteration 576, loss 0.42411501
iteration 577, loss 0.59664684
iteration 578, loss 0.48971870
iteration 579, loss 0.42613446
iteration 580, loss 0.47788086
iteration 581, loss 0.39679305
iteration 582, loss 0.48294145
iteration 583, loss 0.38290929
iteration 584, loss 0.39707124
iteration 585, loss 0.45361733
iteration 586, loss 0.43348137
iteration 587, loss 0.41080698
iteration 588, loss 0.57150001
iteration 589, loss 0.41720553
iteration 590, loss 0.52215608
iteration 591, loss 0.39880760
iteration 592, loss 0.47970488
iteration 593, loss 0.70839172
iteration 594, loss 0.66966653
iteration 595, loss 0.35021053
iteration 596, loss 0.79280180
iteration 597, loss 0.79614003
iteration 598, loss 0.60059649
iteration 599, loss 0.47721775
iteration 600, loss 0.51167541
iteration 601, loss 0.53555597
iteration 602, loss 0.50422182
iteration 603, loss 0.52583458
iteration 604, loss 0.48786280
iteration 605, loss 0.61448995
iteration 606, loss 0.47838449
iteration 607, loss 0.51500449
iteration 608, loss 0.52329693
iteration 609, loss 0.47576004
iteration 610, loss 0.56131968
iteration 611, loss 0.50461459
iteration 612, loss 0.52125173
iteration 613, loss 0.48887700
iteration 614, loss 0.51451590
iteration 615, loss 0.57591984
iteration 616, loss 0.46739604
iteration 617, loss 0.53295469
iteration 618, loss 0.51627157
iteration 619, loss 0.52103882
iteration 620, loss 0.58459080
iteration 621, loss 0.54503018
iteration 622, loss 0.53919437
iteration 623, loss 0.56227382
iteration 624, loss 0.54847820
iteration 625, loss 0.56813204
iteration 626, loss 0.52380175
iteration 627, loss 0.61025713
iteration 628, loss 0.52837014
iteration 629, loss 0.58293280
iteration 630, loss 0.66539183
iteration 631, loss 0.42455703
iteration 632, loss 0.53048909
iteration 633, loss 0.50193125
iteration 634, loss 0.58060111
iteration 635, loss 0.51066086
iteration 636, loss 0.59077781
iteration 637, loss 0.51991180
iteration 638, loss 0.40498431
iteration 639, loss 0.48933008
iteration 640, loss 0.50024123
iteration 641, loss 0.45968392
iteration 642, loss 0.57141317
iteration 643, loss 0.53769369
iteration 644, loss 0.60831049
iteration 645, loss 0.54819665
iteration 646, loss 0.51814141
iteration 647, loss 0.56196045
iteration 648, loss 0.47704328
iteration 649, loss 0.56547614
iteration 650, loss 0.50182190
iteration 651, loss 0.52677266
iteration 652, loss 0.51273884
iteration 653, loss 0.46382773
iteration 654, loss 0.47404686
iteration 655, loss 0.53475336
iteration 656, loss 0.77503730
iteration 657, loss 0.54518963
iteration 658, loss 0.66924804
iteration 659, loss 0.60722848
iteration 660, loss 0.49139715
iteration 661, loss 0.48481214
iteration 662, loss 0.48547273
iteration 663, loss 0.56238878
iteration 664, loss 0.51864883
iteration 665, loss 0.49894948
iteration 666, loss 0.48700581
iteration 667, loss 0.49130003
iteration 668, loss 0.51217485
iteration 669, loss 0.51500173
iteration 670, loss 0.62497187
iteration 671, loss 0.57925211
iteration 672, loss 0.55571776
iteration 673, loss 0.59115357
iteration 674, loss 0.40746597
iteration 675, loss 0.60171932
iteration 676, loss 0.66848635
iteration 677, loss 0.51215124
iteration 678, loss 0.46323001
iteration 679, loss 0.50072020
iteration 680, loss 0.51037609
iteration 681, loss 0.54794236
iteration 682, loss 0.47772895
iteration 683, loss 0.46813492
iteration 684, loss 0.56914897
iteration 685, loss 0.67592669
iteration 686, loss 0.60717902
iteration 687, loss 0.57743994
iteration 688, loss 0.58337990
iteration 689, loss 0.60492115
iteration 690, loss 0.41026054
iteration 691, loss 0.56503525
iteration 692, loss 0.57167793
iteration 693, loss 0.57629803
iteration 694, loss 0.61778455
iteration 695, loss 0.57488505
iteration 696, loss 0.50905501
iteration 697, loss 0.51136703
iteration 698, loss 0.48767938
iteration 699, loss 0.56550566
iteration 700, loss 0.48876672
iteration 701, loss 0.51567109
iteration 702, loss 0.49536776
iteration 703, loss 0.55277246
iteration 704, loss 0.55314597
iteration 705, loss 0.46625829
iteration 706, loss 0.50417236
iteration 707, loss 0.50211205
iteration 708, loss 0.52970793
iteration 709, loss 0.45765610
iteration 710, loss 0.79838497
iteration 711, loss 0.64227688
iteration 712, loss 0.63068324
iteration 713, loss 0.55439454
iteration 714, loss 0.69195680
iteration 715, loss 0.54128610
iteration 716, loss 0.52951058
iteration 717, loss 0.51284693
iteration 718, loss 0.49600586
iteration 719, loss 0.47913807
iteration 720, loss 0.55668285
iteration 721, loss 0.50349326
iteration 722, loss 0.47530810
iteration 723, loss 0.57732724
iteration 724, loss 0.53537770
iteration 725, loss 0.47848791
iteration 726, loss 0.51990336
iteration 727, loss 0.46613803
iteration 728, loss 0.54017747
iteration 729, loss 0.52901210
iteration 730, loss 0.59687719
iteration 731, loss 0.53408329
iteration 732, loss 0.49551128
iteration 733, loss 0.49160398
iteration 734, loss 0.55251150
iteration 735, loss 0.49426929
iteration 736, loss 0.50590372
iteration 737, loss 0.47422851
iteration 738, loss 0.51200843
iteration 739, loss 0.49239840
iteration 740, loss 0.53791245
iteration 741, loss 0.45989604
iteration 742, loss 0.65060415
iteration 743, loss 0.64787384
iteration 744, loss 0.79128974
iteration 745, loss 0.53242288
iteration 746, loss 0.57025240
iteration 747, loss 0.58643150
iteration 748, loss 0.51016817
iteration 749, loss 0.53513076
iteration 750, loss 0.58967466
iteration 751, loss 0.50673560
iteration 752, loss 0.45579309
iteration 753, loss 0.62167756
iteration 754, loss 0.66315332
iteration 755, loss 0.58037209
iteration 756, loss 0.48579383
iteration 757, loss 0.45763913
iteration 758, loss 0.45670322
iteration 759, loss 0.49799583
iteration 760, loss 0.51898170
iteration 761, loss 0.51555494
iteration 762, loss 0.47213533
iteration 763, loss 0.50779227
iteration 764, loss 0.54726865
iteration 765, loss 0.48299630
iteration 766, loss 0.49891756
iteration 767, loss 0.62655799
iteration 768, loss 0.46296513
iteration 769, loss 0.76096606
iteration 770, loss 0.83260321
iteration 771, loss 0.53534013
iteration 772, loss 0.51590867
iteration 773, loss 0.57375494
iteration 774, loss 0.63057890
iteration 775, loss 0.55300226
iteration 776, loss 0.55296997
iteration 777, loss 0.61269470
iteration 778, loss 0.53291277
iteration 779, loss 0.50632470
iteration 780, loss 0.52220062
iteration 781, loss 0.54825170
iteration 782, loss 0.47298556
iteration 783, loss 0.56317835
iteration 784, loss 0.48958325
iteration 785, loss 0.55534100
iteration 786, loss 0.60349909
iteration 787, loss 0.46670145
iteration 788, loss 0.63704913
iteration 789, loss 0.54105488
iteration 790, loss 0.55277512
iteration 791, loss 0.56502084
iteration 792, loss 0.53706616
iteration 793, loss 0.44780060
iteration 794, loss 0.59298985
iteration 795, loss 0.63421886
iteration 796, loss 0.59110000
iteration 797, loss 0.61823921
iteration 798, loss 0.59081661
iteration 799, loss 0.64461986
iteration 800, loss 0.51567857
iteration 801, loss 0.44391069
iteration 802, loss 0.50534467
iteration 803, loss 0.53075949
iteration 804, loss 0.50010719
iteration 805, loss 0.73403339
iteration 806, loss 0.44894676
iteration 807, loss 0.50209805
iteration 808, loss 0.58973189
iteration 809, loss 0.47003566
iteration 810, loss 0.52914524
iteration 811, loss 0.53217785
iteration 812, loss 0.50812765
iteration 813, loss 0.49130579
iteration 814, loss 0.49293031
iteration 815, loss 0.49958832
iteration 816, loss 0.50299957
iteration 817, loss 0.52225289
iteration 818, loss 0.62297229
iteration 819, loss 0.55530315
iteration 820, loss 0.54144979
iteration 821, loss 0.52458399
iteration 822, loss 0.51822984
iteration 823, loss 0.58164058
iteration 824, loss 0.50599055
iteration 825, loss 0.50228693
iteration 826, loss 0.51517080
iteration 827, loss 0.49584776
iteration 828, loss 0.47195433
iteration 829, loss 0.50649072
iteration 830, loss 0.54489013
iteration 831, loss 0.54201132
iteration 832, loss 0.51365990
iteration 833, loss 0.55760626
iteration 834, loss 0.59277541
iteration 835, loss 0.42265441
iteration 836, loss 0.45600665
iteration 837, loss 0.49237978
iteration 838, loss 0.60098050
iteration 839, loss 0.49083962
iteration 840, loss 0.56724567
iteration 841, loss 0.52317424
iteration 842, loss 0.50917733
iteration 843, loss 0.51333255
iteration 844, loss 0.51245361
iteration 845, loss 0.47269721
iteration 846, loss 0.58007154
iteration 847, loss 0.57477595
iteration 848, loss 0.46300405
iteration 849, loss 0.72380865
iteration 850, loss 0.60805664
iteration 851, loss 0.53161063
iteration 852, loss 0.55781716
iteration 853, loss 0.49913696
iteration 854, loss 0.53532300
iteration 855, loss 0.57192718
iteration 856, loss 0.65765500
iteration 857, loss 0.68589745
iteration 858, loss 0.52710658
iteration 859, loss 0.67562865
iteration 860, loss 0.81091800
iteration 861, loss 0.61997604
iteration 862, loss 0.43902281
iteration 863, loss 0.48129610
iteration 864, loss 0.51728435
iteration 865, loss 0.48379237
iteration 866, loss 0.52801484
iteration 867, loss 0.59195183
iteration 868, loss 0.43819573
iteration 869, loss 0.59691495
iteration 870, loss 0.58292005
iteration 871, loss 0.51535686
iteration 872, loss 0.46744011
iteration 873, loss 0.53342556
iteration 874, loss 0.47207196
iteration 875, loss 0.51771084
iteration 876, loss 0.51955177
iteration 877, loss 0.50982965
iteration 878, loss 0.51951195
iteration 879, loss 0.49840691
iteration 880, loss 0.57349401
iteration 881, loss 0.48986731
iteration 882, loss 0.58704996
iteration 883, loss 0.83535694
iteration 884, loss 0.60000624
iteration 885, loss 0.48120268
iteration 886, loss 0.46263646
iteration 887, loss 0.53058583
iteration 888, loss 0.57584858
iteration 889, loss 0.51161525
iteration 890, loss 0.50379265
iteration 891, loss 0.53070230
iteration 892, loss 0.50205271
iteration 893, loss 0.56226272
iteration 894, loss 0.51255393
iteration 895, loss 0.61708410
iteration 896, loss 0.47923463
iteration 897, loss 0.56312201
iteration 898, loss 0.55536820
iteration 899, loss 0.48341995
iteration 900, loss 0.53840762
iteration 901, loss 0.53046344
iteration 902, loss 0.50222454
iteration 903, loss 0.49753606
iteration 904, loss 0.55537545
iteration 905, loss 0.54236491
iteration 906, loss 0.47290498
iteration 907, loss 0.50439980
iteration 908, loss 0.50731767
iteration 909, loss 0.53540150
iteration 910, loss 0.45311579
iteration 911, loss 0.61524709
iteration 912, loss 0.57693395
iteration 913, loss 0.53999177
iteration 914, loss 0.49818826
iteration 915, loss 0.55854975
iteration 916, loss 0.54349350
iteration 917, loss 0.60047579
iteration 918, loss 0.63347773
iteration 919, loss 0.52866060
iteration 920, loss 0.66290182
iteration 921, loss 0.58991757
iteration 922, loss 0.48765717
iteration 923, loss 0.49278122
iteration 924, loss 0.54179496
iteration 925, loss 0.49804828
iteration 926, loss 0.49610255
iteration 927, loss 0.46274788
iteration 928, loss 0.48741152
iteration 929, loss 0.51857096
iteration 930, loss 0.50410576
iteration 931, loss 0.51750062
iteration 932, loss 0.58146303
iteration 933, loss 0.54811167
iteration 934, loss 0.69301267
iteration 935, loss 0.48403948
iteration 936, loss 0.69719352
iteration 937, loss 0.54156071
iteration 938, loss 0.45828428
iteration 939, loss 0.63714822
iteration 940, loss 0.46086997
iteration 941, loss 0.46848652
iteration 942, loss 0.50405360
iteration 943, loss 0.52210584
iteration 944, loss 0.49494871
iteration 945, loss 0.45627784
iteration 946, loss 0.55068655
iteration 947, loss 0.48598659
iteration 948, loss 0.57646144
iteration 949, loss 0.49458939
iteration 950, loss 0.56616854
iteration 951, loss 0.59570095
iteration 952, loss 0.44062821
iteration 953, loss 0.56780032
iteration 954, loss 0.66849922
iteration 955, loss 0.65931127
iteration 956, loss 0.59119806
iteration 957, loss 0.48688016
iteration 958, loss 0.51507851
iteration 959, loss 0.60015211
iteration 960, loss 0.56751748
iteration 961, loss 0.49668890
iteration 962, loss 0.48535313
iteration 963, loss 0.47201144
iteration 964, loss 0.46985712
iteration 965, loss 0.57446732
iteration 966, loss 0.49837984
iteration 967, loss 0.56396766
iteration 968, loss 0.56963018
iteration 969, loss 0.43780071
iteration 970, loss 0.51498916
iteration 971, loss 0.51389453
iteration 972, loss 0.52005892
iteration 973, loss 0.66056391
iteration 974, loss 0.50721421
iteration 975, loss 0.52068501
iteration 976, loss 0.50006214
iteration 977, loss 0.49750307
iteration 978, loss 0.62424501
iteration 979, loss 0.47445331
iteration 980, loss 0.52508332
iteration 981, loss 0.50246072
iteration 982, loss 0.60374207
iteration 983, loss 0.62579498
iteration 984, loss 0.49399508
iteration 985, loss 0.47095419
iteration 986, loss 0.58888065
iteration 987, loss 0.46489619
iteration 988, loss 0.51805404
iteration 989, loss 0.52166702
iteration 990, loss 0.70907382
iteration 991, loss 0.58179219
iteration 992, loss 0.51406589
iteration 993, loss 0.54400085
iteration 994, loss 0.51072420
iteration 995, loss 0.49709983
iteration 996, loss 0.59153643
iteration 997, loss 0.54742893
iteration 998, loss 0.46289993
iteration 999, loss 0.60022135
iteration 1000, loss 0.46711593
iteration 1001, loss 0.70316984
iteration 1002, loss 0.47079006
iteration 1003, loss 0.67273430
iteration 1004, loss 0.61522404
iteration 1005, loss 0.51988246
iteration 1006, loss 0.49542310
iteration 1007, loss 0.47952564
iteration 1008, loss 0.54299777
iteration 1009, loss 0.50181585
iteration 1010, loss 0.49234327
iteration 1011, loss 0.55087996
iteration 1012, loss 0.58228085
iteration 1013, loss 0.46650264
iteration 1014, loss 0.54955488
iteration 1015, loss 0.52218690
iteration 1016, loss 0.60246428
iteration 1017, loss 0.58334562
iteration 1018, loss 0.49732201
iteration 1019, loss 0.52738113
iteration 1020, loss 0.50426442
iteration 1021, loss 0.44941071
iteration 1022, loss 0.54603382
iteration 1023, loss 0.53143588
iteration 1024, loss 0.59460462
iteration 1025, loss 0.70549898
iteration 1026, loss 0.52933298
iteration 1027, loss 0.46218458
iteration 1028, loss 0.54334082
iteration 1029, loss 0.55048026
iteration 1030, loss 0.58229523
iteration 1031, loss 0.50137743
iteration 1032, loss 0.47560936
iteration 1033, loss 0.53517375
iteration 1034, loss 0.52299302
iteration 1035, loss 0.50389016
iteration 1036, loss 0.49214495
iteration 1037, loss 0.46721228
iteration 1038, loss 0.55930082
iteration 1039, loss 0.54579628
iteration 1040, loss 0.50777513
iteration 1041, loss 0.49098907
iteration 1042, loss 0.50932477
iteration 1043, loss 0.68482901
iteration 1044, loss 0.49703522
iteration 1045, loss 0.61642978
iteration 1046, loss 0.55925713
iteration 1047, loss 0.58100191
iteration 1048, loss 0.46584841
iteration 1049, loss 0.53352461
iteration 1050, loss 0.49766046
iteration 1051, loss 0.56118623
iteration 1052, loss 0.49311469
iteration 1053, loss 0.46763513
iteration 1054, loss 0.53087085
iteration 1055, loss 0.52323330
iteration 1056, loss 0.54180208
iteration 1057, loss 0.71585384
iteration 1058, loss 0.58916005
iteration 1059, loss 0.51426129
iteration 1060, loss 0.56735317
iteration 1061, loss 0.46473901
iteration 1062, loss 0.52376618
iteration 1063, loss 0.48532528
iteration 1064, loss 0.48350727
iteration 1065, loss 0.47671665
iteration 1066, loss 0.59915553
iteration 1067, loss 0.47283321
iteration 1068, loss 0.50756648
iteration 1069, loss 0.59499172
iteration 1070, loss 0.49016937
iteration 1071, loss 0.51277817
iteration 1072, loss 0.51602913
iteration 1073, loss 0.46175212
iteration 1074, loss 0.54446201
iteration 1075, loss 0.70438254
iteration 1076, loss 0.49925017
iteration 1077, loss 0.44294339
iteration 1078, loss 0.62857927
iteration 1079, loss 0.47686813
iteration 1080, loss 0.56180091
iteration 1081, loss 0.48951408
iteration 1082, loss 0.54475013
iteration 1083, loss 0.50985647
iteration 1084, loss 0.50686099
iteration 1085, loss 0.49808039
iteration 1086, loss 0.50545459
iteration 1087, loss 0.49506583
iteration 1088, loss 0.53157139
iteration 1089, loss 0.56776456
iteration 1090, loss 0.56957323
iteration 1091, loss 0.50627321
iteration 1092, loss 0.61866484
iteration 1093, loss 0.57909012
iteration 1094, loss 0.43911929
iteration 1095, loss 0.51374976
iteration 1096, loss 0.54967840
iteration 1097, loss 0.50185914
iteration 1098, loss 0.45546453
iteration 1099, loss 0.55905402
iteration 1100, loss 0.48909066
iteration 1101, loss 0.50615849
iteration 1102, loss 0.49875715
iteration 1103, loss 0.52928094
iteration 1104, loss 0.51553224
iteration 1105, loss 0.48603621
iteration 1106, loss 0.51280518
iteration 1107, loss 0.50579560
iteration 1108, loss 0.48311346
iteration 1109, loss 0.51877740
iteration 1110, loss 0.48881904
iteration 1111, loss 0.48715307
iteration 1112, loss 0.51192759
iteration 1113, loss 0.48530906
iteration 1114, loss 0.48758368
iteration 1115, loss 0.49773048
iteration 1116, loss 0.53929030
iteration 1117, loss 0.67040775
iteration 1118, loss 0.51037986
iteration 1119, loss 0.60105556
iteration 1120, loss 0.48531843
iteration 1121, loss 0.65353334
iteration 1122, loss 0.58576754
iteration 1123, loss 0.51672476
iteration 1124, loss 0.48945445
iteration 1125, loss 0.56534856
iteration 1126, loss 0.51530526
iteration 1127, loss 0.54350341
iteration 1128, loss 0.57801068
iteration 1129, loss 0.48421359
iteration 1130, loss 0.63284579
iteration 1131, loss 0.60939894
iteration 1132, loss 0.58770332
iteration 1133, loss 0.48601670
iteration 1134, loss 0.55230204
iteration 1135, loss 0.52865540
iteration 1136, loss 0.60603138
iteration 1137, loss 0.47258964
iteration 1138, loss 0.48454852
iteration 1139, loss 0.54259364
iteration 1140, loss 0.58859243
iteration 1141, loss 0.56001958
iteration 1142, loss 0.51488557
iteration 1143, loss 0.47226498
iteration 1144, loss 0.48286691
iteration 1145, loss 0.63949944
iteration 1146, loss 0.47607161
iteration 1147, loss 0.44183610
iteration 1148, loss 0.53601711
iteration 1149, loss 0.51482787
iteration 1150, loss 0.51738271
iteration 1151, loss 0.48828960
iteration 1152, loss 0.43014225
iteration 1153, loss 0.59678410
iteration 1154, loss 0.51861125
iteration 1155, loss 0.60134887
iteration 1156, loss 0.51947016
iteration 1157, loss 0.36665575
iteration 1158, loss 0.63578584
iteration 1159, loss 0.76852123
iteration 1160, loss 0.50384771
iteration 1161, loss 0.56285500
iteration 1162, loss 0.57295710
iteration 1163, loss 0.49036520
iteration 1164, loss 0.60982490
iteration 1165, loss 0.53192883
iteration 1166, loss 0.50118180
iteration 1167, loss 0.50328616
iteration 1168, loss 0.52974681
iteration 1169, loss 0.48354416
iteration 1170, loss 0.59027702
iteration 1171, loss 0.56411500
iteration 1172, loss 0.64439525
iteration 1173, loss 0.48160934
iteration 1174, loss 0.51885102
iteration 1175, loss 0.50411180
iteration 1176, loss 0.49844571
iteration 1177, loss 0.69885542
iteration 1178, loss 0.79275372
iteration 1179, loss 0.57329264
iteration 1180, loss 0.56455774
iteration 1181, loss 0.49545098
iteration 1182, loss 0.52453717
iteration 1183, loss 0.66585992
iteration 1184, loss 0.50595140
iteration 1185, loss 0.58108424
iteration 1186, loss 0.60183925
iteration 1187, loss 0.48968372
iteration 1188, loss 0.46048431
iteration 1189, loss 0.51620883
iteration 1190, loss 0.50794355
iteration 1191, loss 0.48748650
iteration 1192, loss 0.47086852
iteration 1193, loss 0.48128353
iteration 1194, loss 0.59885324
iteration 1195, loss 0.46226548
iteration 1196, loss 0.71325193
iteration 1197, loss 0.46133307
iteration 1198, loss 0.56333270
iteration 1199, loss 0.55684637
iteration 1200, loss 0.52643399
iteration 1201, loss 0.49672656
iteration 1202, loss 0.51254741
iteration 1203, loss 0.51956447
iteration 1204, loss 0.54486442
iteration 1205, loss 0.50089594
iteration 1206, loss 0.53857824
iteration 1207, loss 0.46528561
iteration 1208, loss 0.50402556
iteration 1209, loss 0.58627084
iteration 1210, loss 0.47239335
iteration 1211, loss 0.46686677
iteration 1212, loss 0.53685185
iteration 1213, loss 0.61739931
iteration 1214, loss 0.56308824
iteration 1215, loss 0.48766828
iteration 1216, loss 0.50194398
iteration 1217, loss 0.50542786
iteration 1218, loss 0.52447295
iteration 1219, loss 0.49106368
iteration 1220, loss 0.49853441
iteration 1221, loss 0.53272780
iteration 1222, loss 0.49971355
iteration 1223, loss 0.47455473
iteration 1224, loss 0.53572230
iteration 1225, loss 0.56008031
iteration 1226, loss 0.50602474
iteration 1227, loss 0.51076334
iteration 1228, loss 0.61066250
iteration 1229, loss 0.59726526
iteration 1230, loss 0.64535509
iteration 1231, loss 0.44501121
iteration 1232, loss 0.63871917
iteration 1233, loss 0.52569607
iteration 1234, loss 0.58587938
iteration 1235, loss 0.53606832
iteration 1236, loss 0.47447683
iteration 1237, loss 0.49231144
iteration 1238, loss 0.58717593
iteration 1239, loss 0.46284901
iteration 1240, loss 0.60741333
iteration 1241, loss 0.62665038
iteration 1242, loss 0.56867755
iteration 1243, loss 0.47503373
iteration 1244, loss 0.54691773
iteration 1245, loss 0.52352330
iteration 1246, loss 0.49671146
iteration 1247, loss 0.49247058
iteration 1248, loss 0.48038394
iteration 1249, loss 0.52739780
iteration 1250, loss 0.51004418
iteration 1251, loss 0.46141136
iteration 1252, loss 0.58119170
iteration 1253, loss 0.48495338
iteration 1254, loss 0.46705954
iteration 1255, loss 0.52132029
iteration 1256, loss 0.52532183
iteration 1257, loss 0.54178078
iteration 1258, loss 0.52793819
iteration 1259, loss 0.59163058
iteration 1260, loss 0.50196843
iteration 1261, loss 0.51358804
iteration 1262, loss 0.47501670
iteration 1263, loss 0.49372223
iteration 1264, loss 0.51259528
iteration 1265, loss 0.47898233
iteration 1266, loss 0.51374686
iteration 1267, loss 0.57512688
iteration 1268, loss 0.53741415
iteration 1269, loss 0.42348303
iteration 1270, loss 0.54522641
iteration 1271, loss 0.59327233
iteration 1272, loss 0.58785175
iteration 1273, loss 0.48533173
iteration 1274, loss 0.48576470
iteration 1275, loss 0.53034854
iteration 1276, loss 0.48302235
iteration 1277, loss 0.57643808
iteration 1278, loss 0.48496054
iteration 1279, loss 0.54721144
iteration 1280, loss 0.54290838
iteration 1281, loss 0.46441381
iteration 1282, loss 0.50602870
iteration 1283, loss 0.49335024
iteration 1284, loss 0.50440133
iteration 1285, loss 0.53248102
iteration 1286, loss 0.61197151
iteration 1287, loss 0.54307378
iteration 1288, loss 0.58389421
iteration 1289, loss 0.58793360
iteration 1290, loss 0.61493748
iteration 1291, loss 0.45484813
iteration 1292, loss 0.52922423
iteration 1293, loss 0.53051883
iteration 1294, loss 0.51621269
iteration 1295, loss 0.51851845
iteration 1296, loss 0.55084557
iteration 1297, loss 0.65329203
iteration 1298, loss 0.57793443
iteration 1299, loss 0.60554572
iteration 1300, loss 0.61625894
iteration 1301, loss 0.51750509
iteration 1302, loss 0.49965592
iteration 1303, loss 0.48927811
iteration 1304, loss 0.48915580
iteration 1305, loss 0.49545938
iteration 1306, loss 0.47414195
iteration 1307, loss 0.50406266
iteration 1308, loss 0.48273605
iteration 1309, loss 0.54091119
iteration 1310, loss 0.57631388
iteration 1311, loss 0.47508412
iteration 1312, loss 0.50886817
iteration 1313, loss 0.48263803
iteration 1314, loss 0.52240923
iteration 1315, loss 0.46339150
iteration 1316, loss 0.52793593
iteration 1317, loss 0.46743471
iteration 1318, loss 0.51913450
iteration 1319, loss 0.53501953
iteration 1320, loss 0.55463683
iteration 1321, loss 0.49334172
iteration 1322, loss 0.57950258
iteration 1323, loss 0.55279951
iteration 1324, loss 0.68426999
iteration 1325, loss 0.52475459
iteration 1326, loss 0.57246592
iteration 1327, loss 0.50596613
iteration 1328, loss 0.57837933
iteration 1329, loss 0.45136717
iteration 1330, loss 0.50386069
iteration 1331, loss 0.55352104
iteration 1332, loss 0.48674267
iteration 1333, loss 0.55116986
iteration 1334, loss 0.49190111
iteration 1335, loss 0.52501958
iteration 1336, loss 0.51212460
iteration 1337, loss 0.48273548
iteration 1338, loss 0.54271560
iteration 1339, loss 0.45606078
iteration 1340, loss 0.58475126
iteration 1341, loss 0.60917675
iteration 1342, loss 0.55126637
iteration 1343, loss 0.44642660
iteration 1344, loss 0.49040648
iteration 1345, loss 0.63251448
iteration 1346, loss 0.53448282
iteration 1347, loss 0.45507550
iteration 1348, loss 0.54294948
iteration 1349, loss 0.51345402
iteration 1350, loss 0.46697424
iteration 1351, loss 0.51729823
iteration 1352, loss 0.54371447
iteration 1353, loss 0.52433041
iteration 1354, loss 0.49615376
iteration 1355, loss 0.49539857
iteration 1356, loss 0.55692758
iteration 1357, loss 0.59465561
iteration 1358, loss 0.65612398
iteration 1359, loss 0.52592209
iteration 1360, loss 0.47221844
iteration 1361, loss 0.57018822
iteration 1362, loss 0.49998688
iteration 1363, loss 0.60148228
iteration 1364, loss 0.53755220
iteration 1365, loss 0.44737881
iteration 1366, loss 0.55618520
iteration 1367, loss 0.49120315
iteration 1368, loss 0.64913295
iteration 1369, loss 0.62973905
iteration 1370, loss 0.58740466
iteration 1371, loss 0.48197178
iteration 1372, loss 0.51637060
iteration 1373, loss 0.50204250
iteration 1374, loss 0.59334569
iteration 1375, loss 0.62625278
iteration 1376, loss 0.56863901
iteration 1377, loss 0.54054711
iteration 1378, loss 0.72791049
iteration 1379, loss 0.49670789
iteration 1380, loss 0.59198862
iteration 1381, loss 0.60430080
iteration 1382, loss 0.51126515
iteration 1383, loss 0.50302076
iteration 1384, loss 0.61273376
iteration 1385, loss 0.46151575
iteration 1386, loss 0.49655487
iteration 1387, loss 0.52983213
iteration 1388, loss 0.56046395
iteration 1389, loss 0.54762042
iteration 1390, loss 0.48817709
iteration 1391, loss 0.51902543
iteration 1392, loss 0.59203361
iteration 1393, loss 0.54091517
iteration 1394, loss 0.46970265
iteration 1395, loss 0.46038515
iteration 1396, loss 0.56578865
iteration 1397, loss 0.56750764
iteration 1398, loss 0.47749709
iteration 1399, loss 0.48751914
iteration 1400, loss 0.57698443
iteration 1401, loss 0.46351319
iteration 1402, loss 0.48303644
iteration 1403, loss 0.52775817
iteration 1404, loss 0.51282936
iteration 1405, loss 0.52960896
iteration 1406, loss 0.49062300
iteration 1407, loss 0.52601917
iteration 1408, loss 0.52725758
iteration 1409, loss 0.55230065
iteration 1410, loss 0.56266877
iteration 1411, loss 0.51710192
iteration 1412, loss 0.49333218
iteration 1413, loss 0.62483102
iteration 1414, loss 0.69255000
iteration 1415, loss 0.57593293
iteration 1416, loss 0.43872024
iteration 1417, loss 0.49871167
iteration 1418, loss 0.69972480
iteration 1419, loss 0.55443330
iteration 1420, loss 0.49048102
iteration 1421, loss 0.45434385
iteration 1422, loss 0.51321201
iteration 1423, loss 0.51762847
iteration 1424, loss 0.48804140
iteration 1425, loss 0.48913090
iteration 1426, loss 0.58374146
iteration 1427, loss 0.51814183
iteration 1428, loss 0.53552680
iteration 1429, loss 0.54633484
iteration 1430, loss 0.68911716
iteration 1431, loss 0.59701399
iteration 1432, loss 0.47405345
iteration 1433, loss 0.49838342
iteration 1434, loss 0.46968849
iteration 1435, loss 0.60729431
iteration 1436, loss 0.43612129
iteration 1437, loss 0.43603130
iteration 1438, loss 0.50757479
iteration 1439, loss 0.48509263
iteration 1440, loss 0.50932452
iteration 1441, loss 0.53223646
iteration 1442, loss 0.47941873
iteration 1443, loss 0.62668933
iteration 1444, loss 0.47171984
iteration 1445, loss 0.58843712
iteration 1446, loss 0.49047791
iteration 1447, loss 0.75427009
iteration 1448, loss 0.48604086
iteration 1449, loss 0.53513043
iteration 1450, loss 0.55584638
iteration 1451, loss 0.58763640
iteration 1452, loss 0.57015464
iteration 1453, loss 0.46323344
iteration 1454, loss 0.52869337
iteration 1455, loss 0.51221481
iteration 1456, loss 0.49910874
iteration 1457, loss 0.54216242
iteration 1458, loss 0.57116763
iteration 1459, loss 0.45126916
iteration 1460, loss 0.53899477
iteration 1461, loss 0.59836952
iteration 1462, loss 0.57165482
iteration 1463, loss 0.47718629
iteration 1464, loss 0.48308246
iteration 1465, loss 0.51142822
iteration 1466, loss 0.47747520
iteration 1467, loss 0.61192600
iteration 1468, loss 0.55348488
iteration 1469, loss 0.59839637
iteration 1470, loss 0.49910191
iteration 1471, loss 0.50896682
iteration 1472, loss 0.50355481
iteration 1473, loss 0.51907752
iteration 1474, loss 0.48976254
iteration 1475, loss 0.52902311
iteration 1476, loss 0.54092383
iteration 1477, loss 0.48249692
iteration 1478, loss 0.54215684
iteration 1479, loss 0.49298278
iteration 1480, loss 0.54675207
iteration 1481, loss 0.44791205
iteration 1482, loss 0.54635087
iteration 1483, loss 0.49073670
iteration 1484, loss 0.49508082
iteration 1485, loss 0.54620494
iteration 1486, loss 0.50527159
iteration 1487, loss 0.51259933
iteration 1488, loss 0.57990424
iteration 1489, loss 0.48772708
iteration 1490, loss 0.47201499
iteration 1491, loss 0.50764390
iteration 1492, loss 0.58867918
iteration 1493, loss 0.49960758
iteration 1494, loss 0.48770863
iteration 1495, loss 0.51727503
iteration 1496, loss 0.44094059
iteration 1497, loss 0.56782045
iteration 1498, loss 0.48137553
iteration 1499, loss 0.52226073
iteration 1500, loss 0.51053830
iteration 1501, loss 0.55447636
iteration 1502, loss 0.44788233
iteration 1503, loss 0.63541034
iteration 1504, loss 0.58252779
iteration 1505, loss 0.56009884
iteration 1506, loss 0.53566575
iteration 1507, loss 0.53332397
iteration 1508, loss 0.48537830
iteration 1509, loss 0.51599769
iteration 1510, loss 0.52063043
iteration 1511, loss 0.52626137
iteration 1512, loss 0.46511247
iteration 1513, loss 0.52760242
iteration 1514, loss 0.51488157
iteration 1515, loss 0.55690389
iteration 1516, loss 0.47937746
iteration 1517, loss 0.59250375
iteration 1518, loss 0.47333024
iteration 1519, loss 0.47899564
iteration 1520, loss 0.51011655
iteration 1521, loss 0.58674823
iteration 1522, loss 0.49070292
iteration 1523, loss 0.52958852
iteration 1524, loss 0.55457942
iteration 1525, loss 0.52755533
iteration 1526, loss 0.47898821
iteration 1527, loss 0.49790398
iteration 1528, loss 0.50408580
iteration 1529, loss 0.53017156
iteration 1530, loss 0.57305231
iteration 1531, loss 0.62986711
iteration 1532, loss 0.53619664
iteration 1533, loss 0.63203004
iteration 1534, loss 0.44840077
iteration 1535, loss 0.48924009
iteration 1536, loss 0.53844122
iteration 1537, loss 0.48415778
iteration 1538, loss 0.57334076
iteration 1539, loss 0.48811630
iteration 1540, loss 0.47626503
iteration 1541, loss 0.52341549
iteration 1542, loss 0.49147599
iteration 1543, loss 0.51174131
iteration 1544, loss 0.50344173
iteration 1545, loss 0.49698662
iteration 1546, loss 0.44548335
iteration 1547, loss 0.55236549
iteration 1548, loss 0.50609869
iteration 1549, loss 0.56188080
iteration 1550, loss 0.41608203
iteration 1551, loss 0.51313092
iteration 1552, loss 0.49462086
iteration 1553, loss 0.47118527
iteration 1554, loss 0.55722906
iteration 1555, loss 0.54157326
iteration 1556, loss 0.50493940
iteration 1557, loss 0.52026543
iteration 1558, loss 0.48997117
iteration 1559, loss 0.52558530
iteration 1560, loss 0.48936567
iteration 1561, loss 0.48917702
iteration 1562, loss 0.51298754
iteration 1563, loss 0.55025357
iteration 1564, loss 0.58958902
iteration 1565, loss 0.57821411
iteration 1566, loss 0.51231799
iteration 1567, loss 0.62139385
iteration 1568, loss 0.49767040
iteration 1569, loss 0.47132080
iteration 1570, loss 0.50946928
iteration 1571, loss 0.61859024
iteration 1572, loss 0.65459518
iteration 1573, loss 0.50208610
iteration 1574, loss 0.61400003
iteration 1575, loss 0.47731273
iteration 1576, loss 0.50366112
iteration 1577, loss 0.51248395
iteration 1578, loss 0.54119150
iteration 1579, loss 0.49522496
iteration 1580, loss 0.49651848
iteration 1581, loss 0.46953825
iteration 1582, loss 0.53538316
iteration 1583, loss 0.47435058
iteration 1584, loss 0.49002632
iteration 1585, loss 0.52155547
iteration 1586, loss 0.54381942
iteration 1587, loss 0.51013132
iteration 1588, loss 0.55924384
iteration 1589, loss 0.45347811
iteration 1590, loss 0.52560032
iteration 1591, loss 0.51791454
iteration 1592, loss 0.53139016
iteration 1593, loss 0.45412148
iteration 1594, loss 0.42237908
iteration 1595, loss 0.49291470
iteration 1596, loss 0.56188561
iteration 1597, loss 0.47779901
iteration 1598, loss 0.50019432
iteration 1599, loss 0.41208499
iteration 1600, loss 0.55069101
iteration 1601, loss 0.63196239
iteration 1602, loss 0.51543131
iteration 1603, loss 0.45060515
iteration 1604, loss 0.51167320
iteration 1605, loss 0.57186422
iteration 1606, loss 0.51894693
iteration 1607, loss 0.46940066
iteration 1608, loss 0.49514546
iteration 1609, loss 0.61206498
iteration 1610, loss 0.46742639
iteration 1611, loss 0.48871669
iteration 1612, loss 0.53869801
iteration 1613, loss 0.53694669
iteration 1614, loss 0.60266392
iteration 1615, loss 0.52910847
iteration 1616, loss 0.50076764
iteration 1617, loss 0.56120780
iteration 1618, loss 0.63197800
iteration 1619, loss 0.56217108
iteration 1620, loss 0.51752289
iteration 1621, loss 0.50935234
iteration 1622, loss 0.49695032
iteration 1623, loss 0.48359795
iteration 1624, loss 0.53349490
iteration 1625, loss 0.58938768
iteration 1626, loss 0.45953829
iteration 1627, loss 0.56917228
iteration 1628, loss 0.57926304
iteration 1629, loss 0.53976146
iteration 1630, loss 0.75507879
iteration 1631, loss 0.87548030
iteration 1632, loss 0.72169980
iteration 1633, loss 0.52338765
iteration 1634, loss 0.43416585
iteration 1635, loss 0.60034267
iteration 1636, loss 0.54243383
iteration 1637, loss 0.46704470
iteration 1638, loss 0.56259213
iteration 1639, loss 0.60437011
iteration 1640, loss 0.43817551
iteration 1641, loss 0.50326515
iteration 1642, loss 0.54379251
iteration 1643, loss 0.50129080
iteration 1644, loss 0.46236249
iteration 1645, loss 0.53199535
iteration 1646, loss 0.52829476
iteration 1647, loss 0.54314039
iteration 1648, loss 0.50711631
iteration 1649, loss 0.50466301
iteration 1650, loss 0.47006309
iteration 1651, loss 0.57925112
iteration 1652, loss 0.51639937
iteration 1653, loss 0.45836526
iteration 1654, loss 0.51479348
iteration 1655, loss 0.47026462
iteration 1656, loss 0.53468414
iteration 1657, loss 0.48653127
iteration 1658, loss 0.47372306
iteration 1659, loss 0.51083406
iteration 1660, loss 0.48871002
iteration 1661, loss 0.49363595
iteration 1662, loss 0.53456352
iteration 1663, loss 0.51517985
iteration 1664, loss 0.52331582
iteration 1665, loss 0.47168750
iteration 1666, loss 0.47573319
iteration 1667, loss 0.55712789
iteration 1668, loss 0.61417436
iteration 1669, loss 0.82330296
iteration 1670, loss 0.45778739
iteration 1671, loss 0.45056181
iteration 1672, loss 0.52537335
iteration 1673, loss 0.51992047
iteration 1674, loss 0.52476020
iteration 1675, loss 0.34372933
iteration 1676, loss 0.49122257
iteration 1677, loss 0.52255040
iteration 1678, loss 0.71053830
iteration 1679, loss 0.38619752
iteration 1680, loss 0.61527896
iteration 1681, loss 0.72521005
iteration 1682, loss 0.61860948
iteration 1683, loss 0.76871460
iteration 1684, loss 0.42185726
iteration 1685, loss 0.67013101
iteration 1686, loss 0.67302047
iteration 1687, loss 0.46224661
iteration 1688, loss 0.50832364
iteration 1689, loss 0.51836167
iteration 1690, loss 0.49386587
iteration 1691, loss 0.52162731
iteration 1692, loss 0.48147886
iteration 1693, loss 0.53691485
iteration 1694, loss 0.62688230
iteration 1695, loss 0.52426381
iteration 1696, loss 0.49907778
iteration 1697, loss 0.53819920
iteration 1698, loss 0.62116564
iteration 1699, loss 0.59286657
iteration 1700, loss 0.41499333
iteration 1701, loss 0.63937389
iteration 1702, loss 0.60643025
iteration 1703, loss 0.72540510
iteration 1704, loss 0.46012408
iteration 1705, loss 0.50400622
iteration 1706, loss 0.56177606
iteration 1707, loss 0.48082993
iteration 1708, loss 0.47229164
iteration 1709, loss 0.48761790
iteration 1710, loss 0.46776616
iteration 1711, loss 0.49256425
iteration 1712, loss 0.49061541
iteration 1713, loss 0.52513018
iteration 1714, loss 0.51615916
iteration 1715, loss 0.50026401
iteration 1716, loss 0.50583777
iteration 1717, loss 0.49012650
iteration 1718, loss 0.52453472
iteration 1719, loss 0.52464704
iteration 1720, loss 0.48451336
iteration 1721, loss 0.54569388
iteration 1722, loss 0.48465317
iteration 1723, loss 0.57288377
iteration 1724, loss 0.52390268
iteration 1725, loss 0.51921026
iteration 1726, loss 0.51573667
iteration 1727, loss 0.44249512
iteration 1728, loss 0.52650365
iteration 1729, loss 0.52020038
iteration 1730, loss 0.52235459
iteration 1731, loss 0.49647545
iteration 1732, loss 0.52121546
iteration 1733, loss 0.50728028
iteration 1734, loss 0.50387484
iteration 1735, loss 0.56756912
iteration 1736, loss 0.57969385
iteration 1737, loss 0.59668523
iteration 1738, loss 0.47900648
iteration 1739, loss 0.52312834
iteration 1740, loss 0.50247412
iteration 1741, loss 0.55887896
iteration 1742, loss 0.51805936
iteration 1743, loss 0.50646405
iteration 1744, loss 0.68037927
iteration 1745, loss 0.51471975
iteration 1746, loss 0.70667433
iteration 1747, loss 0.53799801
iteration 1748, loss 0.55281852
iteration 1749, loss 0.57272604
iteration 1750, loss 0.50845338
iteration 1751, loss 0.49136525
iteration 1752, loss 0.52214961
iteration 1753, loss 0.48984821
iteration 1754, loss 0.50402216
iteration 1755, loss 0.54844371
iteration 1756, loss 0.54158700
iteration 1757, loss 0.57670875
iteration 1758, loss 0.46463098
iteration 1759, loss 0.49070129
iteration 1760, loss 0.47332528
iteration 1761, loss 0.53452064
iteration 1762, loss 0.50250720
iteration 1763, loss 0.53113699
iteration 1764, loss 0.53573086
iteration 1765, loss 0.50112810
iteration 1766, loss 0.50853624
iteration 1767, loss 0.50294339
iteration 1768, loss 0.49197489
iteration 1769, loss 0.59879802
iteration 1770, loss 0.45538091
iteration 1771, loss 0.55244815
iteration 1772, loss 0.54877333
iteration 1773, loss 0.51328835
iteration 1774, loss 0.63745790
iteration 1775, loss 0.55673158
iteration 1776, loss 0.63843598
iteration 1777, loss 0.49979459
iteration 1778, loss 0.59371777
iteration 1779, loss 0.76836086
iteration 1780, loss 0.67903445
iteration 1781, loss 0.60740738
iteration 1782, loss 0.45248477
iteration 1783, loss 0.50040646
iteration 1784, loss 0.60435102
iteration 1785, loss 0.49845782
iteration 1786, loss 0.59770817
iteration 1787, loss 0.50017599
iteration 1788, loss 0.51080819
iteration 1789, loss 0.51753364
iteration 1790, loss 0.53355974
iteration 1791, loss 0.46421785
iteration 1792, loss 0.49795217
iteration 1793, loss 0.53346334
iteration 1794, loss 0.52262521
iteration 1795, loss 0.49867127
iteration 1796, loss 0.48939706
iteration 1797, loss 0.50783455
iteration 1798, loss 0.55173404
iteration 1799, loss 0.48900896
iteration 1800, loss 0.68291594
iteration 1801, loss 0.63294198
iteration 1802, loss 0.56007593
iteration 1803, loss 0.50092006
iteration 1804, loss 0.50112236
iteration 1805, loss 0.63952142
iteration 1806, loss 0.48789003
iteration 1807, loss 0.48697075
iteration 1808, loss 0.54703698
iteration 1809, loss 0.40256266
iteration 1810, loss 0.54222692
iteration 1811, loss 0.53674610
iteration 1812, loss 0.54054908
iteration 1813, loss 0.52950541
iteration 1814, loss 0.59536993
iteration 1815, loss 0.54253463
iteration 1816, loss 0.50073994
iteration 1817, loss 0.52039828
iteration 1818, loss 0.49059851
iteration 1819, loss 0.51700141
iteration 1820, loss 0.50993044
iteration 1821, loss 0.52759587
iteration 1822, loss 0.48529013
iteration 1823, loss 0.50513556
iteration 1824, loss 0.60225614
iteration 1825, loss 0.45867091
iteration 1826, loss 0.75030654
iteration 1827, loss 0.48437989
iteration 1828, loss 0.57728900
iteration 1829, loss 0.57728584
iteration 1830, loss 0.49576862
iteration 1831, loss 0.51348198
iteration 1832, loss 0.50027812
iteration 1833, loss 0.52200852
iteration 1834, loss 0.49289508
iteration 1835, loss 0.48519289
iteration 1836, loss 0.47708646
iteration 1837, loss 0.51597856
iteration 1838, loss 0.48212855
iteration 1839, loss 0.49191280
iteration 1840, loss 0.48153755
iteration 1841, loss 0.47332700
iteration 1842, loss 0.47839234
iteration 1843, loss 0.53400540
iteration 1844, loss 0.49970496
iteration 1845, loss 0.64469943
iteration 1846, loss 0.61396347
iteration 1847, loss 0.59677639
iteration 1848, loss 0.56208995
iteration 1849, loss 0.45660065
iteration 1850, loss 0.54387691
iteration 1851, loss 0.57349410
iteration 1852, loss 0.46036544
iteration 1853, loss 0.54977584
iteration 1854, loss 0.63984056
iteration 1855, loss 0.54922111
iteration 1856, loss 0.54204198
iteration 1857, loss 0.50049481
iteration 1858, loss 0.49291525
iteration 1859, loss 0.51524702
iteration 1860, loss 0.53437502
iteration 1861, loss 0.42581661
iteration 1862, loss 0.55928864
iteration 1863, loss 0.57250879
iteration 1864, loss 0.49557554
iteration 1865, loss 0.61797047
iteration 1866, loss 0.42114033
iteration 1867, loss 0.61853761
iteration 1868, loss 0.58906524
iteration 1869, loss 0.54878751
iteration 1870, loss 0.45151225
iteration 1871, loss 0.52316880
iteration 1872, loss 0.57024091
iteration 1873, loss 0.55886848
iteration 1874, loss 0.60737749
iteration 1875, loss 0.57331628
iteration 1876, loss 0.48739995
iteration 1877, loss 0.55238406
iteration 1878, loss 0.57936252
iteration 1879, loss 0.54809963
iteration 1880, loss 0.49657708
iteration 1881, loss 0.53513194
iteration 1882, loss 0.61300719
iteration 1883, loss 0.57169207
iteration 1884, loss 0.50328907
iteration 1885, loss 0.54849852
iteration 1886, loss 0.49472071
iteration 1887, loss 0.49892473
iteration 1888, loss 0.51828603
iteration 1889, loss 0.46046112
iteration 1890, loss 0.55750384
iteration 1891, loss 0.59912463
iteration 1892, loss 0.52911724
iteration 1893, loss 0.69938589
iteration 1894, loss 0.48851441
iteration 1895, loss 0.60182018
iteration 1896, loss 0.67976912
iteration 1897, loss 0.53304850
iteration 1898, loss 0.45145041
iteration 1899, loss 0.64299648
iteration 1900, loss 0.51387433
iteration 1901, loss 0.48618344
iteration 1902, loss 0.55190319
iteration 1903, loss 0.60107529
iteration 1904, loss 0.51839441
iteration 1905, loss 0.49016549
iteration 1906, loss 0.50643133
iteration 1907, loss 0.50553552
iteration 1908, loss 0.63369072
iteration 1909, loss 0.40704238
iteration 1910, loss 0.51177478
iteration 1911, loss 0.51037159
iteration 1912, loss 0.54773858
iteration 1913, loss 0.48707700
iteration 1914, loss 0.49294681
iteration 1915, loss 0.53942496
iteration 1916, loss 0.50912938
iteration 1917, loss 0.54865073
iteration 1918, loss 0.50552828
iteration 1919, loss 0.51054278
iteration 1920, loss 0.51797547
iteration 1921, loss 0.52707094
iteration 1922, loss 0.52973532
iteration 1923, loss 0.48577384
iteration 1924, loss 0.49640495
iteration 1925, loss 0.54699498
iteration 1926, loss 0.54027913
iteration 1927, loss 0.51961353
iteration 1928, loss 0.51944967
iteration 1929, loss 0.47956240
iteration 1930, loss 0.50991543
iteration 1931, loss 0.47747680
iteration 1932, loss 0.47975622
iteration 1933, loss 0.46626638
iteration 1934, loss 0.49056811
iteration 1935, loss 0.52672687
iteration 1936, loss 0.48887648
iteration 1937, loss 0.49640782
iteration 1938, loss 0.55320945
iteration 1939, loss 0.52800054
iteration 1940, loss 0.52304476
iteration 1941, loss 0.50701702
iteration 1942, loss 0.47718164
iteration 1943, loss 0.56863232
iteration 1944, loss 0.48263203
iteration 1945, loss 0.52537307
iteration 1946, loss 0.52349950
iteration 1947, loss 0.52939003
iteration 1948, loss 0.52116329
iteration 1949, loss 0.53353131
iteration 1950, loss 0.42825381
iteration 1951, loss 0.50560533
iteration 1952, loss 0.56685554
iteration 1953, loss 0.40948579
iteration 1954, loss 0.49675262
iteration 1955, loss 0.62290236
iteration 1956, loss 0.48394467
iteration 1957, loss 0.54226318
iteration 1958, loss 0.54819262
iteration 1959, loss 0.47811885
iteration 1960, loss 0.50371673
iteration 1961, loss 0.52098729
iteration 1962, loss 0.47588057
iteration 1963, loss 0.48096578
iteration 1964, loss 0.56625866
iteration 1965, loss 0.47757448
iteration 1966, loss 0.50992684
iteration 1967, loss 0.51143276
iteration 1968, loss 0.54308176
iteration 1969, loss 0.58432318
iteration 1970, loss 0.51565561
iteration 1971, loss 0.57655083
iteration 1972, loss 0.47559814
iteration 1973, loss 0.53670736
iteration 1974, loss 0.55392509
iteration 1975, loss 0.51549576
iteration 1976, loss 0.47456698
iteration 1977, loss 0.48853829
iteration 1978, loss 0.52582292
iteration 1979, loss 0.49082627
iteration 1980, loss 0.46651843
iteration 1981, loss 0.53893907
iteration 1982, loss 0.52682780
iteration 1983, loss 0.49497722
iteration 1984, loss 0.49292559
iteration 1985, loss 0.46359110
iteration 1986, loss 0.51677946
iteration 1987, loss 0.57638225
iteration 1988, loss 0.48681450
iteration 1989, loss 0.60354066
iteration 1990, loss 0.52293052
iteration 1991, loss 0.60600119
iteration 1992, loss 0.47657332
iteration 1993, loss 0.55126820
iteration 1994, loss 0.53535014
iteration 1995, loss 0.53393632
iteration 1996, loss 0.75439291
iteration 1997, loss 0.55418062
iteration 1998, loss 0.59292662
iteration 1999, loss 0.51504929
iteration 2000, loss 0.49479361
iteration 2001, loss 0.48701341
iteration 2002, loss 0.55658904
iteration 2003, loss 0.46897621
iteration 2004, loss 0.66335449
iteration 2005, loss 0.50288270
iteration 2006, loss 0.65985722
iteration 2007, loss 0.57141719
iteration 2008, loss 0.47289560
iteration 2009, loss 0.52055750
iteration 2010, loss 0.62282140
iteration 2011, loss 0.72511231
iteration 2012, loss 0.54695642
iteration 2013, loss 0.52310484
iteration 2014, loss 0.52456780
iteration 2015, loss 0.57691168
iteration 2016, loss 0.43154998
iteration 2017, loss 0.48394570
iteration 2018, loss 0.58480247
iteration 2019, loss 0.45986765
iteration 2020, loss 0.60958334
iteration 2021, loss 0.62129747
iteration 2022, loss 0.51232791
iteration 2023, loss 0.65083178
iteration 2024, loss 0.71510893
iteration 2025, loss 0.73862157
iteration 2026, loss 0.53089644
iteration 2027, loss 0.57004072
iteration 2028, loss 0.44952388
iteration 2029, loss 0.54528101
iteration 2030, loss 0.56762259
iteration 2031, loss 0.43783232
iteration 2032, loss 0.66003430
iteration 2033, loss 0.59537012
iteration 2034, loss 0.70808206
iteration 2035, loss 0.42862361
iteration 2036, loss 0.78711436
iteration 2037, loss 0.75286057
iteration 2038, loss 0.62470757
iteration 2039, loss 0.45700974
iteration 2040, loss 0.54093990
iteration 2041, loss 0.49198361
iteration 2042, loss 0.53215492
iteration 2043, loss 0.62707347
iteration 2044, loss 0.45611106
iteration 2045, loss 0.62116945
iteration 2046, loss 0.51618587
iteration 2047, loss 0.55749200
iteration 2048, loss 0.57761191
iteration 2049, loss 0.50226886
iteration 2050, loss 0.45103761
iteration 2051, loss 0.52003595
iteration 2052, loss 0.52623503
iteration 2053, loss 0.55227200
iteration 2054, loss 0.51966086
iteration 2055, loss 0.49974426
iteration 2056, loss 0.48481807
iteration 2057, loss 0.53328707
iteration 2058, loss 0.50179165
iteration 2059, loss 0.47313627
iteration 2060, loss 0.55003823
iteration 2061, loss 0.49897331
iteration 2062, loss 0.49273809
iteration 2063, loss 0.50481575
iteration 2064, loss 0.52833923
iteration 2065, loss 0.48674374
iteration 2066, loss 0.51528382
iteration 2067, loss 0.52832502
iteration 2068, loss 0.54459144
iteration 2069, loss 0.47058444
iteration 2070, loss 0.59001900
iteration 2071, loss 0.44673869
iteration 2072, loss 0.49538021
iteration 2073, loss 0.50045076
iteration 2074, loss 0.52779294
iteration 2075, loss 0.49319057
iteration 2076, loss 0.49800835
iteration 2077, loss 0.49931351
iteration 2078, loss 0.48455469
iteration 2079, loss 0.54238725
iteration 2080, loss 0.61520862
iteration 2081, loss 0.62578157
iteration 2082, loss 0.49279413
iteration 2083, loss 0.76206906
iteration 2084, loss 1.02014099
iteration 2085, loss 0.63181583
iteration 2086, loss 0.36602448
iteration 2087, loss 0.44213258
iteration 2088, loss 0.63101474
iteration 2089, loss 0.57344759
iteration 2090, loss 0.43091223
iteration 2091, loss 0.53766910
iteration 2092, loss 0.52578263
iteration 2093, loss 0.63388712
iteration 2094, loss 0.60765028
iteration 2095, loss 0.51000233
iteration 2096, loss 0.54738431
iteration 2097, loss 0.56131762
iteration 2098, loss 0.49518038
iteration 2099, loss 0.50299883
iteration 2100, loss 0.53320468
iteration 2101, loss 0.52876551
iteration 2102, loss 0.47477622
iteration 2103, loss 0.58202281
iteration 2104, loss 0.56813487
iteration 2105, loss 0.76126110
iteration 2106, loss 0.78121272
iteration 2107, loss 0.64693704
iteration 2108, loss 0.47685761
iteration 2109, loss 0.49504913
iteration 2110, loss 0.51314489
iteration 2111, loss 0.51988994
iteration 2112, loss 0.58183743
iteration 2113, loss 0.45879552
iteration 2114, loss 0.62061352
iteration 2115, loss 0.62774220
iteration 2116, loss 0.55438170
iteration 2117, loss 0.46223384
iteration 2118, loss 0.49513569
iteration 2119, loss 0.50741813
iteration 2120, loss 0.45692089
iteration 2121, loss 0.49703048
iteration 2122, loss 0.55825897
iteration 2123, loss 0.44188364
iteration 2124, loss 0.49036835
iteration 2125, loss 0.56904994
iteration 2126, loss 0.45763980
iteration 2127, loss 0.60784638
iteration 2128, loss 0.60743370
iteration 2129, loss 0.49487441
iteration 2130, loss 0.64189290
iteration 2131, loss 0.52630357
iteration 2132, loss 0.76275285
iteration 2133, loss 0.42262813
iteration 2134, loss 0.64049543
iteration 2135, loss 0.63113074
iteration 2136, loss 0.64193911
iteration 2137, loss 0.54689627
iteration 2138, loss 0.53632424
iteration 2139, loss 0.53340670
iteration 2140, loss 0.56691321
iteration 2141, loss 0.51684280
iteration 2142, loss 0.59772868
iteration 2143, loss 0.56978220
iteration 2144, loss 0.54967845
iteration 2145, loss 0.50183569
iteration 2146, loss 0.65398514
iteration 2147, loss 0.45926349
iteration 2148, loss 0.60043632
iteration 2149, loss 0.55280267
iteration 2150, loss 0.64410412
iteration 2151, loss 0.55301462
iteration 2152, loss 0.55507701
iteration 2153, loss 0.59431267
iteration 2154, loss 0.45820026
iteration 2155, loss 0.48709808
iteration 2156, loss 0.49580995
iteration 2157, loss 0.48655869
iteration 2158, loss 0.63834371
iteration 2159, loss 0.45951540
iteration 2160, loss 0.56738375
iteration 2161, loss 0.61900970
iteration 2162, loss 0.59282930
iteration 2163, loss 0.54528197
iteration 2164, loss 0.42450038
iteration 2165, loss 0.49491518
iteration 2166, loss 0.49990655
iteration 2167, loss 0.60645221
iteration 2168, loss 0.49698552
iteration 2169, loss 0.48789508
iteration 2170, loss 0.58053557
iteration 2171, loss 0.47944867
iteration 2172, loss 0.52569944
iteration 2173, loss 0.54200118
iteration 2174, loss 0.53131899
iteration 2175, loss 0.54689301
iteration 2176, loss 0.56009782
iteration 2177, loss 0.46065528
iteration 2178, loss 0.53202644
iteration 2179, loss 0.53714289
iteration 2180, loss 0.49490815
iteration 2181, loss 0.51437959
iteration 2182, loss 0.51488601
iteration 2183, loss 0.49352193
iteration 2184, loss 0.49769414
iteration 2185, loss 0.48922579
iteration 2186, loss 0.49036335
iteration 2187, loss 0.61074938
iteration 2188, loss 0.57906754
iteration 2189, loss 0.49763615
iteration 2190, loss 0.69510562
iteration 2191, loss 0.48858455
iteration 2192, loss 0.62602333
iteration 2193, loss 0.58415986
iteration 2194, loss 0.57655696
iteration 2195, loss 0.46238413
iteration 2196, loss 0.47104191
iteration 2197, loss 0.52397290
iteration 2198, loss 0.48280834
iteration 2199, loss 0.49782860
iteration 2200, loss 0.56533847
iteration 2201, loss 0.49715868
iteration 2202, loss 0.61363170
iteration 2203, loss 0.54262627
iteration 2204, loss 0.45841662
iteration 2205, loss 0.48795226
iteration 2206, loss 0.50487290
iteration 2207, loss 0.50409842
iteration 2208, loss 0.49776487
iteration 2209, loss 0.49488220
iteration 2210, loss 0.49816660
iteration 2211, loss 0.49669703
iteration 2212, loss 0.50511393
iteration 2213, loss 0.49609014
iteration 2214, loss 0.51012085
iteration 2215, loss 0.55632145
iteration 2216, loss 0.57391950
iteration 2217, loss 0.48637194
iteration 2218, loss 0.54515309
iteration 2219, loss 0.48672745
iteration 2220, loss 0.50156081
iteration 2221, loss 0.53854934
iteration 2222, loss 0.48470250
iteration 2223, loss 0.63633680
iteration 2224, loss 0.46769296
iteration 2225, loss 0.68335720
iteration 2226, loss 0.60711934
iteration 2227, loss 0.78089251
iteration 2228, loss 0.49695754
iteration 2229, loss 0.52168912
iteration 2230, loss 0.62326315
iteration 2231, loss 0.42782078
iteration 2232, loss 0.54549441
iteration 2233, loss 0.57270410
iteration 2234, loss 0.50154523
iteration 2235, loss 0.49310852
iteration 2236, loss 0.49759109
iteration 2237, loss 0.56101596
iteration 2238, loss 0.50472431
iteration 2239, loss 0.62379778
iteration 2240, loss 0.62924369
iteration 2241, loss 0.45261023
iteration 2242, loss 0.54924123
iteration 2243, loss 0.74553472
iteration 2244, loss 0.73826777
iteration 2245, loss 0.61736375
iteration 2246, loss 0.46776469
iteration 2247, loss 0.46358097
iteration 2248, loss 0.53385213
iteration 2249, loss 0.53127958
iteration 2250, loss 0.47775914
iteration 2251, loss 0.63110460
iteration 2252, loss 0.42347625
iteration 2253, loss 0.56026036
iteration 2254, loss 0.66752367
iteration 2255, loss 0.53282726
iteration 2256, loss 0.47349782
iteration 2257, loss 0.48554063
iteration 2258, loss 0.50746539
iteration 2259, loss 0.57508933
iteration 2260, loss 0.50250741
iteration 2261, loss 0.47690492
iteration 2262, loss 0.56821089
iteration 2263, loss 0.46505377
iteration 2264, loss 0.43032781
iteration 2265, loss 0.61737373
iteration 2266, loss 0.59253632
iteration 2267, loss 0.48573856
iteration 2268, loss 0.56816687
iteration 2269, loss 0.50022750
iteration 2270, loss 0.47793382
iteration 2271, loss 0.54480613
iteration 2272, loss 0.53766888
iteration 2273, loss 0.56642959
iteration 2274, loss 0.56255019
iteration 2275, loss 0.56797617
iteration 2276, loss 0.46870166
iteration 2277, loss 0.53993962
iteration 2278, loss 0.51856497
iteration 2279, loss 0.53734276
iteration 2280, loss 0.62274915
iteration 2281, loss 0.66459085
iteration 2282, loss 0.61057210
iteration 2283, loss 0.45298469
iteration 2284, loss 0.51993971
iteration 2285, loss 0.57476591
iteration 2286, loss 0.52078521
iteration 2287, loss 0.54455164
iteration 2288, loss 0.50887320
iteration 2289, loss 0.60117062
iteration 2290, loss 0.49613356
iteration 2291, loss 0.57205518
iteration 2292, loss 0.51349131
iteration 2293, loss 0.53916695
iteration 2294, loss 0.60595689
iteration 2295, loss 0.51115573
iteration 2296, loss 0.48882185
iteration 2297, loss 0.55533448
iteration 2298, loss 0.57249693
iteration 2299, loss 0.52957895
iteration 2300, loss 0.57715018
iteration 2301, loss 0.53967442
iteration 2302, loss 0.58479046
iteration 2303, loss 0.55381441
iteration 2304, loss 0.56749191
iteration 2305, loss 0.50067389
iteration 2306, loss 0.48306834
iteration 2307, loss 0.48352594
iteration 2308, loss 0.45542197
iteration 2309, loss 0.53384481
iteration 2310, loss 0.51422508
iteration 2311, loss 0.59806084
iteration 2312, loss 0.45518649
iteration 2313, loss 0.60511617
iteration 2314, loss 0.55421776
iteration 2315, loss 0.49534672
iteration 2316, loss 0.49807179
iteration 2317, loss 0.47796568
iteration 2318, loss 0.49582701
iteration 2319, loss 0.55820999
iteration 2320, loss 0.51324016
iteration 2321, loss 0.49522089
iteration 2322, loss 0.46450469
iteration 2323, loss 0.51930838
iteration 2324, loss 0.52217417
iteration 2325, loss 0.43963181
iteration 2326, loss 0.55596623
iteration 2327, loss 0.50356063
iteration 2328, loss 0.51460996
iteration 2329, loss 0.55538550
iteration 2330, loss 0.47490016
iteration 2331, loss 0.47626914
iteration 2332, loss 0.52281135
iteration 2333, loss 0.50733139
iteration 2334, loss 0.48649325
iteration 2335, loss 0.50641151
iteration 2336, loss 0.51134920
iteration 2337, loss 0.49274895
iteration 2338, loss 0.54091815
iteration 2339, loss 0.50869547
iteration 2340, loss 0.49247655
iteration 2341, loss 0.51460219
iteration 2342, loss 0.50351744
iteration 2343, loss 0.56780569
iteration 2344, loss 0.51597963
iteration 2345, loss 0.50403787
iteration 2346, loss 0.56181564
iteration 2347, loss 0.53024251
iteration 2348, loss 0.54602519
iteration 2349, loss 0.52775748
iteration 2350, loss 0.49249268
iteration 2351, loss 0.47859412
iteration 2352, loss 0.48633950
iteration 2353, loss 0.55053842
iteration 2354, loss 0.54295763
iteration 2355, loss 0.45001346
iteration 2356, loss 0.54026107
iteration 2357, loss 0.54435943
iteration 2358, loss 0.50338116
iteration 2359, loss 0.54867285
iteration 2360, loss 0.48116531
iteration 2361, loss 0.50534711
iteration 2362, loss 0.52315824
iteration 2363, loss 0.46905448
iteration 2364, loss 0.53479285
iteration 2365, loss 0.48231461
iteration 2366, loss 0.49682322
iteration 2367, loss 0.51239103
iteration 2368, loss 0.61410657
iteration 2369, loss 0.53622943
iteration 2370, loss 0.43541017
iteration 2371, loss 0.69347242
iteration 2372, loss 0.47035922
iteration 2373, loss 0.73085050
iteration 2374, loss 0.63295538
iteration 2375, loss 0.57507564
iteration 2376, loss 0.55588804
iteration 2377, loss 0.49027901
iteration 2378, loss 0.69692908
iteration 2379, loss 0.68773669
iteration 2380, loss 0.81311385
iteration 2381, loss 0.57562788
iteration 2382, loss 0.41267887
iteration 2383, loss 0.50837642
iteration 2384, loss 0.57276868
iteration 2385, loss 0.53124856
iteration 2386, loss 0.68587828
iteration 2387, loss 0.44460967
iteration 2388, loss 0.69673284
iteration 2389, loss 0.53593310
iteration 2390, loss 0.54012131
iteration 2391, loss 0.54795335
iteration 2392, loss 0.55959806
iteration 2393, loss 0.47492908
iteration 2394, loss 0.74199327
iteration 2395, loss 0.57055247
iteration 2396, loss 0.61418713
iteration 2397, loss 0.51908447
iteration 2398, loss 0.57211208
iteration 2399, loss 0.51622675
iteration 2400, loss 0.58816428
iteration 2401, loss 0.54849756
iteration 2402, loss 0.64406614
iteration 2403, loss 0.48002589
iteration 2404, loss 0.56330832
iteration 2405, loss 0.51143020
iteration 2406, loss 0.47943780
iteration 2407, loss 0.54084161
iteration 2408, loss 0.48419260
iteration 2409, loss 0.53428101
iteration 2410, loss 0.52154208
iteration 2411, loss 0.53165216
iteration 2412, loss 0.69468612
iteration 2413, loss 0.50482288
iteration 2414, loss 0.55606142
iteration 2415, loss 0.49816167
iteration 2416, loss 0.47319100
iteration 2417, loss 0.52052419
iteration 2418, loss 0.70340978
iteration 2419, loss 0.45582562
iteration 2420, loss 0.61902162
iteration 2421, loss 0.60090150
iteration 2422, loss 0.57224047
iteration 2423, loss 0.46530923
iteration 2424, loss 0.46115061
iteration 2425, loss 0.53701146
iteration 2426, loss 0.54178407
iteration 2427, loss 0.57501878
iteration 2428, loss 0.46121028
iteration 2429, loss 0.55190049
iteration 2430, loss 0.50817737
iteration 2431, loss 0.46855609
iteration 2432, loss 0.52707029
iteration 2433, loss 0.50879913
iteration 2434, loss 0.48179474
iteration 2435, loss 0.56330969
iteration 2436, loss 0.53557098
iteration 2437, loss 0.50466731
iteration 2438, loss 0.52248244
iteration 2439, loss 0.53273777
iteration 2440, loss 0.50298440
iteration 2441, loss 0.52494905
iteration 2442, loss 0.57018688
iteration 2443, loss 0.50304939
iteration 2444, loss 0.56639584
iteration 2445, loss 0.49077987
iteration 2446, loss 0.50055977
iteration 2447, loss 0.53603032
iteration 2448, loss 0.52078940
iteration 2449, loss 0.55758831
iteration 2450, loss 0.44830734
iteration 2451, loss 0.57633509
iteration 2452, loss 0.73339118
iteration 2453, loss 0.52939402
iteration 2454, loss 0.59650516
iteration 2455, loss 0.82470469
iteration 2456, loss 0.78521509
iteration 2457, loss 0.57766185
iteration 2458, loss 0.59144658
iteration 2459, loss 0.63406281
iteration 2460, loss 0.78762899
iteration 2461, loss 0.55072927
iteration 2462, loss 0.46572859
iteration 2463, loss 0.47265758
iteration 2464, loss 0.55643853
iteration 2465, loss 0.51320436
iteration 2466, loss 0.50038063
iteration 2467, loss 0.54759580
iteration 2468, loss 0.49893063
iteration 2469, loss 0.55938541
iteration 2470, loss 0.52655121
iteration 2471, loss 0.55196468
iteration 2472, loss 0.50448116
iteration 2473, loss 0.54844949
iteration 2474, loss 0.51109082
iteration 2475, loss 0.62898735
iteration 2476, loss 0.45158431
iteration 2477, loss 0.49534982
iteration 2478, loss 0.50697529
iteration 2479, loss 0.46974789
iteration 2480, loss 0.51231365
iteration 2481, loss 0.54142360
iteration 2482, loss 0.47554615
iteration 2483, loss 0.50084341
iteration 2484, loss 0.52636122
iteration 2485, loss 0.53326982
iteration 2486, loss 0.48080062
iteration 2487, loss 0.58026726
iteration 2488, loss 0.51801405
iteration 2489, loss 0.49152946
iteration 2490, loss 0.48798963
iteration 2491, loss 0.59590762
iteration 2492, loss 0.48126439
iteration 2493, loss 0.50781267
iteration 2494, loss 0.54171566
iteration 2495, loss 0.53740256
iteration 2496, loss 0.48348131
iteration 2497, loss 0.50687162
iteration 2498, loss 0.53486216
iteration 2499, loss 0.49381265
iteration 2500, loss 0.69959095
iteration 2501, loss 0.81808148
iteration 2502, loss 0.55919150
iteration 2503, loss 0.59682351
iteration 2504, loss 0.55832184
iteration 2505, loss 0.54401671
iteration 2506, loss 0.54644482
iteration 2507, loss 0.45797323
iteration 2508, loss 0.54675687
iteration 2509, loss 0.49924087
iteration 2510, loss 0.52444285
iteration 2511, loss 0.47238541
iteration 2512, loss 0.46645460
iteration 2513, loss 0.56045140
iteration 2514, loss 0.48756069
iteration 2515, loss 0.61818666
iteration 2516, loss 0.51313576
iteration 2517, loss 0.48190686
iteration 2518, loss 0.48405117
iteration 2519, loss 0.51531830
iteration 2520, loss 0.55188798
iteration 2521, loss 0.48142184
iteration 2522, loss 0.48713403
iteration 2523, loss 0.51304546
iteration 2524, loss 0.52454530
iteration 2525, loss 0.51832903
iteration 2526, loss 0.51952301
iteration 2527, loss 0.53529533
iteration 2528, loss 0.51371050
iteration 2529, loss 0.51819530
iteration 2530, loss 0.52072905
iteration 2531, loss 0.49995492
iteration 2532, loss 0.48809064
iteration 2533, loss 0.56494914
iteration 2534, loss 0.49373993
iteration 2535, loss 0.48353612
iteration 2536, loss 0.52737488
iteration 2537, loss 0.47959944
iteration 2538, loss 0.51739893
iteration 2539, loss 0.50518996
iteration 2540, loss 0.45038074
iteration 2541, loss 0.51031188
iteration 2542, loss 0.46886944
iteration 2543, loss 0.53915861
iteration 2544, loss 0.52562763
iteration 2545, loss 0.57778276
iteration 2546, loss 0.78523730
iteration 2547, loss 0.47199702
iteration 2548, loss 0.80882822
iteration 2549, loss 0.65158376
iteration 2550, loss 0.70294758
iteration 2551, loss 0.62566081
iteration 2552, loss 0.44600841
iteration 2553, loss 0.49935059
iteration 2554, loss 0.51435861
iteration 2555, loss 0.61510276
iteration 2556, loss 0.42389457
iteration 2557, loss 0.48726976
iteration 2558, loss 0.54458646
iteration 2559, loss 0.65135439
iteration 2560, loss 0.55226147
iteration 2561, loss 0.48836386
iteration 2562, loss 0.51632975
iteration 2563, loss 0.53414647
iteration 2564, loss 0.48030006
iteration 2565, loss 0.61562513
iteration 2566, loss 0.53722136
iteration 2567, loss 0.68077827
iteration 2568, loss 0.51440093
iteration 2569, loss 0.64536561
iteration 2570, loss 0.63504940
iteration 2571, loss 0.58253914
iteration 2572, loss 0.51431658
iteration 2573, loss 0.57935899
iteration 2574, loss 0.53836518
iteration 2575, loss 0.49937949
iteration 2576, loss 0.58245970
iteration 2577, loss 0.46686305
iteration 2578, loss 0.47172898
iteration 2579, loss 0.50943255
iteration 2580, loss 0.49212996
iteration 2581, loss 0.49637617
iteration 2582, loss 0.50264163
iteration 2583, loss 0.51653886
iteration 2584, loss 0.64885985
iteration 2585, loss 0.49534098
iteration 2586, loss 0.62286519
iteration 2587, loss 0.58749670
iteration 2588, loss 0.40569140
iteration 2589, loss 0.57446866
iteration 2590, loss 0.63782709
iteration 2591, loss 0.76706024
iteration 2592, loss 0.57951179
iteration 2593, loss 0.55965765
iteration 2594, loss 0.53620891
iteration 2595, loss 0.56817696
iteration 2596, loss 0.54372046
iteration 2597, loss 0.59290861
iteration 2598, loss 0.49041887
iteration 2599, loss 0.62747431
iteration 2600, loss 0.57135484
iteration 2601, loss 0.55062402
iteration 2602, loss 0.49328060
iteration 2603, loss 0.59442566
iteration 2604, loss 0.63935190
iteration 2605, loss 0.69111010
iteration 2606, loss 0.64976982
iteration 2607, loss 0.66799615
iteration 2608, loss 0.67325148
iteration 2609, loss 0.50409452
iteration 2610, loss 0.62626441
iteration 2611, loss 0.71117184
iteration 2612, loss 0.45872813
iteration 2613, loss 0.55018781
iteration 2614, loss 0.65664553
iteration 2615, loss 0.53923184
iteration 2616, loss 0.50385172
iteration 2617, loss 0.51839215
iteration 2618, loss 0.56937091
iteration 2619, loss 0.48101016
iteration 2620, loss 0.56106821
iteration 2621, loss 0.68699769
iteration 2622, loss 0.48483619
iteration 2623, loss 0.47018882
iteration 2624, loss 0.49217121
iteration 2625, loss 0.52195611
iteration 2626, loss 0.51515754
iteration 2627, loss 0.51656773
iteration 2628, loss 0.55144648
iteration 2629, loss 0.48249831
iteration 2630, loss 0.51184315
iteration 2631, loss 0.48387898
iteration 2632, loss 0.58173885
iteration 2633, loss 0.51572015
iteration 2634, loss 0.52617062
iteration 2635, loss 0.52761497
iteration 2636, loss 0.51280223
iteration 2637, loss 0.65315988
iteration 2638, loss 0.56355325
iteration 2639, loss 0.63978257
iteration 2640, loss 0.47423926
iteration 2641, loss 0.56543161
iteration 2642, loss 0.75708766
iteration 2643, loss 0.48068869
iteration 2644, loss 0.43618216
iteration 2645, loss 0.50895710
iteration 2646, loss 0.50512621
iteration 2647, loss 0.66096851
iteration 2648, loss 0.49979944
iteration 2649, loss 0.49475930
iteration 2650, loss 0.69247919
iteration 2651, loss 0.49242255
iteration 2652, loss 0.50167089
iteration 2653, loss 0.54718474
iteration 2654, loss 0.46774421
iteration 2655, loss 0.46646166
iteration 2656, loss 0.51566426
iteration 2657, loss 0.50092120
iteration 2658, loss 0.57888902
iteration 2659, loss 0.61293426
iteration 2660, loss 0.54803568
iteration 2661, loss 0.48173431
iteration 2662, loss 0.53576645
iteration 2663, loss 0.52504454
iteration 2664, loss 0.51195713
iteration 2665, loss 0.47827136
iteration 2666, loss 0.50693527
iteration 2667, loss 0.54292196
iteration 2668, loss 0.57969208
iteration 2669, loss 0.71934902
iteration 2670, loss 0.50606620
iteration 2671, loss 0.50878579
iteration 2672, loss 0.54026873
iteration 2673, loss 0.51872351
iteration 2674, loss 0.53132559
iteration 2675, loss 0.49382025
iteration 2676, loss 0.48866377
iteration 2677, loss 0.47369157
iteration 2678, loss 0.48506101
iteration 2679, loss 0.52850395
iteration 2680, loss 0.45341860
iteration 2681, loss 0.54639205
iteration 2682, loss 0.54236719
iteration 2683, loss 0.46847369
iteration 2684, loss 0.48446484
iteration 2685, loss 0.51658078
iteration 2686, loss 0.46341108
iteration 2687, loss 0.51547042
iteration 2688, loss 0.47847645
iteration 2689, loss 0.52107259
iteration 2690, loss 0.47843192
iteration 2691, loss 0.56433760
iteration 2692, loss 0.46950488
iteration 2693, loss 0.54740626
iteration 2694, loss 0.45785786
iteration 2695, loss 0.48541602
iteration 2696, loss 0.48136223
iteration 2697, loss 0.56186067
iteration 2698, loss 0.53847903
iteration 2699, loss 0.57031406
iteration 2700, loss 0.50114345
iteration 2701, loss 0.60885147
iteration 2702, loss 0.48053986
iteration 2703, loss 0.65660806
iteration 2704, loss 0.54704383
iteration 2705, loss 0.59539164
iteration 2706, loss 0.45057281
iteration 2707, loss 0.53294601
iteration 2708, loss 0.55225678
iteration 2709, loss 0.48405734
iteration 2710, loss 0.53452808
iteration 2711, loss 0.50290430
iteration 2712, loss 0.51902920
iteration 2713, loss 0.47936608
iteration 2714, loss 0.56083320
iteration 2715, loss 0.49898470
iteration 2716, loss 0.45750841
iteration 2717, loss 0.48038493
iteration 2718, loss 0.53597656
iteration 2719, loss 0.61159711
iteration 2720, loss 0.51183802
iteration 2721, loss 0.49450900
iteration 2722, loss 0.47571674
iteration 2723, loss 0.50296638
iteration 2724, loss 0.53812579
iteration 2725, loss 0.62161928
iteration 2726, loss 0.57194784
iteration 2727, loss 0.52031271
iteration 2728, loss 0.51928082
iteration 2729, loss 0.52791550
iteration 2730, loss 0.52288299
iteration 2731, loss 0.54879224
iteration 2732, loss 0.49024488
iteration 2733, loss 0.46710775
iteration 2734, loss 0.51553041
iteration 2735, loss 0.51527974
iteration 2736, loss 0.54533503
iteration 2737, loss 0.53031037
iteration 2738, loss 0.50725577
iteration 2739, loss 0.58714123
iteration 2740, loss 0.47010331
iteration 2741, loss 0.40792542
iteration 2742, loss 0.50022616
iteration 2743, loss 0.53943934
iteration 2744, loss 0.48104502
iteration 2745, loss 0.49863513
iteration 2746, loss 0.52463977
iteration 2747, loss 0.55408126
iteration 2748, loss 0.59672954
iteration 2749, loss 0.67411164
iteration 2750, loss 0.59163045
iteration 2751, loss 0.70489205
iteration 2752, loss 0.61141979
iteration 2753, loss 0.67620580
iteration 2754, loss 0.54410569
iteration 2755, loss 0.61370000
iteration 2756, loss 0.54720630
iteration 2757, loss 0.43989392
iteration 2758, loss 0.50092048
iteration 2759, loss 0.55118556
iteration 2760, loss 0.48749665
iteration 2761, loss 0.51306385
iteration 2762, loss 0.51177710
iteration 2763, loss 0.53841683
iteration 2764, loss 0.55010523
iteration 2765, loss 0.50894071
iteration 2766, loss 0.49196987
iteration 2767, loss 0.64876352
iteration 2768, loss 0.54346247
iteration 2769, loss 0.56196968
iteration 2770, loss 0.70579327
iteration 2771, loss 0.50823685
iteration 2772, loss 0.53118920
iteration 2773, loss 0.46098990
iteration 2774, loss 0.47864162
iteration 2775, loss 0.50101080
iteration 2776, loss 0.59251887
iteration 2777, loss 0.49180743
iteration 2778, loss 0.49801537
iteration 2779, loss 0.53691496
iteration 2780, loss 0.45933434
iteration 2781, loss 0.53871462
iteration 2782, loss 0.53684410
iteration 2783, loss 0.48106335
iteration 2784, loss 0.47231574
iteration 2785, loss 0.50814512
iteration 2786, loss 0.53374150
iteration 2787, loss 0.47994867
iteration 2788, loss 0.52735540
iteration 2789, loss 0.54031372
iteration 2790, loss 0.46494205
iteration 2791, loss 0.50060920
iteration 2792, loss 0.52605810
iteration 2793, loss 0.50450615
iteration 2794, loss 0.56724749
iteration 2795, loss 0.54366756
iteration 2796, loss 0.57434685
iteration 2797, loss 0.50482774
iteration 2798, loss 0.50638812
iteration 2799, loss 0.58917948
iteration 2800, loss 0.47510963
iteration 2801, loss 0.52371015
iteration 2802, loss 0.54161002
iteration 2803, loss 0.49046392
iteration 2804, loss 0.53004943
iteration 2805, loss 0.53016174
iteration 2806, loss 0.50718055
iteration 2807, loss 0.52287725
iteration 2808, loss 0.48332183
iteration 2809, loss 0.48113358
iteration 2810, loss 0.49813350
iteration 2811, loss 0.46641901
iteration 2812, loss 0.52896280
iteration 2813, loss 0.57047942
iteration 2814, loss 0.49821156
iteration 2815, loss 0.41781982
iteration 2816, loss 0.62343401
iteration 2817, loss 0.49754727
iteration 2818, loss 0.48390536
iteration 2819, loss 0.51855866
iteration 2820, loss 0.51023813
iteration 2821, loss 0.50329568
iteration 2822, loss 0.48196960
iteration 2823, loss 0.48235591
iteration 2824, loss 0.52813781
iteration 2825, loss 0.48801262
iteration 2826, loss 0.49788776
iteration 2827, loss 0.50709111
iteration 2828, loss 0.52656428
iteration 2829, loss 0.49531124
iteration 2830, loss 0.51520285
iteration 2831, loss 0.48557050
iteration 2832, loss 0.52785501
iteration 2833, loss 0.48625775
iteration 2834, loss 0.53504257
iteration 2835, loss 0.47441722
iteration 2836, loss 0.49530328
iteration 2837, loss 0.56232588
iteration 2838, loss 0.46983052
iteration 2839, loss 0.58946167
iteration 2840, loss 0.52992993
iteration 2841, loss 0.46839626
iteration 2842, loss 0.66399691
iteration 2843, loss 0.71893557
iteration 2844, loss 0.59288016
iteration 2845, loss 0.48703091
iteration 2846, loss 0.57096787
iteration 2847, loss 0.58868539
iteration 2848, loss 0.57442693
iteration 2849, loss 0.54298305
iteration 2850, loss 0.52368608
iteration 2851, loss 0.53212377
iteration 2852, loss 0.52085926
iteration 2853, loss 0.45858972
iteration 2854, loss 0.50746244
iteration 2855, loss 0.52623887
iteration 2856, loss 0.50302176
iteration 2857, loss 0.50754888
iteration 2858, loss 0.48528990
iteration 2859, loss 0.55160476
iteration 2860, loss 0.50236142
iteration 2861, loss 0.60132812
iteration 2862, loss 0.45285964
iteration 2863, loss 0.46706430
iteration 2864, loss 0.50450341
iteration 2865, loss 0.48302532
iteration 2866, loss 0.48867273
iteration 2867, loss 0.46859558
iteration 2868, loss 0.48574612
iteration 2869, loss 0.48178921
iteration 2870, loss 0.53296993
iteration 2871, loss 0.46505643
iteration 2872, loss 0.55560032
iteration 2873, loss 0.50909670
iteration 2874, loss 0.56176019
iteration 2875, loss 0.56684717
iteration 2876, loss 0.56665354
iteration 2877, loss 0.52288954
iteration 2878, loss 0.60107079
iteration 2879, loss 0.54697251
iteration 2880, loss 0.56480575
iteration 2881, loss 0.59412220
iteration 2882, loss 0.44973407
iteration 2883, loss 0.52926366
iteration 2884, loss 0.56165589
iteration 2885, loss 0.43796570
iteration 2886, loss 0.53791027
iteration 2887, loss 0.53970997
iteration 2888, loss 0.47611536
iteration 2889, loss 0.57665649
iteration 2890, loss 0.51329437
iteration 2891, loss 0.47769427
iteration 2892, loss 0.53700262
iteration 2893, loss 0.48753726
iteration 2894, loss 0.49269860
iteration 2895, loss 0.54193985
iteration 2896, loss 0.47501623
iteration 2897, loss 0.47756063
iteration 2898, loss 0.57125960
iteration 2899, loss 0.55181569
iteration 2900, loss 0.62371053
iteration 2901, loss 0.50528706
iteration 2902, loss 0.53487116
iteration 2903, loss 0.53096668
iteration 2904, loss 0.55714005
iteration 2905, loss 0.57905947
iteration 2906, loss 0.54777662
iteration 2907, loss 0.52820094
iteration 2908, loss 0.46793134
iteration 2909, loss 0.49774026
iteration 2910, loss 0.60138612
iteration 2911, loss 0.54583885
iteration 2912, loss 0.51757480
iteration 2913, loss 0.62710980
iteration 2914, loss 0.62922161
iteration 2915, loss 0.60323449
iteration 2916, loss 0.59880540
iteration 2917, loss 0.57104171
iteration 2918, loss 0.49228357
iteration 2919, loss 0.47843007
iteration 2920, loss 0.59259166
iteration 2921, loss 0.57436165
iteration 2922, loss 0.80983488
iteration 2923, loss 0.53309723
iteration 2924, loss 0.45277994
iteration 2925, loss 0.56732521
iteration 2926, loss 0.47395466
iteration 2927, loss 0.52926798
iteration 2928, loss 0.56870016
iteration 2929, loss 0.53759969
iteration 2930, loss 0.52307989
iteration 2931, loss 0.53322038
iteration 2932, loss 0.49907826
iteration 2933, loss 0.52781023
iteration 2934, loss 0.45995798
iteration 2935, loss 0.48170908
iteration 2936, loss 0.48637574
iteration 2937, loss 0.55578058
iteration 2938, loss 0.45861166
iteration 2939, loss 0.47502880
iteration 2940, loss 0.53319472
iteration 2941, loss 0.47654227
iteration 2942, loss 0.52148168
iteration 2943, loss 0.50157017
iteration 2944, loss 0.47873309
iteration 2945, loss 0.52039824
iteration 2946, loss 0.46883847
iteration 2947, loss 0.47142292
iteration 2948, loss 0.55495149
iteration 2949, loss 0.72653993
iteration 2950, loss 0.67401492
iteration 2951, loss 0.63861183
iteration 2952, loss 0.52124430
iteration 2953, loss 0.69766393
iteration 2954, loss 0.63279768
iteration 2955, loss 0.53794585
iteration 2956, loss 0.57769796
iteration 2957, loss 0.47468967
iteration 2958, loss 0.49118636
iteration 2959, loss 0.57859116
iteration 2960, loss 0.50439235
iteration 2961, loss 0.49505162
iteration 2962, loss 0.46180611
iteration 2963, loss 0.48726358
iteration 2964, loss 0.54494250
iteration 2965, loss 0.49409840
iteration 2966, loss 0.52227822
iteration 2967, loss 0.51709013
iteration 2968, loss 0.48970456
iteration 2969, loss 0.52652607
iteration 2970, loss 0.47878493
iteration 2971, loss 0.47989519
iteration 2972, loss 0.53236850
iteration 2973, loss 0.50356438
iteration 2974, loss 0.55234792
iteration 2975, loss 0.57270009
iteration 2976, loss 0.51432696
iteration 2977, loss 0.57257137
iteration 2978, loss 0.51081720
iteration 2979, loss 0.51706936
iteration 2980, loss 0.59585945
iteration 2981, loss 0.54956929
iteration 2982, loss 0.50787582
iteration 2983, loss 0.63217801
iteration 2984, loss 0.63477465
iteration 2985, loss 0.54211835
iteration 2986, loss 0.56952991
iteration 2987, loss 0.61971219
iteration 2988, loss 0.62920207
iteration 2989, loss 0.46452800
iteration 2990, loss 0.50332247
iteration 2991, loss 0.52735454
iteration 2992, loss 0.52300148
iteration 2993, loss 0.50898932
iteration 2994, loss 0.52222556
iteration 2995, loss 0.50655940
iteration 2996, loss 0.41171190
iteration 2997, loss 0.50341930
iteration 2998, loss 0.54194382
iteration 2999, loss 0.56653351
iteration 3000, loss 0.54478392
iteration 3001, loss 0.56077974
iteration 3002, loss 0.51258272
iteration 3003, loss 0.47917409
iteration 3004, loss 0.56543250
iteration 3005, loss 0.47333360
iteration 3006, loss 0.52530679
iteration 3007, loss 0.54138243
iteration 3008, loss 0.58529206
iteration 3009, loss 0.59554991
iteration 3010, loss 0.44980030
iteration 3011, loss 0.56301959
iteration 3012, loss 0.54192887
iteration 3013, loss 0.65254317
iteration 3014, loss 0.55324818
iteration 3015, loss 0.47803558
iteration 3016, loss 0.51751172
iteration 3017, loss 0.53252380
iteration 3018, loss 0.52372134
iteration 3019, loss 0.68349543
iteration 3020, loss 0.46502102
iteration 3021, loss 0.55844089
iteration 3022, loss 0.53553057
iteration 3023, loss 0.51134201
iteration 3024, loss 0.52478213
iteration 3025, loss 0.50440186
iteration 3026, loss 0.51466379
iteration 3027, loss 0.48936809
iteration 3028, loss 0.51936581
iteration 3029, loss 0.50310806
iteration 3030, loss 0.50285925
iteration 3031, loss 0.47742452
iteration 3032, loss 0.55064224
iteration 3033, loss 0.48043333
iteration 3034, loss 0.55757839
iteration 3035, loss 0.52566798
iteration 3036, loss 0.47762688
iteration 3037, loss 0.52802999
iteration 3038, loss 0.52677366
iteration 3039, loss 0.53943944
iteration 3040, loss 0.51341250
iteration 3041, loss 0.51259542
iteration 3042, loss 0.53235050
iteration 3043, loss 0.50227304
iteration 3044, loss 0.49373722
iteration 3045, loss 0.49633574
iteration 3046, loss 0.49696359
iteration 3047, loss 0.55246310
iteration 3048, loss 0.62145884
iteration 3049, loss 0.43703440
iteration 3050, loss 0.50793793
iteration 3051, loss 0.55088740
iteration 3052, loss 0.48976771
iteration 3053, loss 0.53546484
iteration 3054, loss 0.53428380
iteration 3055, loss 0.48342899
iteration 3056, loss 0.54452930
iteration 3057, loss 0.64234193
iteration 3058, loss 0.44045769
iteration 3059, loss 0.51995620
iteration 3060, loss 0.47696842
iteration 3061, loss 0.55004693
iteration 3062, loss 0.52162881
iteration 3063, loss 0.52145367
iteration 3064, loss 0.53235494
iteration 3065, loss 0.58877558
iteration 3066, loss 0.59102056
iteration 3067, loss 0.71275476
iteration 3068, loss 0.54957900
iteration 3069, loss 0.59007478
iteration 3070, loss 0.51277520
iteration 3071, loss 0.49854706
iteration 3072, loss 0.47051883
iteration 3073, loss 0.60222435
iteration 3074, loss 0.60848823
iteration 3075, loss 0.47608387
iteration 3076, loss 0.58842527
iteration 3077, loss 0.54347600
iteration 3078, loss 0.52677926
iteration 3079, loss 0.56337620
iteration 3080, loss 0.62007140
iteration 3081, loss 0.57964493
iteration 3082, loss 0.44418671
iteration 3083, loss 0.56497192
iteration 3084, loss 0.58633348
iteration 3085, loss 0.48356531
iteration 3086, loss 0.50163633
iteration 3087, loss 0.56029076
iteration 3088, loss 0.49864373
iteration 3089, loss 0.48489008
iteration 3090, loss 0.55286778
iteration 3091, loss 0.55323457
iteration 3092, loss 0.57368184
iteration 3093, loss 0.57274399
iteration 3094, loss 0.51781231
iteration 3095, loss 0.54688184
iteration 3096, loss 0.49203113
iteration 3097, loss 0.49948523
iteration 3098, loss 0.48634319
iteration 3099, loss 0.46529651
iteration 3100, loss 0.46608139
iteration 3101, loss 0.53830839
iteration 3102, loss 0.47877206
iteration 3103, loss 0.60354436
iteration 3104, loss 0.58953928
iteration 3105, loss 0.53106986
iteration 3106, loss 0.57327547
iteration 3107, loss 0.46958343
iteration 3108, loss 0.51187537
iteration 3109, loss 0.53700030
iteration 3110, loss 0.52151554
iteration 3111, loss 0.53831589
iteration 3112, loss 0.49052961
iteration 3113, loss 0.64563038
iteration 3114, loss 0.66836428
iteration 3115, loss 0.54564244
iteration 3116, loss 0.58616681
iteration 3117, loss 0.54607474
iteration 3118, loss 0.49133189
iteration 3119, loss 0.49252434
iteration 3120, loss 0.54461454
iteration 3121, loss 0.68100893
iteration 3122, loss 0.55003792
iteration 3123, loss 0.52052705
iteration 3124, loss 0.49423604
iteration 3125, loss 0.69002009
iteration 3126, loss 0.46238946
iteration 3127, loss 0.47049653
iteration 3128, loss 0.66096538
iteration 3129, loss 0.52392358
iteration 3130, loss 0.40274116
iteration 3131, loss 0.61093826
iteration 3132, loss 0.50600175
iteration 3133, loss 0.72827675
iteration 3134, loss 0.74398705
iteration 3135, loss 0.51428331
iteration 3136, loss 0.60576554
iteration 3137, loss 0.51718412
iteration 3138, loss 0.65238672
iteration 3139, loss 0.68151812
iteration 3140, loss 0.54763884
iteration 3141, loss 0.51103228
iteration 3142, loss 0.47418892
iteration 3143, loss 0.53922756
iteration 3144, loss 0.62533172
iteration 3145, loss 0.45490264
iteration 3146, loss 0.54752396
iteration 3147, loss 0.54962939
iteration 3148, loss 0.47119922
iteration 3149, loss 0.46338153
iteration 3150, loss 0.49429862
iteration 3151, loss 0.50471494
iteration 3152, loss 0.51389183
iteration 3153, loss 0.48377619
iteration 3154, loss 0.69073839
iteration 3155, loss 0.57375804
iteration 3156, loss 0.60107022
iteration 3157, loss 0.57907663
iteration 3158, loss 0.48974647
iteration 3159, loss 0.46740548
iteration 3160, loss 0.50932616
iteration 3161, loss 0.50245018
iteration 3162, loss 0.45395322
iteration 3163, loss 0.52109293
iteration 3164, loss 0.48981943
iteration 3165, loss 0.49952931
iteration 3166, loss 0.54689493
iteration 3167, loss 0.50683560
iteration 3168, loss 0.55497133
iteration 3169, loss 0.49049622
iteration 3170, loss 0.59260492
iteration 3171, loss 0.54899163
iteration 3172, loss 0.58963806
iteration 3173, loss 0.62488046
iteration 3174, loss 0.47223981
iteration 3175, loss 0.45186665
iteration 3176, loss 0.51991484
iteration 3177, loss 0.56204091
iteration 3178, loss 0.49134173
iteration 3179, loss 0.48793617
iteration 3180, loss 0.48736589
iteration 3181, loss 0.54828008
iteration 3182, loss 0.52664726
iteration 3183, loss 0.51755768
iteration 3184, loss 0.48253657
iteration 3185, loss 0.57474777
iteration 3186, loss 0.69949785
iteration 3187, loss 0.55226256
iteration 3188, loss 0.56345694
iteration 3189, loss 0.47560183
iteration 3190, loss 0.50332294
iteration 3191, loss 0.51433278
iteration 3192, loss 0.52870268
iteration 3193, loss 0.44855756
iteration 3194, loss 0.50957000
iteration 3195, loss 0.55543902
iteration 3196, loss 0.47919035
iteration 3197, loss 0.51754084
iteration 3198, loss 0.46082188
iteration 3199, loss 0.56069858
iteration 3200, loss 0.50291991
iteration 3201, loss 0.61231075
iteration 3202, loss 0.60545984
iteration 3203, loss 0.44651939
iteration 3204, loss 0.44116872
iteration 3205, loss 0.54255074
iteration 3206, loss 0.59011551
iteration 3207, loss 0.52709493
iteration 3208, loss 0.53709893
iteration 3209, loss 0.60594699
iteration 3210, loss 0.47239267
iteration 3211, loss 0.52031712
iteration 3212, loss 0.65536546
iteration 3213, loss 0.47626139
iteration 3214, loss 0.57438725
iteration 3215, loss 0.60543688
iteration 3216, loss 0.48791522
iteration 3217, loss 0.50553909
iteration 3218, loss 0.52928302
iteration 3219, loss 0.51254985
iteration 3220, loss 0.50735832
iteration 3221, loss 0.47949104
iteration 3222, loss 0.52541615
iteration 3223, loss 0.52128197
iteration 3224, loss 0.44628813
iteration 3225, loss 0.51488385
iteration 3226, loss 0.52265492
iteration 3227, loss 0.56395576
iteration 3228, loss 0.58682593
iteration 3229, loss 0.51749547
iteration 3230, loss 0.51006940
iteration 3231, loss 0.50457600
iteration 3232, loss 0.62201355
iteration 3233, loss 0.52722105
iteration 3234, loss 0.44390113
iteration 3235, loss 0.49307676
iteration 3236, loss 0.53841987
iteration 3237, loss 0.68704549
iteration 3238, loss 0.59864132
iteration 3239, loss 0.64673669
iteration 3240, loss 0.55702610
iteration 3241, loss 0.52484217
iteration 3242, loss 0.49388631
iteration 3243, loss 0.51916244
iteration 3244, loss 0.57172566
iteration 3245, loss 0.65356106
iteration 3246, loss 0.59028800
iteration 3247, loss 0.54756795
iteration 3248, loss 0.48371756
iteration 3249, loss 0.47663020
iteration 3250, loss 0.51035930
iteration 3251, loss 0.49517109
iteration 3252, loss 0.49433803
iteration 3253, loss 0.56883021
iteration 3254, loss 0.54854128
iteration 3255, loss 0.71020127
iteration 3256, loss 0.49951731
iteration 3257, loss 0.60580505
iteration 3258, loss 0.65772154
iteration 3259, loss 0.47422442
iteration 3260, loss 0.50937025
iteration 3261, loss 0.52100601
iteration 3262, loss 0.52743058
iteration 3263, loss 0.47531874
iteration 3264, loss 0.48993356
iteration 3265, loss 0.60432460
iteration 3266, loss 0.44761768
iteration 3267, loss 0.68651150
iteration 3268, loss 0.50799115
iteration 3269, loss 0.45217164
iteration 3270, loss 0.53028019
iteration 3271, loss 0.54285195
iteration 3272, loss 0.54846712
iteration 3273, loss 0.47845541
iteration 3274, loss 0.50424390
iteration 3275, loss 0.51387017
iteration 3276, loss 0.60560393
iteration 3277, loss 0.50074839
iteration 3278, loss 0.62524715
iteration 3279, loss 0.52798164
iteration 3280, loss 0.53626112
iteration 3281, loss 0.50070538
iteration 3282, loss 0.59540125
iteration 3283, loss 0.48305945
iteration 3284, loss 0.55176651
iteration 3285, loss 0.53658318
iteration 3286, loss 0.87682335
iteration 3287, loss 0.85568573
iteration 3288, loss 0.72249857
iteration 3289, loss 0.43672408
iteration 3290, loss 0.43778511
iteration 3291, loss 0.51539232
iteration 3292, loss 0.56724680
iteration 3293, loss 0.50438436
iteration 3294, loss 0.71885228
iteration 3295, loss 0.61786579
iteration 3296, loss 0.69351440
iteration 3297, loss 0.51584396
iteration 3298, loss 0.53592684
iteration 3299, loss 0.57147742
iteration 3300, loss 0.58434791
iteration 3301, loss 0.50197808
iteration 3302, loss 0.50989058
iteration 3303, loss 0.51594338
iteration 3304, loss 0.50967256
iteration 3305, loss 0.48397015
iteration 3306, loss 0.52969685
iteration 3307, loss 0.49703560
iteration 3308, loss 0.51240962
iteration 3309, loss 0.59672915
iteration 3310, loss 0.46331437
iteration 3311, loss 0.62431285
iteration 3312, loss 0.54765146
iteration 3313, loss 0.51694811
iteration 3314, loss 0.52922056
iteration 3315, loss 0.48295778
iteration 3316, loss 0.51833715
iteration 3317, loss 0.56969604
iteration 3318, loss 0.52793228
iteration 3319, loss 0.53500567
iteration 3320, loss 0.52917148
iteration 3321, loss 0.65384909
iteration 3322, loss 0.58375803
iteration 3323, loss 0.51509545
iteration 3324, loss 0.59794595
iteration 3325, loss 0.42956701
iteration 3326, loss 0.48398316
iteration 3327, loss 0.57371548
iteration 3328, loss 0.56164999
iteration 3329, loss 0.54417024
iteration 3330, loss 0.47626565
iteration 3331, loss 0.59840379
iteration 3332, loss 0.48392088
iteration 3333, loss 0.53803811
iteration 3334, loss 0.49978928
iteration 3335, loss 0.48669236
iteration 3336, loss 0.57900286
iteration 3337, loss 0.58908116
iteration 3338, loss 0.49909342
iteration 3339, loss 0.67320332
iteration 3340, loss 0.50522198
iteration 3341, loss 0.53884053
iteration 3342, loss 0.50322013
iteration 3343, loss 0.50958832
iteration 3344, loss 0.49083413
iteration 3345, loss 0.49795852
iteration 3346, loss 0.55559897
iteration 3347, loss 0.51182445
iteration 3348, loss 0.50135030
iteration 3349, loss 0.60252783
iteration 3350, loss 0.47907993
iteration 3351, loss 0.49188530
iteration 3352, loss 0.52948313
iteration 3353, loss 0.48740512
iteration 3354, loss 0.55536986
iteration 3355, loss 0.51851608
iteration 3356, loss 0.53779044
iteration 3357, loss 0.51968093
iteration 3358, loss 0.51584037
iteration 3359, loss 0.49412888
iteration 3360, loss 0.46925780
iteration 3361, loss 0.49533007
iteration 3362, loss 0.50400884
iteration 3363, loss 0.55326438
iteration 3364, loss 0.45737908
iteration 3365, loss 0.51609416
iteration 3366, loss 0.55427659
iteration 3367, loss 0.46928698
iteration 3368, loss 0.47749779
iteration 3369, loss 0.61547949
iteration 3370, loss 0.41272596
iteration 3371, loss 0.52034868
iteration 3372, loss 0.48018865
iteration 3373, loss 0.48279638
iteration 3374, loss 0.55734956
iteration 3375, loss 0.48698399
iteration 3376, loss 0.46719144
iteration 3377, loss 0.53705310
iteration 3378, loss 0.53322604
iteration 3379, loss 0.47735309
iteration 3380, loss 0.51407185
iteration 3381, loss 0.56239487
iteration 3382, loss 0.47005446
iteration 3383, loss 0.49485646
iteration 3384, loss 0.51654372
iteration 3385, loss 0.60230473
iteration 3386, loss 0.52613897
iteration 3387, loss 0.45961631
iteration 3388, loss 0.58566262
iteration 3389, loss 0.47883627
iteration 3390, loss 0.55301042
iteration 3391, loss 0.56400119
iteration 3392, loss 0.49776067
iteration 3393, loss 0.54795955
iteration 3394, loss 0.51650595
iteration 3395, loss 0.41897085
iteration 3396, loss 0.44765956
iteration 3397, loss 0.46523482
iteration 3398, loss 0.44894584
iteration 3399, loss 0.43477569
iteration 3400, loss 0.41527190
iteration 3401, loss 0.59879911
iteration 3402, loss 0.45721170
iteration 3403, loss 0.47069522
iteration 3404, loss 0.46558812
iteration 3405, loss 0.70063283
iteration 3406, loss 0.63273060
iteration 3407, loss 0.50449800
iteration 3408, loss 0.33633948
iteration 3409, loss 0.58673937
iteration 3410, loss 0.41819815
iteration 3411, loss 0.54173840
iteration 3412, loss 0.43076580
iteration 3413, loss 0.46436750
iteration 3414, loss 0.57783286
iteration 3415, loss 0.60015587
iteration 3416, loss 0.36912092
iteration 3417, loss 0.48209141
iteration 3418, loss 0.51486946
iteration 3419, loss 0.38177252
iteration 3420, loss 0.34591780
iteration 3421, loss 0.72424640
iteration 3422, loss 0.58173223
iteration 3423, loss 0.82667455
iteration 3424, loss 0.86681505
iteration 3425, loss 0.97865426
iteration 3426, loss 0.67481584
iteration 3427, loss 0.51599924
iteration 3428, loss 0.55711581
iteration 3429, loss 0.54799785
iteration 3430, loss 0.95125314
iteration 3431, loss 0.75585218
iteration 3432, loss 0.33088438
iteration 3433, loss 0.46877853
iteration 3434, loss 0.49850375
iteration 3435, loss 0.45131917
iteration 3436, loss 0.69513205
iteration 3437, loss 0.58617510
iteration 3438, loss 0.54624190
iteration 3439, loss 0.46689574
iteration 3440, loss 0.65013645
iteration 3441, loss 0.62930669
iteration 3442, loss 0.52051073
iteration 3443, loss 0.61644513
iteration 3444, loss 0.54438211
iteration 3445, loss 0.66772605
iteration 3446, loss 0.50202470
iteration 3447, loss 0.67820157
iteration 3448, loss 0.53222145
iteration 3449, loss 0.69151469
iteration 3450, loss 0.50200969
iteration 3451, loss 0.47507804
iteration 3452, loss 0.51050781
iteration 3453, loss 0.60305485
iteration 3454, loss 0.42317408
iteration 3455, loss 0.67805499
iteration 3456, loss 0.55886520
iteration 3457, loss 0.51746629
iteration 3458, loss 0.49132385
iteration 3459, loss 0.47373923
iteration 3460, loss 0.47544133
iteration 3461, loss 0.48137156
iteration 3462, loss 0.43231792
iteration 3463, loss 0.47110989
iteration 3464, loss 0.49754426
iteration 3465, loss 0.48585324
iteration 3466, loss 0.55264023
iteration 3467, loss 0.49249948
iteration 3468, loss 0.47394436
iteration 3469, loss 0.45900215
iteration 3470, loss 0.59561189
iteration 3471, loss 0.49684284
iteration 3472, loss 0.42020581
iteration 3473, loss 0.40651895
iteration 3474, loss 0.40980052
iteration 3475, loss 0.53057983
iteration 3476, loss 0.42825983
iteration 3477, loss 0.47673201
iteration 3478, loss 0.38956676
iteration 3479, loss 0.48432127
iteration 3480, loss 0.68417282
iteration 3481, loss 0.53400392
iteration 3482, loss 0.51083642
iteration 3483, loss 0.49103490
iteration 3484, loss 0.47638857
iteration 3485, loss 0.45076100
iteration 3486, loss 0.36881212
iteration 3487, loss 0.37180059
iteration 3488, loss 0.44575979
iteration 3489, loss 0.50523380
iteration 3490, loss 0.57032058
iteration 3491, loss 0.41973627
iteration 3492, loss 0.55819327
iteration 3493, loss 0.48692085
iteration 3494, loss 0.40551707
iteration 3495, loss 0.74273930
iteration 3496, loss 0.61089190
iteration 3497, loss 0.57818421
iteration 3498, loss 0.52187298
iteration 3499, loss 0.48570488
iteration 3500, loss 0.59508866
iteration 3501, loss 0.52632455
iteration 3502, loss 0.49117191
iteration 3503, loss 0.49750866
iteration 3504, loss 0.50388450
iteration 3505, loss 0.57419441
iteration 3506, loss 0.58454425
iteration 3507, loss 0.62775761
iteration 3508, loss 0.58795781
iteration 3509, loss 0.49042773
iteration 3510, loss 0.51676264
iteration 3511, loss 0.60464243
iteration 3512, loss 0.64464716
iteration 3513, loss 0.56222638
iteration 3514, loss 0.61432918
iteration 3515, loss 0.68371173
iteration 3516, loss 0.61255616
iteration 3517, loss 0.49774691
iteration 3518, loss 0.48417011
iteration 3519, loss 0.58745678
iteration 3520, loss 0.59278734
iteration 3521, loss 0.47542144
iteration 3522, loss 0.58086548
iteration 3523, loss 0.59795883
iteration 3524, loss 0.50830490
iteration 3525, loss 0.48998253
iteration 3526, loss 0.51154418
iteration 3527, loss 0.47562369
iteration 3528, loss 0.56466288
iteration 3529, loss 0.62831771
iteration 3530, loss 0.49995684
iteration 3531, loss 0.46616945
iteration 3532, loss 0.49399805
iteration 3533, loss 0.60449611
iteration 3534, loss 0.55848555
iteration 3535, loss 0.54283624
iteration 3536, loss 0.71612893
iteration 3537, loss 0.52800700
iteration 3538, loss 0.56872576
iteration 3539, loss 0.55031966
iteration 3540, loss 0.47834267
iteration 3541, loss 0.53317727
iteration 3542, loss 0.48526335
iteration 3543, loss 0.49767578
iteration 3544, loss 0.48366836
iteration 3545, loss 0.50147711
iteration 3546, loss 0.67347905
iteration 3547, loss 0.52352516
iteration 3548, loss 0.49342369
iteration 3549, loss 0.55034190
iteration 3550, loss 0.47350058
iteration 3551, loss 0.57101325
iteration 3552, loss 0.53224955
iteration 3553, loss 0.52141389
iteration 3554, loss 0.46606324
iteration 3555, loss 0.67032519
iteration 3556, loss 0.49653361
iteration 3557, loss 0.53462132
iteration 3558, loss 0.51066664
iteration 3559, loss 0.57574042
iteration 3560, loss 0.52339828
iteration 3561, loss 0.42783694
iteration 3562, loss 0.53679329
iteration 3563, loss 0.50806649
iteration 3564, loss 0.48695775
iteration 3565, loss 0.50592246
iteration 3566, loss 0.46791662
iteration 3567, loss 0.48137796
iteration 3568, loss 0.55868215
iteration 3569, loss 0.48933970
iteration 3570, loss 0.53915536
iteration 3571, loss 0.48527264
iteration 3572, loss 0.49876552
iteration 3573, loss 0.56164232
iteration 3574, loss 0.51046814
iteration 3575, loss 0.70010484
iteration 3576, loss 0.53232639
iteration 3577, loss 0.56111401
iteration 3578, loss 0.56382344
iteration 3579, loss 0.49577044
iteration 3580, loss 0.53112226
iteration 3581, loss 0.49175950
iteration 3582, loss 0.50721254
iteration 3583, loss 0.51745551
iteration 3584, loss 0.52607518
iteration 3585, loss 0.53890156
iteration 3586, loss 0.47782607
iteration 3587, loss 0.51487826
iteration 3588, loss 0.49823754
iteration 3589, loss 0.49338592
iteration 3590, loss 0.51396548
iteration 3591, loss 0.61629911
iteration 3592, loss 0.48309239
iteration 3593, loss 0.54426865
iteration 3594, loss 0.52093969
iteration 3595, loss 0.50780062
iteration 3596, loss 0.50759539
iteration 3597, loss 0.53816330
iteration 3598, loss 0.48726324
iteration 3599, loss 0.57507588
iteration 3600, loss 0.60103316
iteration 3601, loss 0.56668176
iteration 3602, loss 0.46516487
iteration 3603, loss 0.54699375
iteration 3604, loss 0.66502582
iteration 3605, loss 0.53258540
iteration 3606, loss 0.46581321
iteration 3607, loss 0.50813379
iteration 3608, loss 0.49696312
iteration 3609, loss 0.49373798
iteration 3610, loss 0.54554606
iteration 3611, loss 0.46941559
iteration 3612, loss 0.50786539
iteration 3613, loss 0.51634665
iteration 3614, loss 0.47493239
iteration 3615, loss 0.51245493
iteration 3616, loss 0.61432675
iteration 3617, loss 0.49437175
iteration 3618, loss 0.55348239
iteration 3619, loss 0.59052727
iteration 3620, loss 0.63361502
iteration 3621, loss 0.48130613
iteration 3622, loss 0.48580436
iteration 3623, loss 0.58945183
iteration 3624, loss 0.45281977
iteration 3625, loss 0.50642748
iteration 3626, loss 0.52921011
iteration 3627, loss 0.47709583
iteration 3628, loss 0.48895159
iteration 3629, loss 0.53886706
iteration 3630, loss 0.49220083
iteration 3631, loss 0.50647696
iteration 3632, loss 0.50992778
iteration 3633, loss 0.49953639
iteration 3634, loss 0.51598662
iteration 3635, loss 0.50635410
iteration 3636, loss 0.61229146
iteration 3637, loss 0.55595430
iteration 3638, loss 0.51197188
iteration 3639, loss 0.56014367
iteration 3640, loss 0.45274496
iteration 3641, loss 0.54432015
iteration 3642, loss 0.53067706
iteration 3643, loss 0.54648117
iteration 3644, loss 0.48814175
iteration 3645, loss 0.51190679
iteration 3646, loss 0.54031081
iteration 3647, loss 0.47979756
iteration 3648, loss 0.51553356
iteration 3649, loss 0.49180245
iteration 3650, loss 0.51125312
iteration 3651, loss 0.52421058
iteration 3652, loss 0.52921682
iteration 3653, loss 0.61034430
iteration 3654, loss 0.56679571
iteration 3655, loss 0.49250678
iteration 3656, loss 0.59932111
iteration 3657, loss 0.52767396
iteration 3658, loss 0.56759325
iteration 3659, loss 0.52084843
iteration 3660, loss 0.57213573
iteration 3661, loss 0.50014977
iteration 3662, loss 0.51218122
iteration 3663, loss 0.47023020
iteration 3664, loss 0.58539304
iteration 3665, loss 0.54239624
iteration 3666, loss 0.57559203
iteration 3667, loss 0.50490233
iteration 3668, loss 0.50504166
iteration 3669, loss 0.49979608
iteration 3670, loss 0.55964737
iteration 3671, loss 0.48588020
iteration 3672, loss 0.50202591
iteration 3673, loss 0.66057344
iteration 3674, loss 0.52604676
iteration 3675, loss 0.49316430
iteration 3676, loss 0.53518350
iteration 3677, loss 0.57032368
iteration 3678, loss 0.55597968
iteration 3679, loss 0.46124827
iteration 3680, loss 0.57243018
iteration 3681, loss 0.53235047
iteration 3682, loss 0.56776843
iteration 3683, loss 0.49999403
iteration 3684, loss 0.55546061
iteration 3685, loss 0.52003932
iteration 3686, loss 0.47105102
iteration 3687, loss 0.50074782
iteration 3688, loss 0.53658086
iteration 3689, loss 0.47631634
iteration 3690, loss 0.48413516
iteration 3691, loss 0.57193964
iteration 3692, loss 0.46904975
iteration 3693, loss 0.62266711
iteration 3694, loss 0.62410993
iteration 3695, loss 0.54148932
iteration 3696, loss 0.51330000
iteration 3697, loss 0.47124412
iteration 3698, loss 0.51803548
iteration 3699, loss 0.44411230
iteration 3700, loss 0.46531301
iteration 3701, loss 0.51270128
iteration 3702, loss 0.51232291
iteration 3703, loss 0.41033141
iteration 3704, loss 0.61112801
iteration 3705, loss 0.49349597
iteration 3706, loss 0.50647838
iteration 3707, loss 0.58641597
iteration 3708, loss 0.36099005
iteration 3709, loss 0.62127603
iteration 3710, loss 0.57899924
iteration 3711, loss 0.57262296
iteration 3712, loss 0.53556149
iteration 3713, loss 0.47639095
iteration 3714, loss 0.63162790
iteration 3715, loss 0.54484201
iteration 3716, loss 0.38467001
iteration 3717, loss 0.55887907
iteration 3718, loss 0.43958907
iteration 3719, loss 0.42363208
iteration 3720, loss 0.41731221
iteration 3721, loss 0.51827646
iteration 3722, loss 0.51904711
iteration 3723, loss 0.38954075
iteration 3724, loss 0.50293591
iteration 3725, loss 0.67777435
iteration 3726, loss 0.48795867
iteration 3727, loss 0.27570139
iteration 3728, loss 0.79873426
iteration 3729, loss 0.51189225
iteration 3730, loss 0.55150700
iteration 3731, loss 0.64833064
iteration 3732, loss 0.49837018
iteration 3733, loss 0.41581101
iteration 3734, loss 0.52345920
iteration 3735, loss 0.52442277
iteration 3736, loss 0.50762128
iteration 3737, loss 0.54039530
iteration 3738, loss 0.48922458
iteration 3739, loss 0.50831349
iteration 3740, loss 0.58888278
iteration 3741, loss 0.49121328
iteration 3742, loss 0.59751705
iteration 3743, loss 0.51128795
iteration 3744, loss 0.44143925
iteration 3745, loss 0.57607886
iteration 3746, loss 0.50163159
iteration 3747, loss 0.52468073
iteration 3748, loss 0.47809709
iteration 3749, loss 0.60896648
iteration 3750, loss 0.49685638
iteration 3751, loss 0.48033365
iteration 3752, loss 0.51238641
iteration 3753, loss 0.51227783
iteration 3754, loss 0.49300678
iteration 3755, loss 0.59239904
iteration 3756, loss 0.46409686
iteration 3757, loss 0.58899178
iteration 3758, loss 0.50602657
iteration 3759, loss 0.48012064
iteration 3760, loss 0.51005633
iteration 3761, loss 0.54759376
iteration 3762, loss 0.50109252
iteration 3763, loss 0.50298429
iteration 3764, loss 0.56245222
iteration 3765, loss 0.51276231
iteration 3766, loss 0.48386018
iteration 3767, loss 0.54577851
iteration 3768, loss 0.53977372
iteration 3769, loss 0.50937837
iteration 3770, loss 0.52910866
iteration 3771, loss 0.59519726
iteration 3772, loss 0.49197641
iteration 3773, loss 0.65070016
iteration 3774, loss 0.75375197
iteration 3775, loss 0.50876169
iteration 3776, loss 0.48959190
iteration 3777, loss 0.52932651
iteration 3778, loss 0.51720066
iteration 3779, loss 0.47647537
iteration 3780, loss 0.49690018
iteration 3781, loss 0.49742859
iteration 3782, loss 0.54906816
iteration 3783, loss 0.49163352
iteration 3784, loss 0.50506674
iteration 3785, loss 0.50328347
iteration 3786, loss 0.53205609
iteration 3787, loss 0.44014852
iteration 3788, loss 0.49761403
iteration 3789, loss 0.52845308
iteration 3790, loss 0.52195372
iteration 3791, loss 0.54657837
iteration 3792, loss 0.58236779
iteration 3793, loss 0.47512262
iteration 3794, loss 0.51705071
iteration 3795, loss 0.61051468
iteration 3796, loss 0.49835116
iteration 3797, loss 0.67288031
iteration 3798, loss 0.68768316
iteration 3799, loss 0.48774945
iteration 3800, loss 0.49908793
iteration 3801, loss 0.51399203
iteration 3802, loss 0.52711992
iteration 3803, loss 0.49166526
iteration 3804, loss 0.48029297
iteration 3805, loss 0.47815664
iteration 3806, loss 0.54329901
iteration 3807, loss 0.47322771
iteration 3808, loss 0.62878171
iteration 3809, loss 0.55549408
iteration 3810, loss 0.56902483
iteration 3811, loss 0.52037743
iteration 3812, loss 0.53126844
iteration 3813, loss 0.47070700
iteration 3814, loss 0.48904054
iteration 3815, loss 0.45126673
iteration 3816, loss 0.49703793
iteration 3817, loss 0.50918813
iteration 3818, loss 0.51657225
iteration 3819, loss 0.46665219
iteration 3820, loss 0.49436877
iteration 3821, loss 0.58160542
iteration 3822, loss 0.48881754
iteration 3823, loss 0.54671422
iteration 3824, loss 0.63887036
iteration 3825, loss 0.66170129
iteration 3826, loss 0.61849165
iteration 3827, loss 0.60299535
iteration 3828, loss 0.64690051
iteration 3829, loss 0.53554618
iteration 3830, loss 0.60236985
iteration 3831, loss 0.43503089
iteration 3832, loss 0.59979778
iteration 3833, loss 0.53288315
iteration 3834, loss 0.48063378
iteration 3835, loss 0.49434328
iteration 3836, loss 0.52805670
iteration 3837, loss 0.47081010
iteration 3838, loss 0.48334022
iteration 3839, loss 0.50002548
iteration 3840, loss 0.53945299
iteration 3841, loss 0.49271388
iteration 3842, loss 0.63724712
iteration 3843, loss 0.55325374
iteration 3844, loss 0.54204513
iteration 3845, loss 0.48967834
iteration 3846, loss 0.52000304
iteration 3847, loss 0.56340615
iteration 3848, loss 0.50089897
iteration 3849, loss 0.53334568
iteration 3850, loss 0.48332786
iteration 3851, loss 0.49049834
iteration 3852, loss 0.53606342
iteration 3853, loss 0.50986572
iteration 3854, loss 0.55340752
iteration 3855, loss 0.51535513
iteration 3856, loss 0.45573391
iteration 3857, loss 0.52704507
iteration 3858, loss 0.63387736
iteration 3859, loss 0.46738060
iteration 3860, loss 0.61382961
iteration 3861, loss 0.63623662
iteration 3862, loss 0.61423151
iteration 3863, loss 0.56635747
iteration 3864, loss 0.48758270
iteration 3865, loss 0.66840129
iteration 3866, loss 0.55055444
iteration 3867, loss 0.70689935
iteration 3868, loss 0.47276383
iteration 3869, loss 0.58994262
iteration 3870, loss 0.52542413
iteration 3871, loss 0.62640928
iteration 3872, loss 0.82317285
iteration 3873, loss 0.60700929
iteration 3874, loss 0.43348021
iteration 3875, loss 0.49387094
iteration 3876, loss 0.57614411
iteration 3877, loss 0.52028354
iteration 3878, loss 0.58149349
iteration 3879, loss 0.50828849
iteration 3880, loss 0.51295356
iteration 3881, loss 0.48103456
iteration 3882, loss 0.49198499
iteration 3883, loss 0.50985296
iteration 3884, loss 0.57466160
iteration 3885, loss 0.51458888
iteration 3886, loss 0.52843595
iteration 3887, loss 0.48483643
iteration 3888, loss 0.52559461
iteration 3889, loss 0.60500000
iteration 3890, loss 0.42747218
iteration 3891, loss 0.61031817
iteration 3892, loss 0.52702394
iteration 3893, loss 0.56454650
iteration 3894, loss 0.52009709
iteration 3895, loss 0.67157402
iteration 3896, loss 0.64427070
iteration 3897, loss 0.55583135
iteration 3898, loss 0.47449596
iteration 3899, loss 0.63422849
iteration 3900, loss 0.48239727
iteration 3901, loss 0.51466857
iteration 3902, loss 0.51569323
iteration 3903, loss 0.53914742
iteration 3904, loss 0.49076017
iteration 3905, loss 0.57988220
iteration 3906, loss 0.54117356
iteration 3907, loss 0.62565790
iteration 3908, loss 0.51165884
iteration 3909, loss 0.49115882
iteration 3910, loss 0.48696664
iteration 3911, loss 0.48290641
iteration 3912, loss 0.48413340
iteration 3913, loss 0.54451184
iteration 3914, loss 0.56566337
iteration 3915, loss 0.49496832
iteration 3916, loss 0.61652480
iteration 3917, loss 0.43520837
iteration 3918, loss 0.62116385
iteration 3919, loss 0.62861919
iteration 3920, loss 0.50676804
iteration 3921, loss 0.52860208
iteration 3922, loss 0.51998144
iteration 3923, loss 0.51742878
iteration 3924, loss 0.57678656
iteration 3925, loss 0.65835769
iteration 3926, loss 0.49398663
iteration 3927, loss 0.43582432
iteration 3928, loss 0.51468775
iteration 3929, loss 0.50782682
iteration 3930, loss 0.49469661
iteration 3931, loss 0.48460595
iteration 3932, loss 0.51224977
iteration 3933, loss 0.48719074
iteration 3934, loss 0.55455395
iteration 3935, loss 0.48590980
iteration 3936, loss 0.59415451
iteration 3937, loss 0.53937530
iteration 3938, loss 0.53062625
iteration 3939, loss 0.51045625
iteration 3940, loss 0.54414006
iteration 3941, loss 0.46648362
iteration 3942, loss 0.60403045
iteration 3943, loss 0.54685691
iteration 3944, loss 0.52231522
iteration 3945, loss 0.47713226
iteration 3946, loss 0.45622064
iteration 3947, loss 0.69894001
iteration 3948, loss 0.56421432
iteration 3949, loss 0.50145239
iteration 3950, loss 0.58521339
iteration 3951, loss 0.49282681
iteration 3952, loss 0.55831148
iteration 3953, loss 0.59513059
iteration 3954, loss 0.49871305
iteration 3955, loss 0.49387753
iteration 3956, loss 0.57465014
iteration 3957, loss 0.50131148
iteration 3958, loss 0.55710631
iteration 3959, loss 0.49280849
iteration 3960, loss 0.50710536
iteration 3961, loss 0.50850745
iteration 3962, loss 0.52985250
iteration 3963, loss 0.65498705
iteration 3964, loss 0.55686834
iteration 3965, loss 0.54064308
iteration 3966, loss 0.50916314
iteration 3967, loss 0.50649770
iteration 3968, loss 0.49827230
iteration 3969, loss 0.50791283
iteration 3970, loss 0.57918196
iteration 3971, loss 0.50674833
iteration 3972, loss 0.56181480
iteration 3973, loss 0.53012058
iteration 3974, loss 0.48743625
iteration 3975, loss 0.61730751
iteration 3976, loss 0.38209512
iteration 3977, loss 0.52663664
iteration 3978, loss 0.56122187
iteration 3979, loss 0.51392175
iteration 3980, loss 0.50370000
iteration 3981, loss 0.54544415
iteration 3982, loss 0.51444676
iteration 3983, loss 0.52379404
iteration 3984, loss 0.51368725
iteration 3985, loss 0.50925706
iteration 3986, loss 0.54147173
iteration 3987, loss 0.48847722
iteration 3988, loss 0.47533598
iteration 3989, loss 0.52799064
iteration 3990, loss 0.51215533
iteration 3991, loss 0.47418431
iteration 3992, loss 0.51633580
iteration 3993, loss 0.60805091
iteration 3994, loss 0.47782563
iteration 3995, loss 0.64383912
iteration 3996, loss 0.55910896
iteration 3997, loss 0.58421621
iteration 3998, loss 0.64958598
iteration 3999, loss 0.48720179
iteration 4000, loss 0.54090662
iteration 4001, loss 0.48076119
iteration 4002, loss 0.50696638
iteration 4003, loss 0.50356703
iteration 4004, loss 0.71513096
iteration 4005, loss 0.67918059
iteration 4006, loss 0.54854661
iteration 4007, loss 0.44565186
iteration 4008, loss 0.50486273
iteration 4009, loss 0.54331502
iteration 4010, loss 0.49417338
iteration 4011, loss 0.62251513
iteration 4012, loss 0.60609210
iteration 4013, loss 0.59833791
iteration 4014, loss 0.48009939
iteration 4015, loss 0.52263650
iteration 4016, loss 0.51959761
iteration 4017, loss 0.52759772
iteration 4018, loss 0.55455361
iteration 4019, loss 0.52098531
iteration 4020, loss 0.50412580
iteration 4021, loss 0.49936323
iteration 4022, loss 0.50807180
iteration 4023, loss 0.48737456
iteration 4024, loss 0.54013791
iteration 4025, loss 0.48346766
iteration 4026, loss 0.48443816
iteration 4027, loss 0.66302994
iteration 4028, loss 0.48579320
iteration 4029, loss 0.62929445
iteration 4030, loss 0.58002706
iteration 4031, loss 0.48886492
iteration 4032, loss 0.54881125
iteration 4033, loss 0.47448916
iteration 4034, loss 0.57716246
iteration 4035, loss 0.50802184
iteration 4036, loss 0.56903043
iteration 4037, loss 0.45112799
iteration 4038, loss 0.58297991
iteration 4039, loss 0.54610990
iteration 4040, loss 0.54394372
iteration 4041, loss 0.43551321
iteration 4042, loss 0.48664735
iteration 4043, loss 0.65725814
iteration 4044, loss 0.60573227
iteration 4045, loss 0.49912055
iteration 4046, loss 0.47886038
iteration 4047, loss 0.52273756
iteration 4048, loss 0.55955525
iteration 4049, loss 0.68502504
iteration 4050, loss 0.50268135
iteration 4051, loss 0.52795492
iteration 4052, loss 0.61032283
iteration 4053, loss 0.42350647
iteration 4054, loss 0.48042326
iteration 4055, loss 0.53489402
iteration 4056, loss 0.57470924
iteration 4057, loss 0.49422417
iteration 4058, loss 0.56329952
iteration 4059, loss 0.56764772
iteration 4060, loss 0.58771804
iteration 4061, loss 0.56894530
iteration 4062, loss 0.52502235
iteration 4063, loss 0.43712179
iteration 4064, loss 0.55312065
iteration 4065, loss 0.54828992
iteration 4066, loss 0.55908815
iteration 4067, loss 0.51357171
iteration 4068, loss 0.56309057
iteration 4069, loss 0.57771396
iteration 4070, loss 0.50353941
iteration 4071, loss 0.70157793
iteration 4072, loss 0.64279845
iteration 4073, loss 0.52003046
iteration 4074, loss 0.52377727
iteration 4075, loss 0.57778512
iteration 4076, loss 0.56645741
iteration 4077, loss 0.53255993
iteration 4078, loss 0.55382799
iteration 4079, loss 0.50190481
iteration 4080, loss 0.46301253
iteration 4081, loss 0.55750726
iteration 4082, loss 0.61518710
iteration 4083, loss 0.47440294
iteration 4084, loss 0.46961886
iteration 4085, loss 0.50334572
iteration 4086, loss 0.48503479
iteration 4087, loss 0.56585143
iteration 4088, loss 0.55962677
iteration 4089, loss 0.50088688
iteration 4090, loss 0.60997092
iteration 4091, loss 0.48776593
iteration 4092, loss 0.53019392
iteration 4093, loss 0.52171940
iteration 4094, loss 0.51352132
iteration 4095, loss 0.49365975
iteration 4096, loss 0.49840092
iteration 4097, loss 0.51839017
iteration 4098, loss 0.49286357
iteration 4099, loss 0.50350315
iteration 4100, loss 0.50187949
iteration 4101, loss 0.45700567
iteration 4102, loss 0.51933596
iteration 4103, loss 0.53493555
iteration 4104, loss 0.45444782
iteration 4105, loss 0.47823365
iteration 4106, loss 0.52782845
iteration 4107, loss 0.47460724
iteration 4108, loss 0.50507782
iteration 4109, loss 0.51437076
iteration 4110, loss 0.52411221
iteration 4111, loss 0.49719823
iteration 4112, loss 0.60374562
iteration 4113, loss 0.50983749
iteration 4114, loss 0.56729325
iteration 4115, loss 0.67922342
iteration 4116, loss 0.59312662
iteration 4117, loss 0.47464845
iteration 4118, loss 0.50134255
iteration 4119, loss 0.54678840
iteration 4120, loss 0.54503548
iteration 4121, loss 0.50205843
iteration 4122, loss 0.50685368
iteration 4123, loss 0.48972450
iteration 4124, loss 0.51020778
iteration 4125, loss 0.55209995
iteration 4126, loss 0.49897654
iteration 4127, loss 0.50960106
iteration 4128, loss 0.56500954
iteration 4129, loss 0.69692612
iteration 4130, loss 0.47320272
iteration 4131, loss 0.58573793
iteration 4132, loss 0.52147024
iteration 4133, loss 0.52179828
iteration 4134, loss 0.51679605
iteration 4135, loss 0.52998823
iteration 4136, loss 0.49984567
iteration 4137, loss 0.49054973
iteration 4138, loss 0.50672818
iteration 4139, loss 0.49460552
iteration 4140, loss 0.46380005
iteration 4141, loss 0.50116320
iteration 4142, loss 0.53407613
iteration 4143, loss 0.53741399
iteration 4144, loss 0.50164545
iteration 4145, loss 0.56900391
iteration 4146, loss 0.55266746
iteration 4147, loss 0.47293788
iteration 4148, loss 0.49366416
iteration 4149, loss 0.53694894
iteration 4150, loss 0.48312820
iteration 4151, loss 0.49795930
iteration 4152, loss 0.52810176
iteration 4153, loss 0.50863722
iteration 4154, loss 0.48550843
iteration 4155, loss 0.56085540
iteration 4156, loss 0.51332216
iteration 4157, loss 0.53673215
iteration 4158, loss 0.49608596
iteration 4159, loss 0.50677615
iteration 4160, loss 0.48695690
iteration 4161, loss 0.56422816
iteration 4162, loss 0.43610352
iteration 4163, loss 0.51666943
iteration 4164, loss 0.65675466
iteration 4165, loss 0.59154555
iteration 4166, loss 0.79926327
iteration 4167, loss 0.54138234
iteration 4168, loss 0.50534047
iteration 4169, loss 0.59105634
iteration 4170, loss 0.53429848
iteration 4171, loss 0.63368957
iteration 4172, loss 0.56477442
iteration 4173, loss 0.61986827
iteration 4174, loss 0.78155849
iteration 4175, loss 0.57033541
iteration 4176, loss 0.53303542
iteration 4177, loss 0.45869756
iteration 4178, loss 0.50970002
iteration 4179, loss 0.55025187
iteration 4180, loss 0.50919832
iteration 4181, loss 0.51400052
iteration 4182, loss 0.51356920
iteration 4183, loss 0.49454418
iteration 4184, loss 0.49024574
iteration 4185, loss 0.55231044
iteration 4186, loss 0.49877444
iteration 4187, loss 0.53051127
iteration 4188, loss 0.49114772
iteration 4189, loss 0.53632100
iteration 4190, loss 0.57949965
iteration 4191, loss 0.49455429
iteration 4192, loss 0.48866111
iteration 4193, loss 0.56721004
iteration 4194, loss 0.48127965
iteration 4195, loss 0.46378110
iteration 4196, loss 0.52114334
iteration 4197, loss 0.62765146
iteration 4198, loss 0.56225435
iteration 4199, loss 0.54855222
iteration 4200, loss 0.48987200
iteration 4201, loss 0.48303170
iteration 4202, loss 0.64491127
iteration 4203, loss 0.59022152
iteration 4204, loss 0.48478708
iteration 4205, loss 0.57352617
iteration 4206, loss 0.48058378
iteration 4207, loss 0.52795878
iteration 4208, loss 0.49997670
iteration 4209, loss 0.54301287
iteration 4210, loss 0.59922472
iteration 4211, loss 0.49300121
iteration 4212, loss 0.59267467
iteration 4213, loss 0.55552506
iteration 4214, loss 0.52552026
iteration 4215, loss 0.43850300
iteration 4216, loss 0.58363182
iteration 4217, loss 0.53741028
iteration 4218, loss 0.51266163
iteration 4219, loss 0.50531448
iteration 4220, loss 0.47884327
iteration 4221, loss 0.48854207
iteration 4222, loss 0.54322747
iteration 4223, loss 0.48850922
iteration 4224, loss 0.54664376
iteration 4225, loss 0.47615271
iteration 4226, loss 0.58072527
iteration 4227, loss 0.71143647
iteration 4228, loss 0.60064953
iteration 4229, loss 0.42483931
iteration 4230, loss 0.48555726
iteration 4231, loss 0.52223623
iteration 4232, loss 0.49544779
iteration 4233, loss 0.55761942
iteration 4234, loss 0.64030739
iteration 4235, loss 0.57971014
iteration 4236, loss 0.46369103
iteration 4237, loss 0.49817149
iteration 4238, loss 0.53249402
iteration 4239, loss 0.49239857
iteration 4240, loss 0.49487348
iteration 4241, loss 0.48329656
iteration 4242, loss 0.47220740
iteration 4243, loss 0.48642449
iteration 4244, loss 0.48218664
iteration 4245, loss 0.49107704
iteration 4246, loss 0.48610960
iteration 4247, loss 0.48535208
iteration 4248, loss 0.54858381
iteration 4249, loss 0.47164357
iteration 4250, loss 0.61789786
iteration 4251, loss 0.51154282
iteration 4252, loss 0.62858345
iteration 4253, loss 0.50093889
iteration 4254, loss 0.44429467
iteration 4255, loss 0.49532619
iteration 4256, loss 0.55859556
iteration 4257, loss 0.51700878
iteration 4258, loss 0.51503542
iteration 4259, loss 0.48271061
iteration 4260, loss 0.64209988
iteration 4261, loss 0.50396201
iteration 4262, loss 0.51368871
iteration 4263, loss 0.57218183
iteration 4264, loss 0.53103430
iteration 4265, loss 0.50665300
iteration 4266, loss 0.43398232
iteration 4267, loss 0.46923630
iteration 4268, loss 0.48593892
iteration 4269, loss 0.68041941
iteration 4270, loss 0.65509014
iteration 4271, loss 0.45175455
iteration 4272, loss 0.50608741
iteration 4273, loss 0.55102354
iteration 4274, loss 0.56628566
iteration 4275, loss 0.50482790
iteration 4276, loss 0.58204846
iteration 4277, loss 0.62553628
iteration 4278, loss 0.57301657
iteration 4279, loss 0.48933454
iteration 4280, loss 0.47903959
iteration 4281, loss 0.52994742
iteration 4282, loss 0.51333781
iteration 4283, loss 0.50610962
iteration 4284, loss 0.65043911
iteration 4285, loss 0.52674546
iteration 4286, loss 0.52756365
iteration 4287, loss 0.58552856
iteration 4288, loss 0.51079961
iteration 4289, loss 0.48409841
iteration 4290, loss 0.48537224
iteration 4291, loss 0.50553490
iteration 4292, loss 0.49541724
iteration 4293, loss 0.67912393
iteration 4294, loss 0.49812874
iteration 4295, loss 0.51355814
iteration 4296, loss 0.50386917
iteration 4297, loss 0.52326867
iteration 4298, loss 0.54287182
iteration 4299, loss 0.48432991
iteration 4300, loss 0.46741608
iteration 4301, loss 0.47374616
iteration 4302, loss 0.64000374
iteration 4303, loss 0.56625134
iteration 4304, loss 0.53786643
iteration 4305, loss 0.50394011
iteration 4306, loss 0.79865831
iteration 4307, loss 0.54133410
iteration 4308, loss 0.51316561
iteration 4309, loss 0.53696418
iteration 4310, loss 0.50118039
iteration 4311, loss 0.48570397
iteration 4312, loss 0.51561275
iteration 4313, loss 0.49019946
iteration 4314, loss 0.49332291
iteration 4315, loss 0.48968911
iteration 4316, loss 0.49834969
iteration 4317, loss 0.64007186
iteration 4318, loss 0.67190194
iteration 4319, loss 0.51291293
iteration 4320, loss 0.62607252
iteration 4321, loss 0.48535018
iteration 4322, loss 0.53656855
iteration 4323, loss 0.58447721
iteration 4324, loss 0.54647343
iteration 4325, loss 0.57629408
iteration 4326, loss 0.53285968
iteration 4327, loss 0.52373546
iteration 4328, loss 0.53769367
iteration 4329, loss 0.53386226
iteration 4330, loss 0.51020162
iteration 4331, loss 0.46272603
iteration 4332, loss 0.57032576
iteration 4333, loss 0.68503463
iteration 4334, loss 0.56334527
iteration 4335, loss 0.47399897
iteration 4336, loss 0.55446180
iteration 4337, loss 0.73531661
iteration 4338, loss 0.58734429
iteration 4339, loss 0.41557555
iteration 4340, loss 0.53215193
iteration 4341, loss 0.65287406
iteration 4342, loss 0.63166713
iteration 4343, loss 0.56525251
iteration 4344, loss 0.59427000
iteration 4345, loss 0.47092487
iteration 4346, loss 0.57373806
iteration 4347, loss 0.51540840
iteration 4348, loss 0.47232111
iteration 4349, loss 0.52682598
iteration 4350, loss 0.51048989
iteration 4351, loss 0.50896387
iteration 4352, loss 0.64326993
iteration 4353, loss 0.82842336
iteration 4354, loss 0.56870343
iteration 4355, loss 0.98649043
iteration 4356, loss 0.77805853
iteration 4357, loss 0.58548276
iteration 4358, loss 0.56987422
iteration 4359, loss 0.51314457
iteration 4360, loss 0.54198736
iteration 4361, loss 0.49485277
iteration 4362, loss 0.48283562
iteration 4363, loss 0.50649667
iteration 4364, loss 0.53870768
iteration 4365, loss 0.49326774
iteration 4366, loss 0.54065191
iteration 4367, loss 0.44659447
iteration 4368, loss 0.43193959
iteration 4369, loss 0.56181723
iteration 4370, loss 0.53753959
iteration 4371, loss 0.56220173
iteration 4372, loss 0.50199214
iteration 4373, loss 0.52645489
iteration 4374, loss 0.60254188
iteration 4375, loss 0.41348629
iteration 4376, loss 0.57949539
iteration 4377, loss 0.59609978
iteration 4378, loss 0.47273080
iteration 4379, loss 0.48217132
iteration 4380, loss 0.52549515
iteration 4381, loss 0.52610621
iteration 4382, loss 0.50185784
iteration 4383, loss 0.48734780
iteration 4384, loss 0.49925630
iteration 4385, loss 0.50067345
iteration 4386, loss 0.49449631
iteration 4387, loss 0.54105272
iteration 4388, loss 0.62641051
iteration 4389, loss 0.50737084
iteration 4390, loss 0.46481259
iteration 4391, loss 0.53109068
iteration 4392, loss 0.44302488
iteration 4393, loss 0.66658364
iteration 4394, loss 0.58719545
iteration 4395, loss 0.58322715
iteration 4396, loss 0.41841646
iteration 4397, loss 0.43825380
iteration 4398, loss 0.48871955
iteration 4399, loss 0.54690935
iteration 4400, loss 0.46815388
iteration 4401, loss 0.49624196
iteration 4402, loss 0.59325524
iteration 4403, loss 0.48928730
iteration 4404, loss 0.44711125
iteration 4405, loss 0.40271684
iteration 4406, loss 0.48801405
iteration 4407, loss 0.56446530
iteration 4408, loss 0.72902736
iteration 4409, loss 0.53092631
iteration 4410, loss 0.49457144
iteration 4411, loss 0.42929432
iteration 4412, loss 0.39147295
iteration 4413, loss 0.46962850
iteration 4414, loss 0.50675860
iteration 4415, loss 0.58897595
iteration 4416, loss 0.72236567
iteration 4417, loss 0.53926722
iteration 4418, loss 0.54702690
iteration 4419, loss 0.51757939
iteration 4420, loss 0.56486327
iteration 4421, loss 0.51525916
iteration 4422, loss 0.47899314
iteration 4423, loss 0.50985736
iteration 4424, loss 0.56772062
iteration 4425, loss 0.47446336
iteration 4426, loss 0.37428455
iteration 4427, loss 0.52596197
iteration 4428, loss 0.53727520
iteration 4429, loss 0.53916514
iteration 4430, loss 0.22888222
iteration 4431, loss 0.49481122
iteration 4432, loss 0.36502831
iteration 4433, loss 0.38304389
iteration 4434, loss 0.23447024
iteration 4435, loss 0.44807794
iteration 4436, loss 0.59184462
iteration 4437, loss 0.54391845
iteration 4438, loss 0.53347978
iteration 4439, loss 0.39755200
iteration 4440, loss 0.31122394
iteration 4441, loss 0.33680683
iteration 4442, loss 0.28927518
iteration 4443, loss 0.26146209
iteration 4444, loss 0.24777808
iteration 4445, loss 0.29273599
iteration 4446, loss 0.81091336
iteration 4447, loss 0.61202790
iteration 4448, loss 0.65431674
iteration 4449, loss 1.01424295
iteration 4450, loss 1.34620916
iteration 4451, loss 0.62739848
iteration 4452, loss 0.55554513
iteration 4453, loss 0.48361131
iteration 4454, loss 0.52604030
iteration 4455, loss 0.58307115
iteration 4456, loss 0.51375753
iteration 4457, loss 0.52217911
iteration 4458, loss 0.44886602
iteration 4459, loss 0.51259100
iteration 4460, loss 0.53931484
iteration 4461, loss 0.52177266
iteration 4462, loss 0.48773380
iteration 4463, loss 0.57119177
iteration 4464, loss 0.51747933
iteration 4465, loss 0.51611010
iteration 4466, loss 0.49954505
iteration 4467, loss 0.47536174
iteration 4468, loss 0.47004730
iteration 4469, loss 0.53918724
iteration 4470, loss 0.67250446
iteration 4471, loss 0.50855206
iteration 4472, loss 0.45191301
iteration 4473, loss 0.47300668
iteration 4474, loss 0.52181379
iteration 4475, loss 0.56177186
iteration 4476, loss 0.47132296
iteration 4477, loss 0.50167130
iteration 4478, loss 0.62773795
iteration 4479, loss 0.51886169
iteration 4480, loss 0.45387818
iteration 4481, loss 0.48478605
iteration 4482, loss 0.64766874
iteration 4483, loss 0.57624373
iteration 4484, loss 0.50375750
iteration 4485, loss 0.51999138
iteration 4486, loss 0.46818513
iteration 4487, loss 0.48006181
iteration 4488, loss 0.56534985
iteration 4489, loss 0.45101614
iteration 4490, loss 0.54984556
iteration 4491, loss 0.48610292
iteration 4492, loss 0.57531976
iteration 4493, loss 0.71942206
iteration 4494, loss 0.48573903
iteration 4495, loss 0.46064237
iteration 4496, loss 0.63435408
iteration 4497, loss 0.59536396
iteration 4498, loss 0.57258650
iteration 4499, loss 0.53822313
iteration 4500, loss 0.55203321
iteration 4501, loss 0.50483956
iteration 4502, loss 0.52346992
iteration 4503, loss 0.49896554
iteration 4504, loss 0.46940610
iteration 4505, loss 0.51496299
iteration 4506, loss 0.58162746
iteration 4507, loss 0.49792332
iteration 4508, loss 0.49009912
iteration 4509, loss 0.50398909
iteration 4510, loss 0.53802764
iteration 4511, loss 0.59603321
iteration 4512, loss 0.56484135
iteration 4513, loss 0.52530155
iteration 4514, loss 0.48510429
iteration 4515, loss 0.67153061
iteration 4516, loss 0.51391378
iteration 4517, loss 0.59944247
iteration 4518, loss 0.47340513
iteration 4519, loss 0.64109228
iteration 4520, loss 0.56167485
iteration 4521, loss 0.64094462
iteration 4522, loss 0.51229482
iteration 4523, loss 0.51552110
iteration 4524, loss 0.49949387
iteration 4525, loss 0.50600867
iteration 4526, loss 0.48750552
iteration 4527, loss 0.48894347
iteration 4528, loss 0.49052577
iteration 4529, loss 0.56851819
iteration 4530, loss 0.48116500
iteration 4531, loss 0.49435964
iteration 4532, loss 0.50434703
iteration 4533, loss 0.54623799
iteration 4534, loss 0.48053991
iteration 4535, loss 0.50050006
iteration 4536, loss 0.52031666
iteration 4537, loss 0.56136907
iteration 4538, loss 0.45105195
iteration 4539, loss 0.52537627
iteration 4540, loss 0.48555512
iteration 4541, loss 0.51896923
iteration 4542, loss 0.52874412
iteration 4543, loss 0.52913202
iteration 4544, loss 0.60593345
iteration 4545, loss 0.43891026
iteration 4546, loss 0.47667764
iteration 4547, loss 0.53069204
iteration 4548, loss 0.49818036
iteration 4549, loss 0.47211098
iteration 4550, loss 0.48450777
iteration 4551, loss 0.53157391
iteration 4552, loss 0.47975799
iteration 4553, loss 0.56833103
iteration 4554, loss 0.52340665
iteration 4555, loss 0.53857857
iteration 4556, loss 0.47679174
iteration 4557, loss 0.51002610
iteration 4558, loss 0.48490133
iteration 4559, loss 0.47859843
iteration 4560, loss 0.52551712
iteration 4561, loss 0.49488442
iteration 4562, loss 0.54400416
iteration 4563, loss 0.50360648
iteration 4564, loss 0.56199317
iteration 4565, loss 0.74073168
iteration 4566, loss 0.52842162
iteration 4567, loss 0.56445843
iteration 4568, loss 0.49149000
iteration 4569, loss 0.50227930
iteration 4570, loss 0.60307374
iteration 4571, loss 0.50105760
iteration 4572, loss 0.47018633
iteration 4573, loss 0.49226814
iteration 4574, loss 0.59386518
iteration 4575, loss 0.44324218
iteration 4576, loss 0.62541443
iteration 4577, loss 0.70086214
iteration 4578, loss 0.53219466
iteration 4579, loss 0.51027647
iteration 4580, loss 0.50736066
iteration 4581, loss 0.47845766
iteration 4582, loss 0.47792949
iteration 4583, loss 0.64379769
iteration 4584, loss 0.49517395
iteration 4585, loss 0.51157900
iteration 4586, loss 0.46790488
iteration 4587, loss 0.48541893
iteration 4588, loss 0.51617678
iteration 4589, loss 0.64753208
iteration 4590, loss 0.49417198
iteration 4591, loss 0.51939225
iteration 4592, loss 0.56120723
iteration 4593, loss 0.45770551
iteration 4594, loss 0.48281016
iteration 4595, loss 0.50870636
iteration 4596, loss 0.48844210
iteration 4597, loss 0.52620125
iteration 4598, loss 0.52951818
iteration 4599, loss 0.50340392
iteration 4600, loss 0.49584424
iteration 4601, loss 0.47467907
iteration 4602, loss 0.45201866
iteration 4603, loss 0.57873178
iteration 4604, loss 0.54992196
iteration 4605, loss 0.46531670
iteration 4606, loss 0.47339690
iteration 4607, loss 0.56591317
iteration 4608, loss 0.51363984
iteration 4609, loss 0.45089303
iteration 4610, loss 0.54310553
iteration 4611, loss 0.56193824
iteration 4612, loss 0.50544620
iteration 4613, loss 0.46919953
iteration 4614, loss 0.58196453
iteration 4615, loss 0.50407295
iteration 4616, loss 0.49739271
iteration 4617, loss 0.51225084
iteration 4618, loss 0.52357970
iteration 4619, loss 0.53633959
iteration 4620, loss 0.55330772
iteration 4621, loss 0.52825626
iteration 4622, loss 0.45206732
iteration 4623, loss 0.64013929
iteration 4624, loss 0.57639596
iteration 4625, loss 0.48412781
iteration 4626, loss 0.51709059
iteration 4627, loss 0.45958172
iteration 4628, loss 0.46984405
iteration 4629, loss 0.52221343
iteration 4630, loss 0.55328653
iteration 4631, loss 0.68063003
iteration 4632, loss 0.50589633
iteration 4633, loss 0.78230068
iteration 4634, loss 0.53186699
iteration 4635, loss 0.79215103
iteration 4636, loss 0.63734220
iteration 4637, loss 0.57752293
iteration 4638, loss 0.46599502
iteration 4639, loss 0.58965867
iteration 4640, loss 0.52387466
iteration 4641, loss 0.50660658
iteration 4642, loss 0.47568155
iteration 4643, loss 0.46836158
iteration 4644, loss 0.54836505
iteration 4645, loss 0.59242529
iteration 4646, loss 0.62019149
iteration 4647, loss 0.53792472
iteration 4648, loss 0.48596844
iteration 4649, loss 0.46149596
iteration 4650, loss 0.47147715
iteration 4651, loss 0.51683929
iteration 4652, loss 0.52352357
iteration 4653, loss 0.49620853
iteration 4654, loss 0.56099160
iteration 4655, loss 0.62059392
iteration 4656, loss 0.51433360
iteration 4657, loss 0.46990149
iteration 4658, loss 0.60207284
iteration 4659, loss 0.46532913
iteration 4660, loss 0.56391565
iteration 4661, loss 0.76265148
iteration 4662, loss 0.55285251
iteration 4663, loss 0.43361442
iteration 4664, loss 0.50304956
iteration 4665, loss 0.51895299
iteration 4666, loss 0.51390074
iteration 4667, loss 0.57199179
iteration 4668, loss 0.45718655
iteration 4669, loss 0.55537058
iteration 4670, loss 0.50670264
iteration 4671, loss 0.49099059
iteration 4672, loss 0.51097952
iteration 4673, loss 0.55085499
iteration 4674, loss 0.51872274
iteration 4675, loss 0.57845168
iteration 4676, loss 0.41136728
iteration 4677, loss 0.59513089
iteration 4678, loss 0.55312816
iteration 4679, loss 0.45310263
iteration 4680, loss 0.53406666
iteration 4681, loss 0.46597562
iteration 4682, loss 0.49241636
iteration 4683, loss 0.53683783
iteration 4684, loss 0.47826844
iteration 4685, loss 0.58299682
iteration 4686, loss 0.57292115
iteration 4687, loss 0.46228995
iteration 4688, loss 0.59148857
iteration 4689, loss 0.49611947
iteration 4690, loss 0.69450498
iteration 4691, loss 0.58980345
iteration 4692, loss 0.61805977
iteration 4693, loss 0.53633717
iteration 4694, loss 0.51503866
iteration 4695, loss 0.48302876
iteration 4696, loss 0.53259572
iteration 4697, loss 0.49794151
iteration 4698, loss 0.53764833
iteration 4699, loss 0.49710133
iteration 4700, loss 0.57373508
iteration 4701, loss 0.51430418
iteration 4702, loss 0.47586724
iteration 4703, loss 0.55079199
iteration 4704, loss 0.47096955
iteration 4705, loss 0.58775830
iteration 4706, loss 0.57444348
iteration 4707, loss 0.53318575
iteration 4708, loss 0.47841864
iteration 4709, loss 0.51369231
iteration 4710, loss 0.49562542
iteration 4711, loss 0.49154764
iteration 4712, loss 0.53871892
iteration 4713, loss 0.66377975
iteration 4714, loss 0.52253826
iteration 4715, loss 0.52039369
iteration 4716, loss 0.53085629
iteration 4717, loss 0.55125933
iteration 4718, loss 0.45392640
iteration 4719, loss 0.57034707
iteration 4720, loss 0.62763160
iteration 4721, loss 0.67471533
iteration 4722, loss 0.50341891
iteration 4723, loss 0.54229409
iteration 4724, loss 0.58030023
iteration 4725, loss 0.46705454
iteration 4726, loss 0.42674235
iteration 4727, loss 0.64890701
iteration 4728, loss 0.51638145
iteration 4729, loss 0.63424834
iteration 4730, loss 0.68471598
iteration 4731, loss 0.48759785
iteration 4732, loss 0.44036167
iteration 4733, loss 0.54680547
iteration 4734, loss 0.47473158
iteration 4735, loss 0.45921203
iteration 4736, loss 0.47935693
iteration 4737, loss 0.53931254
iteration 4738, loss 0.59555172
iteration 4739, loss 0.51638654
iteration 4740, loss 0.39126573
iteration 4741, loss 0.55333843
iteration 4742, loss 0.57847583
iteration 4743, loss 0.51045564
iteration 4744, loss 0.45654161
iteration 4745, loss 0.54811612
iteration 4746, loss 0.46441224
iteration 4747, loss 0.55889157
iteration 4748, loss 0.48655345
iteration 4749, loss 0.58674452
iteration 4750, loss 0.51031938
iteration 4751, loss 0.53391354
iteration 4752, loss 0.54393221
iteration 4753, loss 0.48434061
iteration 4754, loss 0.48391171
iteration 4755, loss 0.52090888
iteration 4756, loss 0.49275720
iteration 4757, loss 0.45414057
iteration 4758, loss 0.53093595
iteration 4759, loss 0.50191309
iteration 4760, loss 0.54128693
iteration 4761, loss 0.41054816
iteration 4762, loss 0.59832860
iteration 4763, loss 0.58174939
iteration 4764, loss 0.45904346
iteration 4765, loss 0.57100767
iteration 4766, loss 0.51496308
iteration 4767, loss 0.49244522
iteration 4768, loss 0.52115187
iteration 4769, loss 0.43069755
iteration 4770, loss 0.49905504
iteration 4771, loss 0.52113185
iteration 4772, loss 0.51131544
iteration 4773, loss 0.59721675
iteration 4774, loss 0.49826500
iteration 4775, loss 0.49465569
iteration 4776, loss 0.51414948
iteration 4777, loss 0.54876775
iteration 4778, loss 0.43800264
iteration 4779, loss 0.55031152
iteration 4780, loss 0.52502439
iteration 4781, loss 0.45829803
iteration 4782, loss 0.51187025
iteration 4783, loss 0.57686868
iteration 4784, loss 0.50124714
iteration 4785, loss 0.65658571
iteration 4786, loss 0.81120928
iteration 4787, loss 0.64655834
iteration 4788, loss 0.55208013
iteration 4789, loss 0.53676155
iteration 4790, loss 0.43483959
iteration 4791, loss 0.55031626
iteration 4792, loss 0.51249358
iteration 4793, loss 0.58116383
iteration 4794, loss 0.52728543
iteration 4795, loss 0.51243803
iteration 4796, loss 0.53661187
iteration 4797, loss 0.54095279
iteration 4798, loss 0.48386646
iteration 4799, loss 0.46357053
iteration 4800, loss 0.49914516
iteration 4801, loss 0.50821550
iteration 4802, loss 0.51785096
iteration 4803, loss 0.64456704
iteration 4804, loss 0.45126817
iteration 4805, loss 0.61371925
iteration 4806, loss 0.71355225
iteration 4807, loss 0.56932843
iteration 4808, loss 0.65904787
iteration 4809, loss 0.51255196
iteration 4810, loss 0.43866360
iteration 4811, loss 0.54761356
iteration 4812, loss 0.50795018
iteration 4813, loss 0.52745072
iteration 4814, loss 0.56631491
iteration 4815, loss 0.63915057
iteration 4816, loss 0.79053293
iteration 4817, loss 0.59602209
iteration 4818, loss 0.68825973
iteration 4819, loss 0.69830017
iteration 4820, loss 0.52757273
iteration 4821, loss 0.44800127
iteration 4822, loss 0.55818008
iteration 4823, loss 0.61649451
iteration 4824, loss 0.54343716
iteration 4825, loss 0.45772966
iteration 4826, loss 0.50492058
iteration 4827, loss 0.50724259
iteration 4828, loss 0.51283212
iteration 4829, loss 0.48639794
iteration 4830, loss 0.54140530
iteration 4831, loss 0.54389497
iteration 4832, loss 0.57358922
iteration 4833, loss 0.52554134
iteration 4834, loss 0.55085395
iteration 4835, loss 0.53657022
iteration 4836, loss 0.52285270
iteration 4837, loss 0.57050266
iteration 4838, loss 0.52231897
iteration 4839, loss 0.62081047
iteration 4840, loss 0.52911624
iteration 4841, loss 0.51333297
iteration 4842, loss 0.59671374
iteration 4843, loss 0.53902630
iteration 4844, loss 0.58868937
iteration 4845, loss 0.50685439
iteration 4846, loss 0.58146862
iteration 4847, loss 0.59537724
iteration 4848, loss 0.45304548
iteration 4849, loss 0.48740662
iteration 4850, loss 0.60504401
iteration 4851, loss 0.47379866
iteration 4852, loss 0.62653578
iteration 4853, loss 0.68571019
iteration 4854, loss 0.50831837
iteration 4855, loss 0.47288743
iteration 4856, loss 0.48406302
iteration 4857, loss 0.49393999
iteration 4858, loss 0.48566654
iteration 4859, loss 0.46535402
iteration 4860, loss 0.48502862
iteration 4861, loss 0.50777876
iteration 4862, loss 0.47536809
iteration 4863, loss 0.50219319
iteration 4864, loss 0.47516923
iteration 4865, loss 0.54369060
iteration 4866, loss 0.51635867
iteration 4867, loss 0.49087352
iteration 4868, loss 0.49377770
iteration 4869, loss 0.52308233
iteration 4870, loss 0.54683621
iteration 4871, loss 0.47533087
iteration 4872, loss 0.49444424
iteration 4873, loss 0.52589256
iteration 4874, loss 0.47559098
iteration 4875, loss 0.63705311
iteration 4876, loss 0.53284585
iteration 4877, loss 0.48127127
iteration 4878, loss 0.55609936
iteration 4879, loss 0.53598764
iteration 4880, loss 0.45425734
iteration 4881, loss 0.56434204
iteration 4882, loss 0.55822888
iteration 4883, loss 0.59528157
iteration 4884, loss 0.58326167
iteration 4885, loss 0.48688604
iteration 4886, loss 0.66853260
iteration 4887, loss 0.46646262
iteration 4888, loss 0.53592886
iteration 4889, loss 0.56404127
iteration 4890, loss 0.43130435
iteration 4891, loss 0.51154065
iteration 4892, loss 0.56690828
iteration 4893, loss 0.48438093
iteration 4894, loss 0.51676486
iteration 4895, loss 0.47223158
iteration 4896, loss 0.53178038
iteration 4897, loss 0.48814917
iteration 4898, loss 0.67623378
iteration 4899, loss 0.50229196
iteration 4900, loss 0.48314330
iteration 4901, loss 0.68905134
iteration 4902, loss 0.56061379
iteration 4903, loss 0.52719757
iteration 4904, loss 0.49861667
iteration 4905, loss 0.45777931
iteration 4906, loss 0.50061489
iteration 4907, loss 0.49102132
iteration 4908, loss 0.51006654
iteration 4909, loss 0.50022587
iteration 4910, loss 0.51638182
iteration 4911, loss 0.53038028
iteration 4912, loss 0.52271336
iteration 4913, loss 0.49227766
iteration 4914, loss 0.57805960
iteration 4915, loss 0.48884134
iteration 4916, loss 0.51024151
iteration 4917, loss 0.50238426
iteration 4918, loss 0.50098219
iteration 4919, loss 0.48317160
iteration 4920, loss 0.48422709
iteration 4921, loss 0.51048707
iteration 4922, loss 0.59207117
iteration 4923, loss 0.59197085
iteration 4924, loss 0.56983480
iteration 4925, loss 0.48398793
iteration 4926, loss 0.49342082
iteration 4927, loss 0.53406909
iteration 4928, loss 0.48490522
iteration 4929, loss 0.48381803
iteration 4930, loss 0.50886931
iteration 4931, loss 0.53336510
iteration 4932, loss 0.49102688
iteration 4933, loss 0.47532938
iteration 4934, loss 0.47634407
iteration 4935, loss 0.47365012
iteration 4936, loss 0.46398090
iteration 4937, loss 0.51650860
iteration 4938, loss 0.47534597
iteration 4939, loss 0.49211356
iteration 4940, loss 0.59566674
iteration 4941, loss 0.41856578
iteration 4942, loss 0.49065246
iteration 4943, loss 0.55266828
iteration 4944, loss 0.48524981
iteration 4945, loss 0.51148407
iteration 4946, loss 0.55916918
iteration 4947, loss 0.57949356
iteration 4948, loss 0.63074629
iteration 4949, loss 0.50226573
iteration 4950, loss 0.44104076
iteration 4951, loss 0.66133342
iteration 4952, loss 0.47555143
iteration 4953, loss 0.64361563
iteration 4954, loss 0.61821305
iteration 4955, loss 0.48997534
iteration 4956, loss 0.43547632
iteration 4957, loss 0.50697581
iteration 4958, loss 0.55757903
iteration 4959, loss 0.59295925
iteration 4960, loss 0.49854243
iteration 4961, loss 0.54899084
iteration 4962, loss 0.58549607
iteration 4963, loss 0.48385748
iteration 4964, loss 0.46168029
iteration 4965, loss 0.49334777
iteration 4966, loss 0.50282958
iteration 4967, loss 0.51742966
iteration 4968, loss 0.43384538
iteration 4969, loss 0.52423646
iteration 4970, loss 0.64133171
iteration 4971, loss 0.48729942
iteration 4972, loss 0.54446379
iteration 4973, loss 0.52348434
iteration 4974, loss 0.42839634
iteration 4975, loss 0.61262852
iteration 4976, loss 0.55979162
iteration 4977, loss 0.59652012
iteration 4978, loss 0.49077915
iteration 4979, loss 0.60150456
iteration 4980, loss 0.51985809
iteration 4981, loss 0.50837166
iteration 4982, loss 0.57258276
iteration 4983, loss 0.48167131
iteration 4984, loss 0.49272375
iteration 4985, loss 0.58803392
iteration 4986, loss 0.47378845
iteration 4987, loss 0.63596154
iteration 4988, loss 0.67474073
iteration 4989, loss 0.51494963
iteration 4990, loss 0.61991116
iteration 4991, loss 0.60712286
iteration 4992, loss 0.47553638
iteration 4993, loss 0.74605586
iteration 4994, loss 0.52963991
iteration 4995, loss 0.48626785
iteration 4996, loss 0.48156195
iteration 4997, loss 0.50048394
iteration 4998, loss 0.56524108
iteration 4999, loss 0.46609820
iteration 5000, loss 0.55731101
iteration 5001, loss 0.53131357
iteration 5002, loss 0.49294239
iteration 5003, loss 0.74899294
iteration 5004, loss 0.57194296
iteration 5005, loss 0.51967022
iteration 5006, loss 0.53960100
iteration 5007, loss 0.41676236
iteration 5008, loss 0.62818808
iteration 5009, loss 0.53898183
iteration 5010, loss 0.57424123
iteration 5011, loss 0.48518737
iteration 5012, loss 0.63107062
iteration 5013, loss 0.49936054
iteration 5014, loss 0.51452183
iteration 5015, loss 0.55014600
iteration 5016, loss 0.52015666
iteration 5017, loss 0.50405752
iteration 5018, loss 0.50482204
iteration 5019, loss 0.50688417
iteration 5020, loss 0.61229411
iteration 5021, loss 0.50022347
iteration 5022, loss 0.51851508
iteration 5023, loss 0.49294012
iteration 5024, loss 0.54395271
iteration 5025, loss 0.52058956
iteration 5026, loss 0.49706477
iteration 5027, loss 0.50530074
iteration 5028, loss 0.49443906
iteration 5029, loss 0.51936781
iteration 5030, loss 0.48964586
iteration 5031, loss 0.51057002
iteration 5032, loss 0.51613591
iteration 5033, loss 0.54813156
iteration 5034, loss 0.52768346
iteration 5035, loss 0.49513166
iteration 5036, loss 0.53724759
iteration 5037, loss 0.53959310
iteration 5038, loss 0.69574135
iteration 5039, loss 0.49841419
iteration 5040, loss 0.47372868
iteration 5041, loss 0.62917576
iteration 5042, loss 0.55491105
iteration 5043, loss 0.71190649
iteration 5044, loss 0.72457420
iteration 5045, loss 0.51565469
iteration 5046, loss 0.52089494
iteration 5047, loss 0.46605681
iteration 5048, loss 0.52639874
iteration 5049, loss 0.61900684
iteration 5050, loss 0.63979878
iteration 5051, loss 0.69153493
iteration 5052, loss 0.70041484
iteration 5053, loss 0.49544516
iteration 5054, loss 0.46548867
iteration 5055, loss 0.52433096
iteration 5056, loss 0.53829382
iteration 5057, loss 0.52045321
iteration 5058, loss 0.52582586
iteration 5059, loss 0.59931080
iteration 5060, loss 0.44503587
iteration 5061, loss 0.55701772
iteration 5062, loss 0.57757147
iteration 5063, loss 0.49897140
iteration 5064, loss 0.45336426
iteration 5065, loss 0.55338394
iteration 5066, loss 0.50743854
iteration 5067, loss 0.54183376
iteration 5068, loss 0.45779748
iteration 5069, loss 0.51441820
iteration 5070, loss 0.55076275
iteration 5071, loss 0.55642268
iteration 5072, loss 0.51259371
iteration 5073, loss 0.47205415
iteration 5074, loss 0.47835651
iteration 5075, loss 0.53316267
iteration 5076, loss 0.50632335
iteration 5077, loss 0.52093124
iteration 5078, loss 0.54086692
iteration 5079, loss 0.53137795
iteration 5080, loss 0.50862959
iteration 5081, loss 0.58010113
iteration 5082, loss 0.47141706
iteration 5083, loss 0.51088446
iteration 5084, loss 0.54113513
iteration 5085, loss 0.49867635
iteration 5086, loss 0.49110369
iteration 5087, loss 0.51262761
iteration 5088, loss 0.64928982
iteration 5089, loss 0.72761821
iteration 5090, loss 0.55201888
iteration 5091, loss 0.46260741
iteration 5092, loss 0.51937309
iteration 5093, loss 0.55468818
iteration 5094, loss 0.50300322
iteration 5095, loss 0.54483850
iteration 5096, loss 0.47516483
iteration 5097, loss 0.45819726
iteration 5098, loss 0.51806837
iteration 5099, loss 0.58421515
iteration 5100, loss 0.48370621
iteration 5101, loss 0.48400160
iteration 5102, loss 0.52225973
iteration 5103, loss 0.48093960
iteration 5104, loss 0.49149718
iteration 5105, loss 0.49195855
iteration 5106, loss 0.47816748
iteration 5107, loss 0.46219997
iteration 5108, loss 0.48888678
iteration 5109, loss 0.62061558
iteration 5110, loss 0.52276611
iteration 5111, loss 0.46675335
iteration 5112, loss 0.50093047
iteration 5113, loss 0.49973592
iteration 5114, loss 0.50630358
iteration 5115, loss 0.49984624
iteration 5116, loss 0.50839260
iteration 5117, loss 0.49596215
iteration 5118, loss 0.67476507
iteration 5119, loss 0.45124878
iteration 5120, loss 0.56430937
iteration 5121, loss 0.56665198
iteration 5122, loss 0.49799608
iteration 5123, loss 0.49919546
iteration 5124, loss 0.47199943
iteration 5125, loss 0.63246643
iteration 5126, loss 0.43948116
iteration 5127, loss 0.58599079
iteration 5128, loss 0.55205737
iteration 5129, loss 0.56944554
iteration 5130, loss 0.50772365
iteration 5131, loss 0.46379093
iteration 5132, loss 0.64089518
iteration 5133, loss 0.46912258
iteration 5134, loss 0.47389808
iteration 5135, loss 0.51713943
iteration 5136, loss 0.65475852
iteration 5137, loss 0.48192491
iteration 5138, loss 0.47440388
iteration 5139, loss 0.51993903
iteration 5140, loss 0.49672748
iteration 5141, loss 0.52922483
iteration 5142, loss 0.48548571
iteration 5143, loss 0.49220293
iteration 5144, loss 0.50389230
iteration 5145, loss 0.53736618
iteration 5146, loss 0.66032318
iteration 5147, loss 0.51883347
iteration 5148, loss 0.45751840
iteration 5149, loss 0.54189655
iteration 5150, loss 0.60675674
iteration 5151, loss 0.46499279
iteration 5152, loss 0.57915887
iteration 5153, loss 0.50865400
iteration 5154, loss 0.52589869
iteration 5155, loss 0.56450595
iteration 5156, loss 0.49162882
iteration 5157, loss 0.50303532
iteration 5158, loss 0.49061496
iteration 5159, loss 0.49444740
iteration 5160, loss 0.63565751
iteration 5161, loss 0.63353223
iteration 5162, loss 0.50046351
iteration 5163, loss 0.50957395
iteration 5164, loss 0.52647831
iteration 5165, loss 0.51140991
iteration 5166, loss 0.56609620
iteration 5167, loss 0.51642045
iteration 5168, loss 0.47843682
iteration 5169, loss 0.52312856
iteration 5170, loss 0.62330479
iteration 5171, loss 0.45974065
iteration 5172, loss 0.51926793
iteration 5173, loss 0.52595114
iteration 5174, loss 0.46970295
iteration 5175, loss 0.49496563
iteration 5176, loss 0.49510367
iteration 5177, loss 0.52394662
iteration 5178, loss 0.53460100
iteration 5179, loss 0.43303118
iteration 5180, loss 0.50954016
iteration 5181, loss 0.50846839
iteration 5182, loss 0.49093690
iteration 5183, loss 0.60053189
iteration 5184, loss 0.53034972
iteration 5185, loss 0.54165197
iteration 5186, loss 0.51200070
iteration 5187, loss 0.49297438
iteration 5188, loss 0.47776068
iteration 5189, loss 0.52633225
iteration 5190, loss 0.50907001
iteration 5191, loss 0.58713347
iteration 5192, loss 0.45744530
iteration 5193, loss 0.65526745
iteration 5194, loss 0.53301596
iteration 5195, loss 0.49570225
iteration 5196, loss 0.50450032
iteration 5197, loss 0.66279880
iteration 5198, loss 0.64095787
iteration 5199, loss 0.82497942
iteration 5200, loss 0.76941997
iteration 5201, loss 0.52596784
iteration 5202, loss 0.66644694
iteration 5203, loss 0.48026661
iteration 5204, loss 0.53257042
iteration 5205, loss 0.52697423
iteration 5206, loss 0.47184802
iteration 5207, loss 0.48191188
iteration 5208, loss 0.51968831
iteration 5209, loss 0.55199801
iteration 5210, loss 0.48979884
iteration 5211, loss 0.53383833
iteration 5212, loss 0.49180204
iteration 5213, loss 0.50405611
iteration 5214, loss 0.51769933
iteration 5215, loss 0.59529752
iteration 5216, loss 0.47890064
iteration 5217, loss 0.55807385
iteration 5218, loss 0.63661720
iteration 5219, loss 0.52491838
iteration 5220, loss 0.48741032
iteration 5221, loss 0.52308910
iteration 5222, loss 0.46598054
iteration 5223, loss 0.54966789
iteration 5224, loss 0.54738481
iteration 5225, loss 0.57648942
iteration 5226, loss 0.59481942
iteration 5227, loss 0.55808589
iteration 5228, loss 0.52060504
iteration 5229, loss 0.45239279
iteration 5230, loss 0.57691396
iteration 5231, loss 0.54945583
iteration 5232, loss 0.56389754
iteration 5233, loss 0.55567686
iteration 5234, loss 0.50138138
iteration 5235, loss 0.48312184
iteration 5236, loss 0.49751707
iteration 5237, loss 0.49439421
iteration 5238, loss 0.52666904
iteration 5239, loss 0.48995170
iteration 5240, loss 0.48878121
iteration 5241, loss 0.50805099
iteration 5242, loss 0.54926614
iteration 5243, loss 0.47003668
iteration 5244, loss 0.62803287
iteration 5245, loss 0.69960295
iteration 5246, loss 0.60789591
iteration 5247, loss 0.44874483
iteration 5248, loss 0.55003750
iteration 5249, loss 0.59702720
iteration 5250, loss 0.57537536
iteration 5251, loss 0.45746782
iteration 5252, loss 0.51024957
iteration 5253, loss 0.56865388
iteration 5254, loss 0.49274398
iteration 5255, loss 0.47149282
iteration 5256, loss 0.57160289
iteration 5257, loss 0.45151743
iteration 5258, loss 0.58792536
iteration 5259, loss 0.66712139
iteration 5260, loss 0.46362021
iteration 5261, loss 0.46176080
iteration 5262, loss 0.48261005
iteration 5263, loss 0.65789447
iteration 5264, loss 0.47685301
iteration 5265, loss 0.51791048
iteration 5266, loss 0.61608770
iteration 5267, loss 0.49842812
iteration 5268, loss 0.56247671
iteration 5269, loss 0.58833476
iteration 5270, loss 0.50240661
iteration 5271, loss 0.75010002
iteration 5272, loss 0.60596755
iteration 5273, loss 0.79448202
iteration 5274, loss 0.53714499
iteration 5275, loss 0.49718543
iteration 5276, loss 0.52882730
iteration 5277, loss 0.51286971
iteration 5278, loss 0.49977186
iteration 5279, loss 0.47172077
iteration 5280, loss 0.52171542
iteration 5281, loss 0.50360701
iteration 5282, loss 0.55850776
iteration 5283, loss 0.45690743
iteration 5284, loss 0.54734830
iteration 5285, loss 0.54817770
iteration 5286, loss 0.49861222
iteration 5287, loss 0.50618266
iteration 5288, loss 0.47862485
iteration 5289, loss 0.54398438
iteration 5290, loss 0.48502232
iteration 5291, loss 0.48807807
iteration 5292, loss 0.48404775
iteration 5293, loss 0.49665162
iteration 5294, loss 0.47103308
iteration 5295, loss 0.53654326
iteration 5296, loss 0.46776154
iteration 5297, loss 0.60518079
iteration 5298, loss 0.48851342
iteration 5299, loss 0.50328574
iteration 5300, loss 0.52897499
iteration 5301, loss 0.53214780
iteration 5302, loss 0.48272833
iteration 5303, loss 0.58014439
iteration 5304, loss 0.50499147
iteration 5305, loss 0.46808080
iteration 5306, loss 0.48442984
iteration 5307, loss 0.48834507
iteration 5308, loss 0.57432144
iteration 5309, loss 0.45977068
iteration 5310, loss 0.49482910
iteration 5311, loss 0.55812799
iteration 5312, loss 0.53839950
iteration 5313, loss 0.45043275
iteration 5314, loss 0.53554024
iteration 5315, loss 0.51395263
iteration 5316, loss 0.64238662
iteration 5317, loss 0.51280938
iteration 5318, loss 0.69017706
iteration 5319, loss 0.57684531
iteration 5320, loss 0.60181428
iteration 5321, loss 0.58279196
iteration 5322, loss 0.57272957
iteration 5323, loss 0.58725830
iteration 5324, loss 0.55694571
iteration 5325, loss 0.51338638
iteration 5326, loss 0.65035288
iteration 5327, loss 0.55124188
iteration 5328, loss 0.54523796
iteration 5329, loss 0.63111593
iteration 5330, loss 0.52084576
iteration 5331, loss 0.62157295
iteration 5332, loss 0.44243960
iteration 5333, loss 0.51472683
iteration 5334, loss 0.48467607
iteration 5335, loss 0.50080061
iteration 5336, loss 0.61515158
iteration 5337, loss 0.43174260
iteration 5338, loss 0.52791566
iteration 5339, loss 0.57997775
iteration 5340, loss 0.53173644
iteration 5341, loss 0.48096326
iteration 5342, loss 0.50584446
iteration 5343, loss 0.52808815
iteration 5344, loss 0.52600961
iteration 5345, loss 0.53831799
iteration 5346, loss 0.50979720
iteration 5347, loss 0.51001343
iteration 5348, loss 0.48731827
iteration 5349, loss 0.50176286
iteration 5350, loss 0.50278543
iteration 5351, loss 0.49502301
iteration 5352, loss 0.54928217
iteration 5353, loss 0.47736842
iteration 5354, loss 0.49401847
iteration 5355, loss 0.57404884
iteration 5356, loss 0.52263904
iteration 5357, loss 0.61124803
iteration 5358, loss 0.49123541
iteration 5359, loss 0.52648645
iteration 5360, loss 0.58021098
iteration 5361, loss 0.53316293
iteration 5362, loss 0.41354530
iteration 5363, loss 0.55720334
iteration 5364, loss 0.59892444
iteration 5365, loss 0.56891476
iteration 5366, loss 0.43667560
iteration 5367, loss 0.51846120
iteration 5368, loss 0.49527064
iteration 5369, loss 0.50860106
iteration 5370, loss 0.53573158
iteration 5371, loss 0.48324677
iteration 5372, loss 0.49652059
iteration 5373, loss 0.54515676
iteration 5374, loss 0.48345002
iteration 5375, loss 0.51700968
iteration 5376, loss 0.48562888
iteration 5377, loss 0.61953243
iteration 5378, loss 0.48450640
iteration 5379, loss 0.48846356
iteration 5380, loss 0.53574994
iteration 5381, loss 0.48659566
iteration 5382, loss 0.50187237
iteration 5383, loss 0.54006672
iteration 5384, loss 0.57130759
iteration 5385, loss 0.48750928
iteration 5386, loss 0.51583240
iteration 5387, loss 0.49175551
iteration 5388, loss 0.47199211
iteration 5389, loss 0.48156452
iteration 5390, loss 0.56527481
iteration 5391, loss 0.51657809
iteration 5392, loss 0.49308528
iteration 5393, loss 0.54579339
iteration 5394, loss 0.48842646
iteration 5395, loss 0.50688085
iteration 5396, loss 0.62696108
iteration 5397, loss 0.50801549
iteration 5398, loss 0.53108436
iteration 5399, loss 0.46652968
iteration 5400, loss 0.50010462
iteration 5401, loss 0.57066837
iteration 5402, loss 0.47404131
iteration 5403, loss 0.49019964
iteration 5404, loss 0.50138719
iteration 5405, loss 0.49254878
iteration 5406, loss 0.51330001
iteration 5407, loss 0.53104166
iteration 5408, loss 0.51596667
iteration 5409, loss 0.48107198
iteration 5410, loss 0.56193280
iteration 5411, loss 0.50368107
iteration 5412, loss 0.50765521
iteration 5413, loss 0.50326676
iteration 5414, loss 0.50841771
iteration 5415, loss 0.50874396
iteration 5416, loss 0.48326978
iteration 5417, loss 0.50911839
iteration 5418, loss 0.54313741
iteration 5419, loss 0.51805160
iteration 5420, loss 0.66258111
iteration 5421, loss 0.48431236
iteration 5422, loss 0.64841010
iteration 5423, loss 0.53116440
iteration 5424, loss 0.58725679
iteration 5425, loss 0.50577317
iteration 5426, loss 0.49009462
iteration 5427, loss 0.49646538
iteration 5428, loss 0.52349383
iteration 5429, loss 0.56013291
iteration 5430, loss 0.53536362
iteration 5431, loss 0.61591295
iteration 5432, loss 0.62943017
iteration 5433, loss 0.52069920
iteration 5434, loss 0.46143420
iteration 5435, loss 0.47761660
iteration 5436, loss 0.48732936
iteration 5437, loss 0.72259591
iteration 5438, loss 0.54019146
iteration 5439, loss 0.80853465
iteration 5440, loss 0.66521406
iteration 5441, loss 0.49968677
iteration 5442, loss 0.47766927
iteration 5443, loss 0.54982113
iteration 5444, loss 0.57087168
iteration 5445, loss 0.58914705
iteration 5446, loss 0.48021039
iteration 5447, loss 0.50150396
iteration 5448, loss 0.54814237
iteration 5449, loss 0.61712352
iteration 5450, loss 0.57915811
iteration 5451, loss 0.60104945
iteration 5452, loss 0.70002061
iteration 5453, loss 0.61710124
iteration 5454, loss 0.55028409
iteration 5455, loss 0.59277900
iteration 5456, loss 0.53903571
iteration 5457, loss 0.55245146
iteration 5458, loss 0.43883470
iteration 5459, loss 0.63708874
iteration 5460, loss 0.60714723
iteration 5461, loss 0.53562688
iteration 5462, loss 0.47228511
iteration 5463, loss 0.48431762
iteration 5464, loss 0.52968311
iteration 5465, loss 0.48764759
iteration 5466, loss 0.47869786
iteration 5467, loss 0.60073610
iteration 5468, loss 0.45902855
iteration 5469, loss 0.50966179
iteration 5470, loss 0.51005694
iteration 5471, loss 0.57897626
iteration 5472, loss 0.72250105
iteration 5473, loss 0.55423329
iteration 5474, loss 0.69932787
iteration 5475, loss 0.45081438
iteration 5476, loss 0.60329619
iteration 5477, loss 0.70417385
iteration 5478, loss 0.56426037
iteration 5479, loss 0.45566481
iteration 5480, loss 0.56568297
iteration 5481, loss 0.53922146
iteration 5482, loss 0.48769342
iteration 5483, loss 0.49634033
iteration 5484, loss 0.52126526
iteration 5485, loss 0.48205730
iteration 5486, loss 0.49260546
iteration 5487, loss 0.47652131
iteration 5488, loss 0.62551189
iteration 5489, loss 0.49947494
iteration 5490, loss 0.65362337
iteration 5491, loss 0.50471449
iteration 5492, loss 0.60063951
iteration 5493, loss 0.55149119
iteration 5494, loss 0.48815108
iteration 5495, loss 0.58087704
iteration 5496, loss 0.53212943
iteration 5497, loss 0.50943921
iteration 5498, loss 0.66674766
iteration 5499, loss 0.46749447
iteration 5500, loss 0.59841630
iteration 5501, loss 0.78901451
iteration 5502, loss 0.89317115
iteration 5503, loss 0.67733811
iteration 5504, loss 0.40835465
iteration 5505, loss 0.51254579
iteration 5506, loss 0.49170718
iteration 5507, loss 0.48603484
iteration 5508, loss 0.46074836
iteration 5509, loss 0.46344343
iteration 5510, loss 0.54843065
iteration 5511, loss 0.49021731
iteration 5512, loss 0.50123388
iteration 5513, loss 0.53231683
iteration 5514, loss 0.47292527
iteration 5515, loss 0.48267561
iteration 5516, loss 0.54704082
iteration 5517, loss 0.49135196
iteration 5518, loss 0.47299975
iteration 5519, loss 0.51531469
iteration 5520, loss 0.58808194
iteration 5521, loss 0.54129130
iteration 5522, loss 0.61845509
iteration 5523, loss 0.54894867
iteration 5524, loss 0.45123987
iteration 5525, loss 0.53413941
iteration 5526, loss 0.47692792
iteration 5527, loss 0.54773091
iteration 5528, loss 0.56317959
iteration 5529, loss 0.62310113
iteration 5530, loss 0.48318568
iteration 5531, loss 0.47888804
iteration 5532, loss 0.54418714
iteration 5533, loss 0.50008901
iteration 5534, loss 0.49411500
iteration 5535, loss 0.49116204
iteration 5536, loss 0.68308962
iteration 5537, loss 0.68227814
iteration 5538, loss 0.55373449
iteration 5539, loss 0.50910382
iteration 5540, loss 0.53576978
iteration 5541, loss 0.77887353
iteration 5542, loss 0.71593329
iteration 5543, loss 0.50268745
iteration 5544, loss 0.43944395
iteration 5545, loss 0.51708264
iteration 5546, loss 0.52041460
iteration 5547, loss 0.49081129
iteration 5548, loss 0.52492739
iteration 5549, loss 0.48438785
iteration 5550, loss 0.51761119
iteration 5551, loss 0.49035676
iteration 5552, loss 0.58235194
iteration 5553, loss 0.46455143
iteration 5554, loss 0.60526911
iteration 5555, loss 0.50792733
iteration 5556, loss 0.54545175
iteration 5557, loss 0.48430316
iteration 5558, loss 0.54976318
iteration 5559, loss 0.55664483
iteration 5560, loss 0.51562395
iteration 5561, loss 0.50386478
iteration 5562, loss 0.60951460
iteration 5563, loss 0.52826682
iteration 5564, loss 0.58484369
iteration 5565, loss 0.47433215
iteration 5566, loss 0.69646900
iteration 5567, loss 0.59951465
iteration 5568, loss 0.49067642
iteration 5569, loss 0.46807655
iteration 5570, loss 0.53595693
iteration 5571, loss 0.50770585
iteration 5572, loss 0.57874323
iteration 5573, loss 0.48873651
iteration 5574, loss 0.48144219
iteration 5575, loss 0.53704959
iteration 5576, loss 0.45208082
iteration 5577, loss 0.54874322
iteration 5578, loss 0.51719888
iteration 5579, loss 0.47523616
iteration 5580, loss 0.55509014
iteration 5581, loss 0.49437158
iteration 5582, loss 0.46351571
iteration 5583, loss 0.49287321
iteration 5584, loss 0.48489487
iteration 5585, loss 0.54996380
iteration 5586, loss 0.65112419
iteration 5587, loss 0.57795890
iteration 5588, loss 0.50324713
iteration 5589, loss 0.57796529
iteration 5590, loss 0.75233953
iteration 5591, loss 0.69889974
iteration 5592, loss 0.61415270
iteration 5593, loss 0.38337044
iteration 5594, loss 0.56984800
iteration 5595, loss 0.63682245
iteration 5596, loss 0.52638438
iteration 5597, loss 0.59364596
iteration 5598, loss 0.53336241
iteration 5599, loss 0.50710248
iteration 5600, loss 0.50077590
iteration 5601, loss 0.53608806
iteration 5602, loss 0.48884610
iteration 5603, loss 0.49434637
iteration 5604, loss 0.50233363
iteration 5605, loss 0.50891557
iteration 5606, loss 0.51482943
iteration 5607, loss 0.48902210
iteration 5608, loss 0.64039308
iteration 5609, loss 0.47692028
iteration 5610, loss 0.70033412
iteration 5611, loss 0.48510397
iteration 5612, loss 0.45532942
iteration 5613, loss 0.51685681
iteration 5614, loss 0.59450461
iteration 5615, loss 0.50450860
iteration 5616, loss 0.50231175
iteration 5617, loss 0.55110658
iteration 5618, loss 0.44857377
iteration 5619, loss 0.48054203
iteration 5620, loss 0.52475368
iteration 5621, loss 0.59093501
iteration 5622, loss 0.50778384
iteration 5623, loss 0.56603486
iteration 5624, loss 0.65742356
iteration 5625, loss 0.63581266
iteration 5626, loss 0.56774501
iteration 5627, loss 0.54570385
iteration 5628, loss 0.48600514
iteration 5629, loss 0.50850040
iteration 5630, loss 0.47650294
iteration 5631, loss 0.62667599
iteration 5632, loss 0.48282378
iteration 5633, loss 0.50511677
iteration 5634, loss 0.50851036
iteration 5635, loss 0.51755093
iteration 5636, loss 0.51694265
iteration 5637, loss 0.45461868
iteration 5638, loss 0.52198813
iteration 5639, loss 0.46486569
iteration 5640, loss 0.53129201
iteration 5641, loss 0.51559426
iteration 5642, loss 0.56752433
iteration 5643, loss 0.46376679
iteration 5644, loss 0.56553583
iteration 5645, loss 0.63038475
iteration 5646, loss 0.65183654
iteration 5647, loss 0.51865696
iteration 5648, loss 0.62239240
iteration 5649, loss 0.58253894
iteration 5650, loss 0.60983435
iteration 5651, loss 0.48606411
iteration 5652, loss 0.59056246
iteration 5653, loss 0.52041265
iteration 5654, loss 0.47444211
iteration 5655, loss 0.48112551
iteration 5656, loss 0.47556791
iteration 5657, loss 0.60665508
iteration 5658, loss 0.47160345
iteration 5659, loss 0.47041111
iteration 5660, loss 0.56847728
iteration 5661, loss 0.48921672
iteration 5662, loss 0.54630638
iteration 5663, loss 0.46990476
iteration 5664, loss 0.48223167
iteration 5665, loss 0.54101730
iteration 5666, loss 0.61607810
iteration 5667, loss 0.44206355
iteration 5668, loss 0.43413030
iteration 5669, loss 0.51848191
iteration 5670, loss 0.53939221
iteration 5671, loss 0.50156310
iteration 5672, loss 0.48153537
iteration 5673, loss 0.45942105
iteration 5674, loss 0.52955736
iteration 5675, loss 0.50332134
iteration 5676, loss 0.49005101
iteration 5677, loss 0.48181288
iteration 5678, loss 0.54352791
iteration 5679, loss 0.72948973
iteration 5680, loss 0.77456562
iteration 5681, loss 0.52924195
iteration 5682, loss 0.48781797
iteration 5683, loss 0.61502783
iteration 5684, loss 0.50356116
iteration 5685, loss 0.48502493
iteration 5686, loss 0.54915812
iteration 5687, loss 0.50785661
iteration 5688, loss 0.52789933
iteration 5689, loss 0.52806878
iteration 5690, loss 0.47728127
iteration 5691, loss 0.60192037
iteration 5692, loss 0.52441643
iteration 5693, loss 0.50739679
iteration 5694, loss 0.50686540
iteration 5695, loss 0.49941718
iteration 5696, loss 0.50329893
iteration 5697, loss 0.48068735
iteration 5698, loss 0.48366230
iteration 5699, loss 0.52968960
iteration 5700, loss 0.57409500
iteration 5701, loss 0.65986576
iteration 5702, loss 0.44760483
iteration 5703, loss 0.55291979
iteration 5704, loss 0.51760348
iteration 5705, loss 0.49039081
iteration 5706, loss 0.51828435
iteration 5707, loss 0.53134278
iteration 5708, loss 0.55768053
iteration 5709, loss 0.51842665
iteration 5710, loss 0.54245728
iteration 5711, loss 0.51352006
iteration 5712, loss 0.62524519
iteration 5713, loss 0.45205709
iteration 5714, loss 0.56756818
iteration 5715, loss 0.52870588
iteration 5716, loss 0.57569532
iteration 5717, loss 0.55476707
iteration 5718, loss 0.49773004
iteration 5719, loss 0.50063258
iteration 5720, loss 0.59297567
iteration 5721, loss 0.60433776
iteration 5722, loss 0.49071816
iteration 5723, loss 0.55247093
iteration 5724, loss 0.50728948
iteration 5725, loss 0.54893493
iteration 5726, loss 0.49220733
iteration 5727, loss 0.48288508
iteration 5728, loss 0.54582194
iteration 5729, loss 0.50287016
iteration 5730, loss 0.49713446
iteration 5731, loss 0.48534755
iteration 5732, loss 0.47458157
iteration 5733, loss 0.55551085
iteration 5734, loss 0.54630442
iteration 5735, loss 0.51661300
iteration 5736, loss 0.46585500
iteration 5737, loss 0.51691490
iteration 5738, loss 0.52139451
iteration 5739, loss 0.55003301
iteration 5740, loss 0.55644254
iteration 5741, loss 0.60313717
iteration 5742, loss 0.51157399
iteration 5743, loss 0.61992974
iteration 5744, loss 0.66296747
iteration 5745, loss 0.53233959
iteration 5746, loss 0.46220807
iteration 5747, loss 0.51865053
iteration 5748, loss 0.53654609
iteration 5749, loss 0.63182171
iteration 5750, loss 0.56418145
iteration 5751, loss 0.47945180
iteration 5752, loss 0.64223156
iteration 5753, loss 0.53798422
iteration 5754, loss 0.62179474
iteration 5755, loss 0.49938347
iteration 5756, loss 0.56348464
iteration 5757, loss 0.59831016
iteration 5758, loss 0.47184317
iteration 5759, loss 0.67021598
iteration 5760, loss 0.54770372
iteration 5761, loss 0.54437306
iteration 5762, loss 0.47231607
iteration 5763, loss 0.53865218
iteration 5764, loss 0.45046596
iteration 5765, loss 0.72821884
iteration 5766, loss 0.58538013
iteration 5767, loss 0.59630449
iteration 5768, loss 0.52384493
iteration 5769, loss 0.55105027
iteration 5770, loss 0.57111175
iteration 5771, loss 0.62509550
iteration 5772, loss 0.51394523
iteration 5773, loss 0.48899381
iteration 5774, loss 0.54399228
iteration 5775, loss 0.54618861
iteration 5776, loss 0.47099286
iteration 5777, loss 0.54714657
iteration 5778, loss 0.54958527
iteration 5779, loss 0.51929887
iteration 5780, loss 0.45239437
iteration 5781, loss 0.50579222
iteration 5782, loss 0.65711948
iteration 5783, loss 0.61374078
iteration 5784, loss 0.48206160
iteration 5785, loss 0.47150600
iteration 5786, loss 0.47251648
iteration 5787, loss 0.52676920
iteration 5788, loss 0.52620936
iteration 5789, loss 0.56087663
iteration 5790, loss 0.52054971
iteration 5791, loss 0.54344005
iteration 5792, loss 0.65576303
iteration 5793, loss 0.49776479
iteration 5794, loss 0.48264153
iteration 5795, loss 0.53662435
iteration 5796, loss 0.67189204
iteration 5797, loss 0.54092808
iteration 5798, loss 0.61282540
iteration 5799, loss 0.48444316
iteration 5800, loss 0.48510763
iteration 5801, loss 0.55948063
iteration 5802, loss 0.50191798
iteration 5803, loss 0.51674663
iteration 5804, loss 0.46950357
iteration 5805, loss 0.44862618
iteration 5806, loss 0.50235999
iteration 5807, loss 0.48584334
iteration 5808, loss 0.53881777
iteration 5809, loss 0.56639331
iteration 5810, loss 0.55151491
iteration 5811, loss 0.49859267
iteration 5812, loss 0.59930541
iteration 5813, loss 0.43271678
iteration 5814, loss 0.58837077
iteration 5815, loss 0.57069982
iteration 5816, loss 0.50280445
iteration 5817, loss 0.50825232
iteration 5818, loss 0.48400612
iteration 5819, loss 0.53247305
iteration 5820, loss 0.52847734
iteration 5821, loss 0.62218862
iteration 5822, loss 0.56941286
iteration 5823, loss 0.65840279
iteration 5824, loss 0.53343986
iteration 5825, loss 0.51171883
iteration 5826, loss 0.57679528
iteration 5827, loss 0.51799339
iteration 5828, loss 0.46700843
iteration 5829, loss 0.59544595
iteration 5830, loss 0.56371650
iteration 5831, loss 0.61258607
iteration 5832, loss 0.45480438
iteration 5833, loss 0.45665277
iteration 5834, loss 0.52742494
iteration 5835, loss 0.55101272
iteration 5836, loss 0.55609967
iteration 5837, loss 0.48144087
iteration 5838, loss 0.59661745
iteration 5839, loss 0.49884573
iteration 5840, loss 0.44992430
iteration 5841, loss 0.62416748
iteration 5842, loss 0.48250843
iteration 5843, loss 0.51046307
iteration 5844, loss 0.58387900
iteration 5845, loss 0.50312805
iteration 5846, loss 0.49813059
iteration 5847, loss 0.53976534
iteration 5848, loss 0.52526648
iteration 5849, loss 0.54303346
iteration 5850, loss 0.52948260
iteration 5851, loss 0.45406988
iteration 5852, loss 0.51174799
iteration 5853, loss 0.52074297
iteration 5854, loss 0.47962794
iteration 5855, loss 0.52780466
iteration 5856, loss 0.50338090
iteration 5857, loss 0.49187836
iteration 5858, loss 0.53216582
iteration 5859, loss 0.51778376
iteration 5860, loss 0.45436453
iteration 5861, loss 0.57221449
iteration 5862, loss 0.49308379
iteration 5863, loss 0.57135511
iteration 5864, loss 0.53366748
iteration 5865, loss 0.53130472
iteration 5866, loss 0.47160031
iteration 5867, loss 0.48640104
iteration 5868, loss 0.51070534
iteration 5869, loss 0.50678063
iteration 5870, loss 0.49279661
iteration 5871, loss 0.48326041
iteration 5872, loss 0.49394227
iteration 5873, loss 0.52464662
iteration 5874, loss 0.41771253
iteration 5875, loss 0.47680799
iteration 5876, loss 0.56233206
iteration 5877, loss 0.51828350
iteration 5878, loss 0.50263692
iteration 5879, loss 0.46025515
iteration 5880, loss 0.45052466
iteration 5881, loss 0.49796699
iteration 5882, loss 0.57022841
iteration 5883, loss 0.54450253
iteration 5884, loss 0.46361019
iteration 5885, loss 0.49930460
iteration 5886, loss 0.52326158
iteration 5887, loss 0.49651228
iteration 5888, loss 0.52029893
iteration 5889, loss 0.57633900
iteration 5890, loss 0.49809814
iteration 5891, loss 0.50494869
iteration 5892, loss 0.62523230
iteration 5893, loss 0.52249960
iteration 5894, loss 0.56088732
iteration 5895, loss 0.55085826
iteration 5896, loss 0.52519432
iteration 5897, loss 0.49797598
iteration 5898, loss 0.53829960
iteration 5899, loss 0.53139400
iteration 5900, loss 0.64737431
iteration 5901, loss 0.47785990
iteration 5902, loss 0.51315902
iteration 5903, loss 0.62681396
iteration 5904, loss 0.62212413
iteration 5905, loss 0.50873145
iteration 5906, loss 0.52766516
iteration 5907, loss 0.53551229
iteration 5908, loss 0.48617563
iteration 5909, loss 0.46365400
iteration 5910, loss 0.54532617
iteration 5911, loss 0.47221913
iteration 5912, loss 0.58729640
iteration 5913, loss 0.62260474
iteration 5914, loss 0.45704523
iteration 5915, loss 0.50896345
iteration 5916, loss 0.48322889
iteration 5917, loss 0.62293125
iteration 5918, loss 0.43846843
iteration 5919, loss 0.51118939
iteration 5920, loss 0.50875961
iteration 5921, loss 0.48728338
iteration 5922, loss 0.56258690
iteration 5923, loss 0.50222923
iteration 5924, loss 0.51682789
iteration 5925, loss 0.50205371
iteration 5926, loss 0.50016847
iteration 5927, loss 0.49899027
iteration 5928, loss 0.48006589
iteration 5929, loss 0.56907708
iteration 5930, loss 0.54152555
iteration 5931, loss 0.49856530
iteration 5932, loss 0.59505171
iteration 5933, loss 0.48554751
iteration 5934, loss 0.55935997
iteration 5935, loss 0.50401656
iteration 5936, loss 0.51142358
iteration 5937, loss 0.67607919
iteration 5938, loss 0.65958287
iteration 5939, loss 0.76357963
iteration 5940, loss 0.54439844
iteration 5941, loss 0.76341767
iteration 5942, loss 0.45976896
iteration 5943, loss 0.47839158
iteration 5944, loss 0.57152612
iteration 5945, loss 0.54617648
iteration 5946, loss 0.46354480
iteration 5947, loss 0.60571814
iteration 5948, loss 0.70673435
iteration 5949, loss 0.57201619
iteration 5950, loss 0.57081050
iteration 5951, loss 0.42758535
iteration 5952, loss 0.54010008
iteration 5953, loss 0.53525949
iteration 5954, loss 0.56432283
iteration 5955, loss 0.42652638
iteration 5956, loss 0.46705286
iteration 5957, loss 0.48002285
iteration 5958, loss 0.55614097
iteration 5959, loss 0.62961260
iteration 5960, loss 0.50146562
iteration 5961, loss 0.55182736
iteration 5962, loss 0.50138787
iteration 5963, loss 0.49767652
iteration 5964, loss 0.47906234
iteration 5965, loss 0.50599876
iteration 5966, loss 0.52349386
iteration 5967, loss 0.48284159
iteration 5968, loss 0.52068793
iteration 5969, loss 0.51122966
iteration 5970, loss 0.48094064
iteration 5971, loss 0.50924506
iteration 5972, loss 0.54522887
iteration 5973, loss 0.54092624
iteration 5974, loss 0.52090952
iteration 5975, loss 0.48080583
iteration 5976, loss 0.51348599
iteration 5977, loss 0.51268245
iteration 5978, loss 0.49029336
iteration 5979, loss 0.46765504
iteration 5980, loss 0.49065504
iteration 5981, loss 0.57622982
iteration 5982, loss 0.55475342
iteration 5983, loss 0.56564924
iteration 5984, loss 0.71996436
iteration 5985, loss 0.53042582
iteration 5986, loss 0.41752336
iteration 5987, loss 0.54615156
iteration 5988, loss 0.85700064
iteration 5989, loss 0.75752389
iteration 5990, loss 0.48989480
iteration 5991, loss 0.50670785
iteration 5992, loss 0.61369005
iteration 5993, loss 0.67861307
iteration 5994, loss 0.54428537
iteration 5995, loss 0.54373400
iteration 5996, loss 0.51329204
iteration 5997, loss 0.49075738
iteration 5998, loss 0.54269643
iteration 5999, loss 0.48156208
iteration 6000, loss 0.46680392
iteration 6001, loss 0.59167955
iteration 6002, loss 0.45068832
iteration 6003, loss 0.48122977
iteration 6004, loss 0.49934349
iteration 6005, loss 0.49260406
iteration 6006, loss 0.46393743
iteration 6007, loss 0.58943045
iteration 6008, loss 0.46487264
iteration 6009, loss 0.51496815
iteration 6010, loss 0.55314080
iteration 6011, loss 0.58218971
iteration 6012, loss 0.49277202
iteration 6013, loss 0.48697426
iteration 6014, loss 0.56540133
iteration 6015, loss 0.51533467
iteration 6016, loss 0.60526762
iteration 6017, loss 0.55558029
iteration 6018, loss 0.41184007
iteration 6019, loss 0.65940045
iteration 6020, loss 0.56392746
iteration 6021, loss 0.46112970
iteration 6022, loss 0.45890213
iteration 6023, loss 0.50237743
iteration 6024, loss 0.50555421
iteration 6025, loss 0.50259912
iteration 6026, loss 0.45596437
iteration 6027, loss 0.57897482
iteration 6028, loss 0.52725604
iteration 6029, loss 0.57820765
iteration 6030, loss 0.61267187
iteration 6031, loss 0.54617684
iteration 6032, loss 0.42113411
iteration 6033, loss 0.62855997
iteration 6034, loss 0.54983481
iteration 6035, loss 0.57589672
iteration 6036, loss 0.44920620
iteration 6037, loss 0.48125434
iteration 6038, loss 0.51319261
iteration 6039, loss 0.46718158
iteration 6040, loss 0.52631556
iteration 6041, loss 0.57656173
iteration 6042, loss 0.50661544
iteration 6043, loss 0.52966418
iteration 6044, loss 0.59714552
iteration 6045, loss 0.47573750
iteration 6046, loss 0.48684182
iteration 6047, loss 0.54544879
iteration 6048, loss 0.45014589
iteration 6049, loss 0.62654108
iteration 6050, loss 0.71818002
iteration 6051, loss 0.62367134
iteration 6052, loss 0.58435647
iteration 6053, loss 0.47414338
iteration 6054, loss 0.46259276
iteration 6055, loss 0.59917610
iteration 6056, loss 0.47491495
iteration 6057, loss 0.62032317
iteration 6058, loss 0.55406334
iteration 6059, loss 0.43403094
iteration 6060, loss 0.52681739
iteration 6061, loss 0.45600143
iteration 6062, loss 0.58819722
iteration 6063, loss 0.52566392
iteration 6064, loss 0.49175997
iteration 6065, loss 0.50420021
iteration 6066, loss 0.47953146
iteration 6067, loss 0.55793731
iteration 6068, loss 0.48170565
iteration 6069, loss 0.52213883
iteration 6070, loss 0.49206892
iteration 6071, loss 0.62700914
iteration 6072, loss 0.46381107
iteration 6073, loss 0.52229270
iteration 6074, loss 0.53210660
iteration 6075, loss 0.57833535
iteration 6076, loss 0.63274400
iteration 6077, loss 0.71486470
iteration 6078, loss 0.65038871
iteration 6079, loss 0.48541404
iteration 6080, loss 0.48008858
iteration 6081, loss 0.48058456
iteration 6082, loss 0.55161517
iteration 6083, loss 0.46422113
iteration 6084, loss 0.50721035
iteration 6085, loss 0.46782215
iteration 6086, loss 0.48503693
iteration 6087, loss 0.54829131
iteration 6088, loss 0.50084622
iteration 6089, loss 0.49065856
iteration 6090, loss 0.51410074
iteration 6091, loss 0.48443001
iteration 6092, loss 0.48718408
iteration 6093, loss 0.51812962
iteration 6094, loss 0.50878753
iteration 6095, loss 0.47759674
iteration 6096, loss 0.56314004
iteration 6097, loss 0.69584030
iteration 6098, loss 0.52218665
iteration 6099, loss 0.59244561
iteration 6100, loss 0.50116237
iteration 6101, loss 0.51126710
iteration 6102, loss 0.54785845
iteration 6103, loss 0.49181157
iteration 6104, loss 0.52327598
iteration 6105, loss 0.49922745
iteration 6106, loss 0.56682461
iteration 6107, loss 0.52301956
iteration 6108, loss 0.45547650
iteration 6109, loss 0.50898736
iteration 6110, loss 0.50311436
iteration 6111, loss 0.49539338
iteration 6112, loss 0.67222569
iteration 6113, loss 0.45719199
iteration 6114, loss 0.59335042
iteration 6115, loss 0.75745235
iteration 6116, loss 0.56291617
iteration 6117, loss 0.52388665
iteration 6118, loss 0.50117909
iteration 6119, loss 0.50155491
iteration 6120, loss 0.46661222
iteration 6121, loss 0.58647672
iteration 6122, loss 0.49747823
iteration 6123, loss 0.48146065
iteration 6124, loss 0.49111039
iteration 6125, loss 0.49585715
iteration 6126, loss 0.49612411
iteration 6127, loss 0.59596559
iteration 6128, loss 0.52647133
iteration 6129, loss 0.45890588
iteration 6130, loss 0.47858011
iteration 6131, loss 0.48237052
iteration 6132, loss 0.51879417
iteration 6133, loss 0.45713306
iteration 6134, loss 0.51282225
iteration 6135, loss 0.56983330
iteration 6136, loss 0.54958723
iteration 6137, loss 0.46231758
iteration 6138, loss 0.51830787
iteration 6139, loss 0.44689714
iteration 6140, loss 0.56895602
iteration 6141, loss 0.52929026
iteration 6142, loss 0.54711823
iteration 6143, loss 0.49150584
iteration 6144, loss 0.57028079
iteration 6145, loss 0.54576897
iteration 6146, loss 0.54660489
iteration 6147, loss 0.45217513
iteration 6148, loss 0.47091451
iteration 6149, loss 0.54232105
iteration 6150, loss 0.51537017
iteration 6151, loss 0.51265225
iteration 6152, loss 0.45596582
iteration 6153, loss 0.49146969
iteration 6154, loss 0.48037181
iteration 6155, loss 0.50916411
iteration 6156, loss 0.42369271
iteration 6157, loss 0.41546734
iteration 6158, loss 0.71571986
iteration 6159, loss 0.31858718
iteration 6160, loss 0.50743964
iteration 6161, loss 0.59427890
iteration 6162, loss 0.55061999
iteration 6163, loss 0.43586226
iteration 6164, loss 0.66135362
iteration 6165, loss 0.80842328
iteration 6166, loss 0.52558174
iteration 6167, loss 0.54641648
iteration 6168, loss 0.48857986
iteration 6169, loss 0.52713993
iteration 6170, loss 0.55166357
iteration 6171, loss 0.54438173
iteration 6172, loss 0.45033920
iteration 6173, loss 0.59102235
iteration 6174, loss 0.49851850
iteration 6175, loss 0.56808409
iteration 6176, loss 0.58629751
iteration 6177, loss 0.50587716
iteration 6178, loss 0.44590757
iteration 6179, loss 0.55957241
iteration 6180, loss 0.49984168
iteration 6181, loss 0.49167448
iteration 6182, loss 0.49908379
iteration 6183, loss 0.49385787
iteration 6184, loss 0.46944632
iteration 6185, loss 0.51855522
iteration 6186, loss 0.56350051
iteration 6187, loss 0.49278509
iteration 6188, loss 0.57492398
iteration 6189, loss 0.64151084
iteration 6190, loss 0.50992605
iteration 6191, loss 0.55488009
iteration 6192, loss 0.53963323
iteration 6193, loss 0.48036982
iteration 6194, loss 0.53439312
iteration 6195, loss 0.48916638
iteration 6196, loss 0.53759181
iteration 6197, loss 0.63519123
iteration 6198, loss 0.55686543
iteration 6199, loss 0.50666259
iteration 6200, loss 0.53056521
iteration 6201, loss 0.57199753
iteration 6202, loss 0.49494574
iteration 6203, loss 0.65904638
iteration 6204, loss 0.63416870
iteration 6205, loss 0.52532983
iteration 6206, loss 0.51419222
iteration 6207, loss 0.50197861
iteration 6208, loss 0.61941562
iteration 6209, loss 0.54381125
iteration 6210, loss 0.53640773
iteration 6211, loss 0.47390130
iteration 6212, loss 0.51253575
iteration 6213, loss 0.48300281
iteration 6214, loss 0.55521424
iteration 6215, loss 0.49388213
iteration 6216, loss 0.53176693
iteration 6217, loss 0.46222224
iteration 6218, loss 0.57421465
iteration 6219, loss 0.52064206
iteration 6220, loss 0.59234709
iteration 6221, loss 0.44541514
iteration 6222, loss 0.52577821
iteration 6223, loss 0.49833829
iteration 6224, loss 0.54981107
iteration 6225, loss 0.47584283
iteration 6226, loss 0.50277296
iteration 6227, loss 0.53419159
iteration 6228, loss 0.48793668
iteration 6229, loss 0.54048840
iteration 6230, loss 0.54689379
iteration 6231, loss 0.40109048
iteration 6232, loss 0.63042045
iteration 6233, loss 0.52337210
iteration 6234, loss 0.48219241
iteration 6235, loss 0.48826152
iteration 6236, loss 0.53366454
iteration 6237, loss 0.61310655
iteration 6238, loss 0.49268139
iteration 6239, loss 0.61050667
iteration 6240, loss 0.56754148
iteration 6241, loss 0.61556394
iteration 6242, loss 0.53229298
iteration 6243, loss 0.50892768
iteration 6244, loss 0.48737728
iteration 6245, loss 0.55231288
iteration 6246, loss 0.47150016
iteration 6247, loss 0.56739368
iteration 6248, loss 0.50175603
iteration 6249, loss 0.51710158
iteration 6250, loss 0.47725066
iteration 6251, loss 0.51102970
iteration 6252, loss 0.54716216
iteration 6253, loss 0.47645769
iteration 6254, loss 0.48285695
iteration 6255, loss 0.49887094
iteration 6256, loss 0.54201804
iteration 6257, loss 0.48505868
iteration 6258, loss 0.48666101
iteration 6259, loss 0.50608080
iteration 6260, loss 0.49782555
iteration 6261, loss 0.52060257
iteration 6262, loss 0.48921379
iteration 6263, loss 0.48938508
iteration 6264, loss 0.48611788
iteration 6265, loss 0.53770141
iteration 6266, loss 0.51834338
iteration 6267, loss 0.52957616
iteration 6268, loss 0.48816003
iteration 6269, loss 0.56480840
iteration 6270, loss 0.60221668
iteration 6271, loss 0.45096936
iteration 6272, loss 0.51960297
iteration 6273, loss 0.56383939
iteration 6274, loss 0.53421645
iteration 6275, loss 0.63380264
iteration 6276, loss 0.41901609
iteration 6277, loss 0.79355386
iteration 6278, loss 0.63148862
iteration 6279, loss 0.56668500
iteration 6280, loss 0.47854214
iteration 6281, loss 0.45807403
iteration 6282, loss 0.55719128
iteration 6283, loss 0.55895685
iteration 6284, loss 0.55908980
iteration 6285, loss 0.48117804
iteration 6286, loss 0.51022976
iteration 6287, loss 0.57693896
iteration 6288, loss 0.58440676
iteration 6289, loss 0.56555819
iteration 6290, loss 0.67088054
iteration 6291, loss 0.56886841
iteration 6292, loss 0.49725932
iteration 6293, loss 0.51945595
iteration 6294, loss 0.48965626
iteration 6295, loss 0.50156626
iteration 6296, loss 0.51833506
iteration 6297, loss 0.47128134
iteration 6298, loss 0.51366921
iteration 6299, loss 0.51409594
iteration 6300, loss 0.55900563
iteration 6301, loss 0.65326306
iteration 6302, loss 0.60720297
iteration 6303, loss 0.50373551
iteration 6304, loss 0.45825894
iteration 6305, loss 0.70140316
iteration 6306, loss 0.57667013
iteration 6307, loss 0.54266378
iteration 6308, loss 0.56772157
iteration 6309, loss 0.55586664
iteration 6310, loss 0.64676340
iteration 6311, loss 0.74041289
iteration 6312, loss 0.54699089
iteration 6313, loss 0.56801017
iteration 6314, loss 0.51610279
iteration 6315, loss 0.49233105
iteration 6316, loss 0.51722988
iteration 6317, loss 0.48723105
iteration 6318, loss 0.48165913
iteration 6319, loss 0.52818781
iteration 6320, loss 0.54798777
iteration 6321, loss 0.39492219
iteration 6322, loss 0.60243598
iteration 6323, loss 0.58313469
iteration 6324, loss 0.49811264
iteration 6325, loss 0.48633942
iteration 6326, loss 0.51844529
iteration 6327, loss 0.51270628
iteration 6328, loss 0.57496358
iteration 6329, loss 0.55581726
iteration 6330, loss 0.53373117
iteration 6331, loss 0.52773472
iteration 6332, loss 0.65976098
iteration 6333, loss 0.47789006
iteration 6334, loss 0.51514906
iteration 6335, loss 0.53283008
iteration 6336, loss 0.43507124
iteration 6337, loss 0.54845351
iteration 6338, loss 0.54888006
iteration 6339, loss 0.61786538
iteration 6340, loss 0.48644975
iteration 6341, loss 0.49758583
iteration 6342, loss 0.55287056
iteration 6343, loss 0.50622873
iteration 6344, loss 0.52959420
iteration 6345, loss 0.54638375
iteration 6346, loss 0.50373177
iteration 6347, loss 0.51997555
iteration 6348, loss 0.55484299
iteration 6349, loss 0.77402914
iteration 6350, loss 0.54993730
iteration 6351, loss 0.85676505
iteration 6352, loss 0.53156325
iteration 6353, loss 0.42416373
iteration 6354, loss 0.51712171
iteration 6355, loss 0.62571512
iteration 6356, loss 0.51624609
iteration 6357, loss 0.47414844
iteration 6358, loss 0.52058285
iteration 6359, loss 0.46651816
iteration 6360, loss 0.57603629
iteration 6361, loss 0.47660308
iteration 6362, loss 0.48182406
iteration 6363, loss 0.52453086
iteration 6364, loss 0.50521498
iteration 6365, loss 0.54623422
iteration 6366, loss 0.47842436
iteration 6367, loss 0.54956121
iteration 6368, loss 0.51421059
iteration 6369, loss 0.49120669
iteration 6370, loss 0.50306280
iteration 6371, loss 0.59581208
iteration 6372, loss 0.58714848
iteration 6373, loss 0.51593257
iteration 6374, loss 0.48748414
iteration 6375, loss 0.63089682
iteration 6376, loss 0.49986438
iteration 6377, loss 0.50906046
iteration 6378, loss 0.48439086
iteration 6379, loss 0.49650690
iteration 6380, loss 0.48465733
iteration 6381, loss 0.48526555
iteration 6382, loss 0.53141407
iteration 6383, loss 0.49744292
iteration 6384, loss 0.50760563
iteration 6385, loss 0.52436595
iteration 6386, loss 0.46446285
iteration 6387, loss 0.49603405
iteration 6388, loss 0.54283597
iteration 6389, loss 0.49879683
iteration 6390, loss 0.49079883
iteration 6391, loss 0.49452644
iteration 6392, loss 0.53122247
iteration 6393, loss 0.51249222
iteration 6394, loss 0.52387292
iteration 6395, loss 0.47837184
iteration 6396, loss 0.47001067
iteration 6397, loss 0.45794439
iteration 6398, loss 0.56475788
iteration 6399, loss 0.51101813
iteration 6400, loss 0.45719222
iteration 6401, loss 0.58673447
iteration 6402, loss 0.51947123
iteration 6403, loss 0.61123914
iteration 6404, loss 0.48420533
iteration 6405, loss 0.60004954
iteration 6406, loss 0.68066873
iteration 6407, loss 0.53085641
iteration 6408, loss 0.51640811
iteration 6409, loss 0.54392333
iteration 6410, loss 0.48806045
iteration 6411, loss 0.56939990
iteration 6412, loss 0.62641029
iteration 6413, loss 0.80418337
iteration 6414, loss 0.54481060
iteration 6415, loss 0.43806050
iteration 6416, loss 0.53686382
iteration 6417, loss 0.53921268
iteration 6418, loss 0.48023077
iteration 6419, loss 0.50369855
iteration 6420, loss 0.49913351
iteration 6421, loss 0.55575650
iteration 6422, loss 0.59084712
iteration 6423, loss 0.61245147
iteration 6424, loss 0.49037678
iteration 6425, loss 0.62281045
iteration 6426, loss 0.57822411
iteration 6427, loss 0.53550646
iteration 6428, loss 0.63127282
iteration 6429, loss 0.50735764
iteration 6430, loss 0.49462539
iteration 6431, loss 0.53797368
iteration 6432, loss 0.51588476
iteration 6433, loss 0.61381818
iteration 6434, loss 0.53731083
iteration 6435, loss 0.53768403
iteration 6436, loss 0.47812791
iteration 6437, loss 0.52039703
iteration 6438, loss 0.53433901
iteration 6439, loss 0.45356151
iteration 6440, loss 0.45161690
iteration 6441, loss 0.51551243
iteration 6442, loss 0.50867455
iteration 6443, loss 0.55283921
iteration 6444, loss 0.47361284
iteration 6445, loss 0.56739640
iteration 6446, loss 0.46232790
iteration 6447, loss 0.48459599
iteration 6448, loss 0.51795347
iteration 6449, loss 0.53819336
iteration 6450, loss 0.48457476
iteration 6451, loss 0.47729362
iteration 6452, loss 0.55682806
iteration 6453, loss 0.57535827
iteration 6454, loss 0.51680002
iteration 6455, loss 0.50354014
iteration 6456, loss 0.50608619
iteration 6457, loss 0.59597635
iteration 6458, loss 0.48735934
iteration 6459, loss 0.67789949
iteration 6460, loss 0.56811481
iteration 6461, loss 0.68860821
iteration 6462, loss 0.45651951
iteration 6463, loss 0.45430216
iteration 6464, loss 0.54224199
iteration 6465, loss 0.51481442
iteration 6466, loss 0.50226514
iteration 6467, loss 0.46434358
iteration 6468, loss 0.52153686
iteration 6469, loss 0.51047032
iteration 6470, loss 0.52333255
iteration 6471, loss 0.48899831
iteration 6472, loss 0.53742809
iteration 6473, loss 0.49701830
iteration 6474, loss 0.52292830
iteration 6475, loss 0.59870790
iteration 6476, loss 0.48890995
iteration 6477, loss 0.60649644
iteration 6478, loss 0.53089318
iteration 6479, loss 0.45016266
iteration 6480, loss 0.49658064
iteration 6481, loss 0.82270354
iteration 6482, loss 0.57340285
iteration 6483, loss 0.55662955
iteration 6484, loss 0.45433892
iteration 6485, loss 0.40168312
iteration 6486, loss 0.53356202
iteration 6487, loss 0.42928721
iteration 6488, loss 0.54714627
iteration 6489, loss 0.38820311
iteration 6490, loss 0.59784793
iteration 6491, loss 0.42879432
iteration 6492, loss 0.47201295
iteration 6493, loss 0.40651228
iteration 6494, loss 0.38073386
iteration 6495, loss 0.40237784
iteration 6496, loss 0.50189244
iteration 6497, loss 0.51910587
iteration 6498, loss 0.50318967
iteration 6499, loss 0.47828278
iteration 6500, loss 0.36240862
iteration 6501, loss 0.52049817
iteration 6502, loss 0.47005629
iteration 6503, loss 0.39136458
iteration 6504, loss 0.49033400
iteration 6505, loss 0.45840328
iteration 6506, loss 0.41734283
iteration 6507, loss 0.37699044
iteration 6508, loss 0.63557317
iteration 6509, loss 0.45509029
iteration 6510, loss 0.39946499
iteration 6511, loss 0.41467460
iteration 6512, loss 0.43952714
iteration 6513, loss 0.40570939
iteration 6514, loss 0.39597708
iteration 6515, loss 0.43221545
iteration 6516, loss 0.37626765
iteration 6517, loss 0.43226363
iteration 6518, loss 0.42555725
iteration 6519, loss 0.42950027
iteration 6520, loss 0.42673313
iteration 6521, loss 0.64991069
iteration 6522, loss 0.44869919
iteration 6523, loss 0.42338899
iteration 6524, loss 0.41095304
iteration 6525, loss 0.37634055
iteration 6526, loss 0.45882325
iteration 6527, loss 0.55136150
iteration 6528, loss 0.63925837
iteration 6529, loss 0.37927176
iteration 6530, loss 0.60543752
iteration 6531, loss 0.55675268
iteration 6532, loss 0.45251418
iteration 6533, loss 0.44214625
iteration 6534, loss 0.42360547
iteration 6535, loss 0.46497410
iteration 6536, loss 0.57803583
iteration 6537, loss 0.40322255
iteration 6538, loss 0.53129509
iteration 6539, loss 0.58030687
iteration 6540, loss 0.51148623
iteration 6541, loss 0.67510185
iteration 6542, loss 0.55440279
iteration 6543, loss 0.53581999
iteration 6544, loss 0.46775673
iteration 6545, loss 0.51475940
iteration 6546, loss 0.48140516
iteration 6547, loss 0.53175540
iteration 6548, loss 0.48413158
iteration 6549, loss 0.53306839
iteration 6550, loss 0.49237397
iteration 6551, loss 0.56425670
iteration 6552, loss 0.73551310
iteration 6553, loss 0.51223770
iteration 6554, loss 0.49341556
iteration 6555, loss 0.53815776
iteration 6556, loss 0.47602132
iteration 6557, loss 0.74700525
iteration 6558, loss 0.83856685
iteration 6559, loss 0.71546188
iteration 6560, loss 0.49573088
iteration 6561, loss 0.47321343
iteration 6562, loss 0.49346923
iteration 6563, loss 0.46747772
iteration 6564, loss 0.59752262
iteration 6565, loss 0.59865767
iteration 6566, loss 0.39157303
iteration 6567, loss 0.53208659
iteration 6568, loss 0.61746121
iteration 6569, loss 0.46181514
iteration 6570, loss 0.31542221
iteration 6571, loss 0.50980199
iteration 6572, loss 0.53153066
iteration 6573, loss 0.38767429
iteration 6574, loss 0.45632911
iteration 6575, loss 0.40919420
iteration 6576, loss 0.67268618
iteration 6577, loss 0.61862011
iteration 6578, loss 0.38330085
iteration 6579, loss 0.45865179
iteration 6580, loss 0.45879133
iteration 6581, loss 0.40414632
iteration 6582, loss 0.39091534
iteration 6583, loss 0.41246073
iteration 6584, loss 0.41975204
iteration 6585, loss 0.36526287
iteration 6586, loss 0.45924000
iteration 6587, loss 0.42686702
iteration 6588, loss 0.36999293
iteration 6589, loss 0.53469352
iteration 6590, loss 0.42450522
iteration 6591, loss 0.39541133
iteration 6592, loss 0.36914692
iteration 6593, loss 0.35192359
iteration 6594, loss 0.67346657
iteration 6595, loss 0.53832236
iteration 6596, loss 0.41431348
iteration 6597, loss 0.39805365
iteration 6598, loss 0.42760781
iteration 6599, loss 0.42644645
iteration 6600, loss 0.39084097
iteration 6601, loss 0.42026405
iteration 6602, loss 0.53300954
iteration 6603, loss 0.42455184
iteration 6604, loss 0.39230866
iteration 6605, loss 0.37089001
iteration 6606, loss 0.48498301
iteration 6607, loss 0.39745992
iteration 6608, loss 0.38356971
iteration 6609, loss 0.53422247
iteration 6610, loss 0.46379787
iteration 6611, loss 0.35873091
iteration 6612, loss 0.44658385
iteration 6613, loss 0.46070655
iteration 6614, loss 0.40891433
iteration 6615, loss 0.39194059
iteration 6616, loss 0.43129423
iteration 6617, loss 0.49065660
iteration 6618, loss 0.38909480
iteration 6619, loss 0.35420832
iteration 6620, loss 0.47204814
iteration 6621, loss 0.42118289
iteration 6622, loss 0.42240976
iteration 6623, loss 0.48599336
iteration 6624, loss 0.43139520
iteration 6625, loss 0.57207376
iteration 6626, loss 0.55106186
iteration 6627, loss 0.42261799
iteration 6628, loss 0.42030301
iteration 6629, loss 0.41517849
iteration 6630, loss 0.40153533
iteration 6631, loss 0.55373845
iteration 6632, loss 0.37755235
iteration 6633, loss 0.52531857
iteration 6634, loss 0.45125683
iteration 6635, loss 0.36607197
iteration 6636, loss 0.37467445
iteration 6637, loss 0.48175565
iteration 6638, loss 0.43726187
iteration 6639, loss 0.41247074
iteration 6640, loss 0.53603072
iteration 6641, loss 0.49483514
iteration 6642, loss 0.42693630
iteration 6643, loss 0.55048379
iteration 6644, loss 0.52891095
iteration 6645, loss 0.46796131
iteration 6646, loss 0.48099497
iteration 6647, loss 0.45106923
iteration 6648, loss 0.41450608
iteration 6649, loss 0.44491019
iteration 6650, loss 0.39405329
iteration 6651, loss 0.49674143
iteration 6652, loss 0.43495150
iteration 6653, loss 0.42231340
iteration 6654, loss 0.37875354
iteration 6655, loss 0.57934205
iteration 6656, loss 0.42811710
iteration 6657, loss 0.36506818
iteration 6658, loss 0.55027568
iteration 6659, loss 0.51391285
iteration 6660, loss 0.41330083
iteration 6661, loss 0.42631273
iteration 6662, loss 0.44121785
iteration 6663, loss 0.39835308
iteration 6664, loss 0.44990749
iteration 6665, loss 0.43394938
iteration 6666, loss 0.51458343
iteration 6667, loss 0.44083607
iteration 6668, loss 0.40904472
iteration 6669, loss 0.38096518
iteration 6670, loss 0.54610664
iteration 6671, loss 0.48731034
iteration 6672, loss 0.37976913
iteration 6673, loss 0.44735575
iteration 6674, loss 0.35104579
iteration 6675, loss 0.39890109
iteration 6676, loss 0.48133729
iteration 6677, loss 0.34448746
iteration 6678, loss 0.35200081
iteration 6679, loss 0.42314371
iteration 6680, loss 0.44130117
iteration 6681, loss 1.54303124
iteration 6682, loss 1.49901750
iteration 6683, loss 0.66487904
iteration 6684, loss 0.57178678
iteration 6685, loss 0.68753082
iteration 6686, loss 2.21098969
iteration 6687, loss 3.09071326
iteration 6688, loss 2.46261136
iteration 6689, loss 2.10345803
iteration 6690, loss 0.93142544
iteration 6691, loss 1.35038419
iteration 6692, loss 1.16078632
iteration 6693, loss 0.92715096
iteration 6694, loss 0.81135047
iteration 6695, loss 0.92999824
iteration 6696, loss 0.86885272
iteration 6697, loss 0.85432365
iteration 6698, loss 0.81694853
iteration 6699, loss 0.83301696
iteration 6700, loss 0.83393913
iteration 6701, loss 0.89467955
iteration 6702, loss 0.81685733
iteration 6703, loss 0.79229421
iteration 6704, loss 0.83381281
iteration 6705, loss 0.83670869
iteration 6706, loss 0.79794502
iteration 6707, loss 0.91952271
iteration 6708, loss 0.89586796
iteration 6709, loss 0.81930585
iteration 6710, loss 0.82899821
iteration 6711, loss 0.82339935
iteration 6712, loss 0.85041185
iteration 6713, loss 0.88873205
iteration 6714, loss 0.99593351
iteration 6715, loss 0.91440017
iteration 6716, loss 0.81410532
iteration 6717, loss 0.89303304
iteration 6718, loss 1.06495231
iteration 6719, loss 0.91889852
iteration 6720, loss 1.05013740
iteration 6721, loss 0.94874572
iteration 6722, loss 0.86955148
iteration 6723, loss 0.86978634
iteration 6724, loss 0.80243332
iteration 6725, loss 0.91738218
iteration 6726, loss 0.94846659
iteration 6727, loss 1.05469743
iteration 6728, loss 0.83808449
iteration 6729, loss 0.95506333
iteration 6730, loss 0.79348396
iteration 6731, loss 0.89260991
iteration 6732, loss 0.96239358
iteration 6733, loss 1.08981725
iteration 6734, loss 1.03212867
iteration 6735, loss 0.99774663
iteration 6736, loss 1.02340680
iteration 6737, loss 0.78210857
iteration 6738, loss 0.90114517
iteration 6739, loss 0.90521642
iteration 6740, loss 0.90893838
iteration 6741, loss 0.88318530
iteration 6742, loss 0.86341948
iteration 6743, loss 0.79994659
iteration 6744, loss 0.93032657
iteration 6745, loss 0.86131038
iteration 6746, loss 0.84599777
iteration 6747, loss 0.97802560
iteration 6748, loss 1.01922547
iteration 6749, loss 0.90348576
iteration 6750, loss 0.81068035
iteration 6751, loss 0.90782808
iteration 6752, loss 0.89663039
iteration 6753, loss 0.83374032
iteration 6754, loss 1.10899970
iteration 6755, loss 0.85064358
iteration 6756, loss 0.97612587
iteration 6757, loss 0.84539815
iteration 6758, loss 0.96445244
iteration 6759, loss 1.02497241
iteration 6760, loss 0.82465800
iteration 6761, loss 0.87638721
iteration 6762, loss 0.83255944
iteration 6763, loss 0.95763737
iteration 6764, loss 0.83338359
iteration 6765, loss 0.87712298
iteration 6766, loss 0.83827097
iteration 6767, loss 0.83131533
iteration 6768, loss 0.83795535
iteration 6769, loss 0.84515320
iteration 6770, loss 1.02616020
iteration 6771, loss 1.16188596
iteration 6772, loss 0.93645965
iteration 6773, loss 0.88093664
iteration 6774, loss 0.96582614
iteration 6775, loss 0.94443995
iteration 6776, loss 0.84793963
iteration 6777, loss 1.01389639
iteration 6778, loss 0.83507360
iteration 6779, loss 0.82646508
iteration 6780, loss 0.86040496
iteration 6781, loss 0.82127011
iteration 6782, loss 0.83319564
iteration 6783, loss 0.92979918
iteration 6784, loss 0.95388739
iteration 6785, loss 0.81893316
iteration 6786, loss 0.97359585
iteration 6787, loss 1.12647044
iteration 6788, loss 0.80277783
iteration 6789, loss 0.89714645
iteration 6790, loss 0.90152511
iteration 6791, loss 0.86323216
iteration 6792, loss 0.76889503
iteration 6793, loss 0.80462372
iteration 6794, loss 0.88493530
iteration 6795, loss 0.84900196
iteration 6796, loss 0.91823059
iteration 6797, loss 0.92998277
iteration 6798, loss 0.86145525
iteration 6799, loss 0.97054811
iteration 6800, loss 0.76895024
iteration 6801, loss 0.95096237
iteration 6802, loss 1.01254371
iteration 6803, loss 0.90793474
iteration 6804, loss 0.84647339
iteration 6805, loss 0.89919288
iteration 6806, loss 0.82969781
iteration 6807, loss 0.87924185
iteration 6808, loss 0.86899849
iteration 6809, loss 1.02231888
iteration 6810, loss 0.83826303
iteration 6811, loss 0.83237378
iteration 6812, loss 0.85508063
iteration 6813, loss 0.88818740
iteration 6814, loss 0.83547497
iteration 6815, loss 1.05229570
iteration 6816, loss 1.02659373
iteration 6817, loss 0.88949138
iteration 6818, loss 0.85992438
iteration 6819, loss 0.91732945
iteration 6820, loss 1.24028457
iteration 6821, loss 1.02848785
iteration 6822, loss 1.14083514
iteration 6823, loss 0.86284237
iteration 6824, loss 0.98358607
iteration 6825, loss 1.14630937
iteration 6826, loss 0.94029529
iteration 6827, loss 0.98667284
iteration 6828, loss 1.15145693
iteration 6829, loss 0.99799896
iteration 6830, loss 0.80513087
iteration 6831, loss 0.74898969
iteration 6832, loss 1.01721200
iteration 6833, loss 0.80537444
iteration 6834, loss 0.89530172
iteration 6835, loss 0.88889595
iteration 6836, loss 0.93952108
iteration 6837, loss 0.92069199
iteration 6838, loss 0.83366793
iteration 6839, loss 0.86527928
iteration 6840, loss 0.86147120
iteration 6841, loss 0.93325872
iteration 6842, loss 0.93853666
iteration 6843, loss 0.88153818
iteration 6844, loss 0.78190939
iteration 6845, loss 0.86283096
iteration 6846, loss 0.85151256
iteration 6847, loss 0.98197746
iteration 6848, loss 0.88173199
iteration 6849, loss 0.82374138
iteration 6850, loss 0.89096602
iteration 6851, loss 0.78875686
iteration 6852, loss 0.91545853
iteration 6853, loss 0.85614118
iteration 6854, loss 0.95375959
iteration 6855, loss 0.79321596
iteration 6856, loss 0.85315171
iteration 6857, loss 0.82323634
iteration 6858, loss 0.85893888
iteration 6859, loss 0.98662472
iteration 6860, loss 0.97009953
iteration 6861, loss 0.97308615
iteration 6862, loss 0.95163996
iteration 6863, loss 1.00711029
iteration 6864, loss 0.90705152
iteration 6865, loss 0.97409154
iteration 6866, loss 0.99867064
iteration 6867, loss 0.99654153
iteration 6868, loss 0.87714706
iteration 6869, loss 0.83073181
iteration 6870, loss 0.88813399
iteration 6871, loss 0.82240233
iteration 6872, loss 0.83621166
iteration 6873, loss 0.82294495
iteration 6874, loss 0.84284225
iteration 6875, loss 0.84537007
iteration 6876, loss 0.84515746
iteration 6877, loss 0.95431411
iteration 6878, loss 0.91538291
iteration 6879, loss 0.87478703
iteration 6880, loss 0.87706828
iteration 6881, loss 0.88860585
iteration 6882, loss 0.82271743
iteration 6883, loss 0.82559367
iteration 6884, loss 0.87045295
iteration 6885, loss 0.99373586
iteration 6886, loss 0.86982235
iteration 6887, loss 0.83776148
iteration 6888, loss 0.87572831
iteration 6889, loss 0.89812823
iteration 6890, loss 0.94761407
iteration 6891, loss 0.78212412
iteration 6892, loss 0.95629816
iteration 6893, loss 0.96764711
iteration 6894, loss 0.86808610
iteration 6895, loss 0.80419494
iteration 6896, loss 0.82706487
iteration 6897, loss 1.08578747
iteration 6898, loss 0.77517490
iteration 6899, loss 0.91872162
iteration 6900, loss 0.94111189
iteration 6901, loss 0.98578556
iteration 6902, loss 0.81664495
iteration 6903, loss 0.82485530
iteration 6904, loss 0.80499677
iteration 6905, loss 0.79744837
iteration 6906, loss 0.81906961
iteration 6907, loss 0.88718233
iteration 6908, loss 0.81102332
iteration 6909, loss 0.85553414
iteration 6910, loss 0.82176861
iteration 6911, loss 0.89635578
iteration 6912, loss 0.98771630
iteration 6913, loss 0.86726648
iteration 6914, loss 0.94925888
iteration 6915, loss 0.82347386
iteration 6916, loss 0.84186470
iteration 6917, loss 0.95096947
iteration 6918, loss 0.84600128
iteration 6919, loss 0.87881110
iteration 6920, loss 0.97814065
iteration 6921, loss 1.00331794
iteration 6922, loss 0.80804243
iteration 6923, loss 0.77735776
iteration 6924, loss 0.94401709
iteration 6925, loss 0.93958697
iteration 6926, loss 0.87312405
iteration 6927, loss 0.84715925
iteration 6928, loss 0.82871787
iteration 6929, loss 0.94512065
iteration 6930, loss 0.80418101
iteration 6931, loss 0.84793906
iteration 6932, loss 0.90230628
iteration 6933, loss 0.91705500
iteration 6934, loss 0.81900135
iteration 6935, loss 0.93502625
iteration 6936, loss 0.91734573
iteration 6937, loss 0.85543106
iteration 6938, loss 0.96583097
iteration 6939, loss 0.77429311
iteration 6940, loss 1.01660600
iteration 6941, loss 0.88190460
iteration 6942, loss 0.87219145
iteration 6943, loss 0.93517574
iteration 6944, loss 0.95947658
iteration 6945, loss 0.96173617
iteration 6946, loss 0.85188189
iteration 6947, loss 0.85381132
iteration 6948, loss 0.95903991
iteration 6949, loss 0.80434765
iteration 6950, loss 0.98880592
iteration 6951, loss 0.80058561
iteration 6952, loss 0.85417977
iteration 6953, loss 0.89966107
iteration 6954, loss 0.78337096
iteration 6955, loss 0.86001279
iteration 6956, loss 0.85284557
iteration 6957, loss 0.98306990
iteration 6958, loss 0.76575467
iteration 6959, loss 0.96021001
iteration 6960, loss 0.86535538
iteration 6961, loss 0.87405615
iteration 6962, loss 0.87527992
iteration 6963, loss 0.81747501
iteration 6964, loss 0.84371259
iteration 6965, loss 0.83792307
iteration 6966, loss 0.82857193
iteration 6967, loss 0.85545963
iteration 6968, loss 0.83020877
iteration 6969, loss 0.87478425
iteration 6970, loss 0.89078802
iteration 6971, loss 0.78243268
iteration 6972, loss 0.86307027
iteration 6973, loss 0.83893132
iteration 6974, loss 0.79550646
iteration 6975, loss 0.86331223
iteration 6976, loss 0.84810156
iteration 6977, loss 0.86568819
iteration 6978, loss 0.98921043
iteration 6979, loss 0.79778873
iteration 6980, loss 1.00501642
iteration 6981, loss 0.97671293
iteration 6982, loss 0.82566037
iteration 6983, loss 0.86216562
iteration 6984, loss 0.97895048
iteration 6985, loss 1.00924032
iteration 6986, loss 1.04567443
iteration 6987, loss 0.87070275
iteration 6988, loss 0.74076964
iteration 6989, loss 0.86388864
iteration 6990, loss 0.84279818
iteration 6991, loss 0.82015435
iteration 6992, loss 0.92374024
iteration 6993, loss 0.81581155
iteration 6994, loss 0.83166635
iteration 6995, loss 0.91387929
iteration 6996, loss 0.84503990
iteration 6997, loss 0.93709513
iteration 6998, loss 0.81842407
iteration 6999, loss 0.84146406
iteration 7000, loss 0.88274902
iteration 7001, loss 0.98604499
iteration 7002, loss 1.13864604
iteration 7003, loss 0.85989640
iteration 7004, loss 0.87556503
iteration 7005, loss 1.03129512
iteration 7006, loss 1.04808029
iteration 7007, loss 0.86213297
iteration 7008, loss 0.81846559
iteration 7009, loss 0.88984376
iteration 7010, loss 0.83808477
iteration 7011, loss 0.84579032
iteration 7012, loss 0.85637549
iteration 7013, loss 1.03314495
iteration 7014, loss 0.95554197
iteration 7015, loss 0.74587245
iteration 7016, loss 0.93845610
iteration 7017, loss 1.07217853
iteration 7018, loss 0.93313333
iteration 7019, loss 0.74131196
iteration 7020, loss 0.96182580
iteration 7021, loss 0.99233907
iteration 7022, loss 0.86062454
iteration 7023, loss 0.92981300
iteration 7024, loss 1.03504435
iteration 7025, loss 0.88608212
iteration 7026, loss 0.83353505
iteration 7027, loss 1.04071743
iteration 7028, loss 0.83730377
iteration 7029, loss 0.91928453
iteration 7030, loss 0.93721398
iteration 7031, loss 1.03999102
iteration 7032, loss 1.07955535
iteration 7033, loss 1.03626320
iteration 7034, loss 0.94323390
iteration 7035, loss 0.98207611
iteration 7036, loss 0.96638558
iteration 7037, loss 0.86353543
iteration 7038, loss 1.01419658
iteration 7039, loss 0.87752354
iteration 7040, loss 0.96697643
iteration 7041, loss 1.15361097
iteration 7042, loss 0.87873064
iteration 7043, loss 0.84045194
iteration 7044, loss 0.85456149
iteration 7045, loss 0.89374617
iteration 7046, loss 0.83265661
iteration 7047, loss 0.95372882
iteration 7048, loss 1.02103848
iteration 7049, loss 0.90664509
iteration 7050, loss 0.92239756
iteration 7051, loss 1.04813115
iteration 7052, loss 0.90522257
iteration 7053, loss 0.82893310
iteration 7054, loss 0.82671026
iteration 7055, loss 0.88021968
iteration 7056, loss 0.89792357
iteration 7057, loss 0.93293899
iteration 7058, loss 0.88134958
iteration 7059, loss 0.86771737
iteration 7060, loss 0.82378663
iteration 7061, loss 0.85249133
iteration 7062, loss 0.85122260
iteration 7063, loss 0.84621040
iteration 7064, loss 0.83137688
iteration 7065, loss 0.88332248
iteration 7066, loss 0.96296194
iteration 7067, loss 0.95496609
iteration 7068, loss 0.85820623
iteration 7069, loss 0.83951745
iteration 7070, loss 0.81093683
iteration 7071, loss 0.88722087
iteration 7072, loss 0.83661554
iteration 7073, loss 0.84910453
iteration 7074, loss 0.93530221
iteration 7075, loss 0.77621126
iteration 7076, loss 0.90168928
iteration 7077, loss 0.81612605
iteration 7078, loss 0.87247047
iteration 7079, loss 0.80626113
iteration 7080, loss 0.81782930
iteration 7081, loss 0.90932782
iteration 7082, loss 0.84839300
iteration 7083, loss 0.82965729
iteration 7084, loss 0.81762915
iteration 7085, loss 0.79366019
iteration 7086, loss 1.01970003
iteration 7087, loss 1.02632103
iteration 7088, loss 0.89652989
iteration 7089, loss 0.83110898
iteration 7090, loss 1.04389041
iteration 7091, loss 0.95893377
iteration 7092, loss 0.94681878
iteration 7093, loss 0.83806374
iteration 7094, loss 0.94094614
iteration 7095, loss 0.91061441
iteration 7096, loss 0.92492285
iteration 7097, loss 1.05360286
iteration 7098, loss 0.81242750
iteration 7099, loss 0.73132604
iteration 7100, loss 0.86767823
iteration 7101, loss 0.83105943
iteration 7102, loss 0.84782426
iteration 7103, loss 0.86187579
iteration 7104, loss 0.85046718
iteration 7105, loss 0.82094455
iteration 7106, loss 0.93952294
iteration 7107, loss 0.87873322
iteration 7108, loss 0.83348261
iteration 7109, loss 0.87286297
iteration 7110, loss 0.81146253
iteration 7111, loss 0.81284840
iteration 7112, loss 0.85335704
iteration 7113, loss 0.96694175
iteration 7114, loss 1.04052291
iteration 7115, loss 0.90584905
iteration 7116, loss 0.78232188
iteration 7117, loss 0.98887260
iteration 7118, loss 0.86563602
iteration 7119, loss 0.83999110
iteration 7120, loss 0.97205864
iteration 7121, loss 0.88732009
iteration 7122, loss 1.06063192
iteration 7123, loss 0.91991281
iteration 7124, loss 0.79036187
iteration 7125, loss 0.85694795
iteration 7126, loss 0.86708158
iteration 7127, loss 0.87672111
iteration 7128, loss 0.74909225
iteration 7129, loss 0.82422410
iteration 7130, loss 0.96161524
iteration 7131, loss 0.79586637
iteration 7132, loss 0.98196197
iteration 7133, loss 1.02826027
iteration 7134, loss 0.97047702
iteration 7135, loss 0.74967535
iteration 7136, loss 0.85735510
iteration 7137, loss 0.95693068
iteration 7138, loss 0.99903969
iteration 7139, loss 0.83120446
iteration 7140, loss 0.99019062
iteration 7141, loss 0.86598094
iteration 7142, loss 0.89082072
iteration 7143, loss 1.08921996
iteration 7144, loss 0.84785065
iteration 7145, loss 0.89089137
iteration 7146, loss 0.90483712
iteration 7147, loss 0.81676295
iteration 7148, loss 0.78201594
iteration 7149, loss 1.04235000
iteration 7150, loss 1.11813615
iteration 7151, loss 0.88326854
iteration 7152, loss 1.07631302
iteration 7153, loss 0.86447929
iteration 7154, loss 0.90684338
iteration 7155, loss 1.11222498
iteration 7156, loss 0.86127501
iteration 7157, loss 0.81050042
iteration 7158, loss 0.84450077
iteration 7159, loss 0.80451105
iteration 7160, loss 0.87729760
iteration 7161, loss 0.90728294
iteration 7162, loss 0.87178574
iteration 7163, loss 1.03313023
iteration 7164, loss 0.88420435
iteration 7165, loss 0.83396489
iteration 7166, loss 0.97686295
iteration 7167, loss 0.97757516
iteration 7168, loss 0.84208193
iteration 7169, loss 0.81191782
iteration 7170, loss 0.85975878
iteration 7171, loss 0.89962637
iteration 7172, loss 0.97764483
iteration 7173, loss 0.92887523
iteration 7174, loss 0.81766285
iteration 7175, loss 0.85228192
iteration 7176, loss 0.87015605
iteration 7177, loss 0.86262800
iteration 7178, loss 0.81712356
iteration 7179, loss 0.81555262
iteration 7180, loss 0.87557253
iteration 7181, loss 0.84013324
iteration 7182, loss 0.86490820
iteration 7183, loss 0.88148199
iteration 7184, loss 0.81894536
iteration 7185, loss 0.94281437
iteration 7186, loss 0.83633098
iteration 7187, loss 0.87749060
iteration 7188, loss 0.82090253
iteration 7189, loss 0.84437961
iteration 7190, loss 0.85042497
iteration 7191, loss 0.83837988
iteration 7192, loss 0.85166342
iteration 7193, loss 1.00035445
iteration 7194, loss 0.82388883
iteration 7195, loss 0.96123018
iteration 7196, loss 0.85469121
iteration 7197, loss 0.96766275
iteration 7198, loss 0.84634341
iteration 7199, loss 0.82185937
iteration 7200, loss 0.85962103
iteration 7201, loss 0.91881810
iteration 7202, loss 0.91026080
iteration 7203, loss 0.92133982
iteration 7204, loss 0.88017241
iteration 7205, loss 0.85316147
iteration 7206, loss 0.81221264
iteration 7207, loss 0.82598014
iteration 7208, loss 0.90013630
iteration 7209, loss 0.94140660
iteration 7210, loss 0.82572927
iteration 7211, loss 0.91712008
iteration 7212, loss 0.88812714
iteration 7213, loss 0.85060165
iteration 7214, loss 0.90722559
iteration 7215, loss 0.77619189
iteration 7216, loss 0.89835052
iteration 7217, loss 0.91337782
iteration 7218, loss 0.79759232
iteration 7219, loss 0.80718241
iteration 7220, loss 0.89156828
iteration 7221, loss 0.81157742
iteration 7222, loss 0.81638356
iteration 7223, loss 0.80655051
iteration 7224, loss 0.87101488
iteration 7225, loss 1.14553856
iteration 7226, loss 0.90253182
iteration 7227, loss 0.89263060
iteration 7228, loss 0.81456560
iteration 7229, loss 0.82893822
iteration 7230, loss 0.90998769
iteration 7231, loss 0.98379252
iteration 7232, loss 0.78095522
iteration 7233, loss 0.79720240
iteration 7234, loss 0.96527579
iteration 7235, loss 1.27955735
iteration 7236, loss 0.94293281
iteration 7237, loss 0.85218180
iteration 7238, loss 0.87953775
iteration 7239, loss 0.92154990
iteration 7240, loss 0.83880899
iteration 7241, loss 0.82669863
iteration 7242, loss 0.85545105
iteration 7243, loss 0.84179282
iteration 7244, loss 0.83855567
iteration 7245, loss 0.81753346
iteration 7246, loss 0.88943629
iteration 7247, loss 0.79382814
iteration 7248, loss 0.95781277
iteration 7249, loss 0.90071610
iteration 7250, loss 0.83054342
iteration 7251, loss 0.92255855
iteration 7252, loss 0.82196115
iteration 7253, loss 0.93494659
iteration 7254, loss 0.85385870
iteration 7255, loss 0.83973438
iteration 7256, loss 0.84040815
iteration 7257, loss 0.84891391
iteration 7258, loss 0.86205584
iteration 7259, loss 0.88863513
iteration 7260, loss 0.81666154
iteration 7261, loss 0.94053392
iteration 7262, loss 0.75831011
iteration 7263, loss 0.91907699
iteration 7264, loss 1.09862000
iteration 7265, loss 0.78692836
iteration 7266, loss 0.89441936
iteration 7267, loss 0.95879773
iteration 7268, loss 0.77686122
iteration 7269, loss 1.02137140
iteration 7270, loss 1.13526515
iteration 7271, loss 0.89247329
iteration 7272, loss 0.89178603
iteration 7273, loss 0.98018556
iteration 7274, loss 1.07875864
iteration 7275, loss 0.92283840
iteration 7276, loss 0.93059225
iteration 7277, loss 0.81419231
iteration 7278, loss 0.84960260
iteration 7279, loss 0.84544794
iteration 7280, loss 0.92468557
iteration 7281, loss 0.82000798
iteration 7282, loss 0.83896218
iteration 7283, loss 0.82434565
iteration 7284, loss 0.89633290
iteration 7285, loss 0.83739885
iteration 7286, loss 0.84421339
iteration 7287, loss 0.89159946
iteration 7288, loss 0.86763486
iteration 7289, loss 0.82728994
iteration 7290, loss 0.84794822
iteration 7291, loss 0.81900340
iteration 7292, loss 0.84390280
iteration 7293, loss 0.85035094
iteration 7294, loss 0.82206897
iteration 7295, loss 0.86988874
iteration 7296, loss 0.96588305
iteration 7297, loss 0.96709244
iteration 7298, loss 0.95229892
iteration 7299, loss 0.84282558
iteration 7300, loss 0.83902744
iteration 7301, loss 0.95437209
iteration 7302, loss 1.05448835
iteration 7303, loss 1.03719326
iteration 7304, loss 0.85787644
iteration 7305, loss 0.97069140
iteration 7306, loss 0.73845907
iteration 7307, loss 0.97482939
iteration 7308, loss 0.98508730
iteration 7309, loss 0.75589931
iteration 7310, loss 0.85797261
iteration 7311, loss 0.98114556
iteration 7312, loss 0.83918819
iteration 7313, loss 1.09084794
iteration 7314, loss 0.94262693
iteration 7315, loss 0.98946024
iteration 7316, loss 0.91197453
iteration 7317, loss 0.78615535
iteration 7318, loss 0.93419935
iteration 7319, loss 1.26762897
iteration 7320, loss 0.88853320
iteration 7321, loss 0.80239716
iteration 7322, loss 0.88653248
iteration 7323, loss 1.03888368
iteration 7324, loss 0.88305927
iteration 7325, loss 0.80461019
iteration 7326, loss 0.87281271
iteration 7327, loss 0.87157063
iteration 7328, loss 0.80413098
iteration 7329, loss 0.83462647
iteration 7330, loss 0.90024877
iteration 7331, loss 0.77332311
iteration 7332, loss 0.84133426
iteration 7333, loss 0.80724352
iteration 7334, loss 0.94292369
iteration 7335, loss 0.82437266
iteration 7336, loss 0.92935380
iteration 7337, loss 0.85531332
iteration 7338, loss 0.88066516
iteration 7339, loss 0.87109479
iteration 7340, loss 0.84619375
iteration 7341, loss 0.82230694
iteration 7342, loss 0.83489508
iteration 7343, loss 0.87839665
iteration 7344, loss 0.86030382
iteration 7345, loss 0.84349732
iteration 7346, loss 0.83455052
iteration 7347, loss 0.81957068
iteration 7348, loss 0.84721620
iteration 7349, loss 0.83622782
iteration 7350, loss 0.83512591
iteration 7351, loss 0.82896181
iteration 7352, loss 0.86158226
iteration 7353, loss 0.86867074
iteration 7354, loss 0.82832199
iteration 7355, loss 0.98139418
iteration 7356, loss 0.87571627
iteration 7357, loss 1.03556958
iteration 7358, loss 0.97851965
iteration 7359, loss 0.76808589
iteration 7360, loss 0.85127467
iteration 7361, loss 0.86596228
iteration 7362, loss 0.94019766
iteration 7363, loss 1.10247926
iteration 7364, loss 0.83893064
iteration 7365, loss 0.90644361
iteration 7366, loss 0.97397053
iteration 7367, loss 0.80745804
iteration 7368, loss 0.85546792
iteration 7369, loss 0.86919906
iteration 7370, loss 0.79879104
iteration 7371, loss 0.81927465
iteration 7372, loss 0.84296371
iteration 7373, loss 0.81727739
iteration 7374, loss 0.88972647
iteration 7375, loss 1.00298359
iteration 7376, loss 0.93318441
iteration 7377, loss 1.00007705
iteration 7378, loss 0.86958978
iteration 7379, loss 0.84215860
iteration 7380, loss 0.80689535
iteration 7381, loss 0.86902740
iteration 7382, loss 0.87909147
iteration 7383, loss 0.85062340
iteration 7384, loss 0.85390444
iteration 7385, loss 0.97451792
iteration 7386, loss 0.82469791
iteration 7387, loss 0.96052684
iteration 7388, loss 1.00908844
iteration 7389, loss 0.83939042
iteration 7390, loss 0.70216840
iteration 7391, loss 0.87128999
iteration 7392, loss 0.83608358
iteration 7393, loss 0.85017676
iteration 7394, loss 0.82783534
iteration 7395, loss 0.83942213
iteration 7396, loss 0.84649137
iteration 7397, loss 0.98489498
iteration 7398, loss 0.79748810
iteration 7399, loss 1.01146925
iteration 7400, loss 0.79899820
iteration 7401, loss 1.11872018
iteration 7402, loss 0.87038605
iteration 7403, loss 0.93387321
iteration 7404, loss 0.88968357
iteration 7405, loss 0.71215641
iteration 7406, loss 0.88803333
iteration 7407, loss 0.86028229
iteration 7408, loss 0.85407262
iteration 7409, loss 0.87452398
iteration 7410, loss 0.89635765
iteration 7411, loss 0.83498841
iteration 7412, loss 0.82444634
iteration 7413, loss 0.83846293
iteration 7414, loss 0.87861307
iteration 7415, loss 0.84793772
iteration 7416, loss 0.88960985
iteration 7417, loss 0.77082860
iteration 7418, loss 0.90463614
iteration 7419, loss 0.92246478
iteration 7420, loss 0.81235866
iteration 7421, loss 0.80012617
iteration 7422, loss 0.95151187
iteration 7423, loss 1.09226791
iteration 7424, loss 1.10894032
iteration 7425, loss 0.94989266
iteration 7426, loss 0.89062376
iteration 7427, loss 0.87725041
iteration 7428, loss 0.83357905
iteration 7429, loss 0.89524185
iteration 7430, loss 0.82921154
iteration 7431, loss 0.98350426
iteration 7432, loss 0.82672916
iteration 7433, loss 1.12847880
iteration 7434, loss 0.99122323
iteration 7435, loss 1.05203465
iteration 7436, loss 0.96705309
iteration 7437, loss 0.90376390
iteration 7438, loss 1.04410765
iteration 7439, loss 0.90104254
iteration 7440, loss 0.97706499
iteration 7441, loss 1.06768943
iteration 7442, loss 0.87594842
iteration 7443, loss 0.82847777
iteration 7444, loss 0.86352450
iteration 7445, loss 0.83270791
iteration 7446, loss 0.89370352
iteration 7447, loss 0.89968304
iteration 7448, loss 0.80736867
iteration 7449, loss 0.81250447
iteration 7450, loss 0.89672723
iteration 7451, loss 0.82310405
iteration 7452, loss 0.98681238
iteration 7453, loss 0.97668414
iteration 7454, loss 0.87054615
iteration 7455, loss 0.81107084
iteration 7456, loss 0.91694840
iteration 7457, loss 0.88050215
iteration 7458, loss 0.80239563
iteration 7459, loss 0.81510666
iteration 7460, loss 0.86035436
iteration 7461, loss 0.88349720
iteration 7462, loss 1.09210270
iteration 7463, loss 1.36473720
iteration 7464, loss 1.13593975
iteration 7465, loss 1.17514942
iteration 7466, loss 0.86429376
iteration 7467, loss 0.79018783
iteration 7468, loss 0.92040634
iteration 7469, loss 0.94113525
iteration 7470, loss 1.12391857
iteration 7471, loss 1.09196583
iteration 7472, loss 0.99843595
iteration 7473, loss 0.86228544
iteration 7474, loss 0.81536363
iteration 7475, loss 0.82815091
iteration 7476, loss 0.95396508
iteration 7477, loss 0.78870442
iteration 7478, loss 0.91380829
iteration 7479, loss 1.23693789
iteration 7480, loss 0.86205555
iteration 7481, loss 0.77800110
iteration 7482, loss 0.86971864
iteration 7483, loss 0.92038942
iteration 7484, loss 1.09949096
iteration 7485, loss 0.78943433
iteration 7486, loss 1.06409089
iteration 7487, loss 0.85860765
iteration 7488, loss 0.82003717
iteration 7489, loss 0.93184079
iteration 7490, loss 0.85520222
iteration 7491, loss 0.92348373
iteration 7492, loss 0.86075409
iteration 7493, loss 0.84887490
iteration 7494, loss 0.86863377
iteration 7495, loss 0.88478691
iteration 7496, loss 1.13018595
iteration 7497, loss 0.89130906
iteration 7498, loss 0.96038339
iteration 7499, loss 0.98664923
iteration 7500, loss 0.80218642
iteration 7501, loss 0.91265646
iteration 7502, loss 1.03816024
iteration 7503, loss 0.83968121
iteration 7504, loss 0.80319468
iteration 7505, loss 0.84914178
iteration 7506, loss 0.95108488
iteration 7507, loss 0.84587959
iteration 7508, loss 0.84063827
iteration 7509, loss 0.91128594
iteration 7510, loss 0.82295248
iteration 7511, loss 0.84443671
iteration 7512, loss 0.94542132
iteration 7513, loss 0.96378445
iteration 7514, loss 0.87187657
iteration 7515, loss 0.84556599
iteration 7516, loss 0.84368308
iteration 7517, loss 0.89255506
iteration 7518, loss 1.16826570
iteration 7519, loss 0.90723429
iteration 7520, loss 0.88580423
iteration 7521, loss 0.95801886
iteration 7522, loss 0.93618876
iteration 7523, loss 0.96311059
iteration 7524, loss 0.83181073
iteration 7525, loss 0.95951241
iteration 7526, loss 0.84922388
iteration 7527, loss 0.79837350
iteration 7528, loss 0.89218325
iteration 7529, loss 0.97732647
iteration 7530, loss 0.84143092
iteration 7531, loss 1.09770992
iteration 7532, loss 0.81217421
iteration 7533, loss 0.96495101
iteration 7534, loss 0.85431311
iteration 7535, loss 0.86312386
iteration 7536, loss 0.83605832
iteration 7537, loss 0.84554948
iteration 7538, loss 0.80832673
iteration 7539, loss 0.85799509
iteration 7540, loss 0.90595370
iteration 7541, loss 0.86786263
iteration 7542, loss 1.03319641
iteration 7543, loss 0.81301490
iteration 7544, loss 1.07920597
iteration 7545, loss 0.87624289
iteration 7546, loss 0.89812985
iteration 7547, loss 0.92150015
iteration 7548, loss 1.30996635
iteration 7549, loss 1.15158182
iteration 7550, loss 0.99975864
iteration 7551, loss 1.06768262
iteration 7552, loss 0.86405230
iteration 7553, loss 0.95633715
iteration 7554, loss 0.90270749
iteration 7555, loss 0.90579717
iteration 7556, loss 0.91851187
iteration 7557, loss 0.88843325
iteration 7558, loss 1.13804376
iteration 7559, loss 0.83977212
iteration 7560, loss 0.80876361
iteration 7561, loss 0.96564440
iteration 7562, loss 0.88158599
iteration 7563, loss 0.85612750
iteration 7564, loss 0.81636711
iteration 7565, loss 0.79144352
iteration 7566, loss 0.86539924
iteration 7567, loss 0.94482978
iteration 7568, loss 0.80090009
iteration 7569, loss 0.92338495
iteration 7570, loss 0.96284641
iteration 7571, loss 0.83821819
iteration 7572, loss 1.04485443
iteration 7573, loss 1.07186876
iteration 7574, loss 0.83921604
iteration 7575, loss 0.86464139
iteration 7576, loss 0.87834953
iteration 7577, loss 0.87011217
iteration 7578, loss 0.80644699
iteration 7579, loss 0.82987013
iteration 7580, loss 0.78590049
iteration 7581, loss 0.79706477
iteration 7582, loss 0.89870386
iteration 7583, loss 1.09911905
iteration 7584, loss 1.05123551
iteration 7585, loss 0.85663150
iteration 7586, loss 0.94058384
iteration 7587, loss 1.13936628
iteration 7588, loss 0.87816431
iteration 7589, loss 0.82010606
iteration 7590, loss 0.87832096
iteration 7591, loss 0.89613357
iteration 7592, loss 0.84273716
iteration 7593, loss 0.96477602
iteration 7594, loss 0.80110053
iteration 7595, loss 0.88433267
iteration 7596, loss 0.95140611
iteration 7597, loss 0.85683004
iteration 7598, loss 0.83769839
iteration 7599, loss 0.84982756
iteration 7600, loss 0.97480766
iteration 7601, loss 1.14477850
iteration 7602, loss 0.90639507
iteration 7603, loss 0.90457128
iteration 7604, loss 1.00910985
iteration 7605, loss 0.92977632
iteration 7606, loss 0.93373281
iteration 7607, loss 0.83145363
iteration 7608, loss 0.97882664
iteration 7609, loss 1.00207580
iteration 7610, loss 0.89104448
iteration 7611, loss 0.85458105
iteration 7612, loss 0.83446273
iteration 7613, loss 0.93824972
iteration 7614, loss 0.76360931
iteration 7615, loss 0.90483365
iteration 7616, loss 1.01256872
iteration 7617, loss 0.94526574
iteration 7618, loss 0.88914596
iteration 7619, loss 0.88619851
iteration 7620, loss 0.77862788
iteration 7621, loss 0.92740973
iteration 7622, loss 0.98661738
iteration 7623, loss 0.75527140
iteration 7624, loss 0.89767067
iteration 7625, loss 0.89627595
iteration 7626, loss 0.88978468
iteration 7627, loss 0.83599057
iteration 7628, loss 0.90624287
iteration 7629, loss 0.98663537
iteration 7630, loss 0.83630636
iteration 7631, loss 0.92194293
iteration 7632, loss 0.92258432
iteration 7633, loss 0.91581814
iteration 7634, loss 0.86425243
iteration 7635, loss 0.93972172
iteration 7636, loss 0.83819000
iteration 7637, loss 0.83582689
iteration 7638, loss 0.90703903
iteration 7639, loss 0.90100672
iteration 7640, loss 0.90650068
iteration 7641, loss 0.82614407
iteration 7642, loss 0.81240001
iteration 7643, loss 0.84601572
iteration 7644, loss 1.06230412
iteration 7645, loss 0.84173438
iteration 7646, loss 0.94075145
iteration 7647, loss 0.89570260
iteration 7648, loss 0.91445187
iteration 7649, loss 0.88904953
iteration 7650, loss 0.97015181
iteration 7651, loss 0.78856748
iteration 7652, loss 0.86441142
iteration 7653, loss 0.79610920
iteration 7654, loss 0.86303226
iteration 7655, loss 0.89235824
iteration 7656, loss 0.96737028
iteration 7657, loss 1.09357884
iteration 7658, loss 0.95052935
iteration 7659, loss 0.83615777
iteration 7660, loss 0.87895607
iteration 7661, loss 0.88080365
iteration 7662, loss 0.87246875
iteration 7663, loss 1.09105756
iteration 7664, loss 0.81031320
iteration 7665, loss 1.09489058
iteration 7666, loss 0.99007114
iteration 7667, loss 0.89244996
iteration 7668, loss 0.81024191
iteration 7669, loss 0.78730932
iteration 7670, loss 0.85940165
iteration 7671, loss 0.90290314
iteration 7672, loss 1.06655357
iteration 7673, loss 0.84054383
iteration 7674, loss 0.82361200
iteration 7675, loss 0.81454003
iteration 7676, loss 0.86373576
iteration 7677, loss 0.86881193
iteration 7678, loss 0.79914136
iteration 7679, loss 0.81810712
iteration 7680, loss 0.84729168
iteration 7681, loss 0.88641383
iteration 7682, loss 0.87107091
iteration 7683, loss 0.81834270
iteration 7684, loss 0.81407909
iteration 7685, loss 0.95613771
iteration 7686, loss 0.81000224
iteration 7687, loss 0.84696267
iteration 7688, loss 1.12605359
iteration 7689, loss 0.94524055
iteration 7690, loss 0.84015249
iteration 7691, loss 0.83420585
iteration 7692, loss 0.88626687
iteration 7693, loss 1.09153576
iteration 7694, loss 1.33001817
iteration 7695, loss 0.93476581
iteration 7696, loss 0.97691613
iteration 7697, loss 0.80794809
iteration 7698, loss 0.81494611
iteration 7699, loss 0.89848980
iteration 7700, loss 0.96907211
iteration 7701, loss 0.79247438
iteration 7702, loss 0.97306970
iteration 7703, loss 0.94809355
iteration 7704, loss 0.89343602
iteration 7705, loss 0.79587135
iteration 7706, loss 0.82631225
iteration 7707, loss 0.85464532
iteration 7708, loss 0.97246025
iteration 7709, loss 0.82706086
iteration 7710, loss 0.83005685
iteration 7711, loss 0.86438687
iteration 7712, loss 0.93780675
iteration 7713, loss 0.96580179
iteration 7714, loss 0.80672198
iteration 7715, loss 0.86077114
iteration 7716, loss 0.84628449
iteration 7717, loss 0.84649889
iteration 7718, loss 0.84536018
iteration 7719, loss 0.81511684
iteration 7720, loss 0.87211956
iteration 7721, loss 0.80369615
iteration 7722, loss 0.95117164
iteration 7723, loss 0.86886322
iteration 7724, loss 1.13547084
iteration 7725, loss 1.02307201
iteration 7726, loss 0.83103847
iteration 7727, loss 0.89214365
iteration 7728, loss 1.27429543
iteration 7729, loss 1.21221481
iteration 7730, loss 1.16734584
iteration 7731, loss 0.98869225
iteration 7732, loss 0.86684783
iteration 7733, loss 0.96208654
iteration 7734, loss 0.86602155
iteration 7735, loss 0.92133954
iteration 7736, loss 0.91059613
iteration 7737, loss 0.93792127
iteration 7738, loss 0.86272233
iteration 7739, loss 0.89373638
iteration 7740, loss 0.85018535
iteration 7741, loss 0.84003178
iteration 7742, loss 0.97111191
iteration 7743, loss 1.11362825
iteration 7744, loss 0.89011861
iteration 7745, loss 0.83242008
iteration 7746, loss 0.90656404
iteration 7747, loss 0.87633820
iteration 7748, loss 0.80330553
iteration 7749, loss 0.85153845
iteration 7750, loss 0.81537852
iteration 7751, loss 0.86969349
iteration 7752, loss 0.83195530
iteration 7753, loss 0.87544242
iteration 7754, loss 0.96181519
iteration 7755, loss 0.90664132
iteration 7756, loss 0.81913320
iteration 7757, loss 0.82496041
iteration 7758, loss 0.82751627
iteration 7759, loss 0.89558128
iteration 7760, loss 0.80618879
iteration 7761, loss 1.00937773
iteration 7762, loss 0.88629693
iteration 7763, loss 0.93057548
iteration 7764, loss 0.86161318
iteration 7765, loss 0.88363566
iteration 7766, loss 0.90537962
iteration 7767, loss 0.91803490
iteration 7768, loss 0.83820848
iteration 7769, loss 0.83217883
iteration 7770, loss 0.83320592
iteration 7771, loss 0.82519184
iteration 7772, loss 0.82194899
iteration 7773, loss 0.80411843
iteration 7774, loss 0.91144400
iteration 7775, loss 0.88359442
iteration 7776, loss 0.81281643
iteration 7777, loss 0.88596616
iteration 7778, loss 0.84426392
iteration 7779, loss 0.84343226
iteration 7780, loss 0.90963585
iteration 7781, loss 0.91169634
iteration 7782, loss 0.89231043
iteration 7783, loss 0.93364538
iteration 7784, loss 0.90222486
iteration 7785, loss 0.87123976
iteration 7786, loss 0.92619365
iteration 7787, loss 0.81372017
iteration 7788, loss 0.82542951
iteration 7789, loss 0.83111363
iteration 7790, loss 0.84088283
iteration 7791, loss 0.93873876
iteration 7792, loss 0.86978201
iteration 7793, loss 0.88028356
iteration 7794, loss 0.87592039
iteration 7795, loss 1.08811691
iteration 7796, loss 0.86579386
iteration 7797, loss 1.00006465
iteration 7798, loss 0.94918389
iteration 7799, loss 1.02469946
iteration 7800, loss 0.82523188
iteration 7801, loss 1.00149008
iteration 7802, loss 1.23492169
iteration 7803, loss 0.93933834
iteration 7804, loss 0.82387024
iteration 7805, loss 0.85905766
iteration 7806, loss 0.93575564
iteration 7807, loss 0.96705692
iteration 7808, loss 0.79900632
iteration 7809, loss 0.84014335
iteration 7810, loss 0.88248766
iteration 7811, loss 0.81370723
iteration 7812, loss 0.83976333
iteration 7813, loss 0.89948992
iteration 7814, loss 0.95658394
iteration 7815, loss 0.94493404
iteration 7816, loss 0.86653405
iteration 7817, loss 0.97701333
iteration 7818, loss 1.00009794
iteration 7819, loss 1.03772128
iteration 7820, loss 0.89793285
iteration 7821, loss 0.95330834
iteration 7822, loss 1.05424107
iteration 7823, loss 0.94155742
iteration 7824, loss 0.81834838
iteration 7825, loss 0.89687759
iteration 7826, loss 0.98818978
iteration 7827, loss 0.76479483
iteration 7828, loss 0.87504088
iteration 7829, loss 0.88987988
iteration 7830, loss 0.98419535
iteration 7831, loss 1.05925285
iteration 7832, loss 0.92006253
iteration 7833, loss 1.02516699
iteration 7834, loss 0.94039672
iteration 7835, loss 0.85935709
iteration 7836, loss 1.01372584
iteration 7837, loss 0.91753501
iteration 7838, loss 0.83174062
iteration 7839, loss 0.95314287
iteration 7840, loss 0.85036251
iteration 7841, loss 1.07334863
iteration 7842, loss 0.80283407
iteration 7843, loss 1.00610982
iteration 7844, loss 0.91000719
iteration 7845, loss 0.87574012
iteration 7846, loss 0.90984189
iteration 7847, loss 0.85165067
iteration 7848, loss 0.87797099
iteration 7849, loss 0.90427710
iteration 7850, loss 0.84297915
iteration 7851, loss 0.84025120
iteration 7852, loss 0.79251750
iteration 7853, loss 0.95378466
iteration 7854, loss 1.03701902
iteration 7855, loss 0.84692066
iteration 7856, loss 0.81224790
iteration 7857, loss 0.93102322
iteration 7858, loss 1.18250336
iteration 7859, loss 1.27337330
iteration 7860, loss 0.99052952
iteration 7861, loss 0.85188639
iteration 7862, loss 0.89235841
iteration 7863, loss 0.94971151
iteration 7864, loss 0.87846262
iteration 7865, loss 0.80184515
iteration 7866, loss 0.84033010
iteration 7867, loss 1.02241862
iteration 7868, loss 0.80089735
iteration 7869, loss 0.95787352
iteration 7870, loss 0.85898609
iteration 7871, loss 0.85149970
iteration 7872, loss 0.85610504
iteration 7873, loss 0.96907236
iteration 7874, loss 0.85534986
iteration 7875, loss 0.88064467
iteration 7876, loss 0.85340103
iteration 7877, loss 0.87639747
iteration 7878, loss 0.86199957
iteration 7879, loss 0.80972796
iteration 7880, loss 0.87799320
iteration 7881, loss 0.91264211
iteration 7882, loss 1.00448743
iteration 7883, loss 0.83313265
iteration 7884, loss 0.88478114
iteration 7885, loss 0.90153861
iteration 7886, loss 0.81195251
iteration 7887, loss 0.82560419
iteration 7888, loss 0.86986719
iteration 7889, loss 0.83510542
iteration 7890, loss 0.95324906
iteration 7891, loss 1.02214997
iteration 7892, loss 0.85305607
iteration 7893, loss 0.91484288
iteration 7894, loss 1.02689072
iteration 7895, loss 0.96008511
iteration 7896, loss 0.93873065
iteration 7897, loss 1.31781797
iteration 7898, loss 1.37736941
iteration 7899, loss 0.96472832
iteration 7900, loss 0.81354279
iteration 7901, loss 1.01744679
iteration 7902, loss 1.14832591
iteration 7903, loss 1.00409866
iteration 7904, loss 0.90804647
iteration 7905, loss 0.84798292
iteration 7906, loss 0.96385637
iteration 7907, loss 0.95176181
iteration 7908, loss 0.86520308
iteration 7909, loss 0.92909595
iteration 7910, loss 0.98579215
iteration 7911, loss 0.82640151
iteration 7912, loss 0.82329437
iteration 7913, loss 0.85455736
iteration 7914, loss 0.82844504
iteration 7915, loss 0.89807546
iteration 7916, loss 0.77137995
iteration 7917, loss 0.89461564
iteration 7918, loss 0.84186276
iteration 7919, loss 0.97100784
iteration 7920, loss 1.07742932
iteration 7921, loss 0.90444650
iteration 7922, loss 0.88293056
iteration 7923, loss 0.91022541
iteration 7924, loss 0.85689379
iteration 7925, loss 0.82089193
iteration 7926, loss 0.92934911
iteration 7927, loss 0.86613994
iteration 7928, loss 1.04549698
iteration 7929, loss 0.88540419
iteration 7930, loss 0.90290047
iteration 7931, loss 0.85671550
iteration 7932, loss 0.95913360
iteration 7933, loss 0.84435300
iteration 7934, loss 0.96267067
iteration 7935, loss 0.97620336
iteration 7936, loss 0.95157222
iteration 7937, loss 1.22385483
iteration 7938, loss 0.82564370
iteration 7939, loss 1.03890350
iteration 7940, loss 0.86124282
iteration 7941, loss 0.98251080
iteration 7942, loss 1.12422346
iteration 7943, loss 1.00992170
iteration 7944, loss 0.79875518
iteration 7945, loss 0.98037467
iteration 7946, loss 0.83015072
iteration 7947, loss 0.82048719
iteration 7948, loss 0.83975644
iteration 7949, loss 0.90348412
iteration 7950, loss 0.84311898
iteration 7951, loss 0.83436932
iteration 7952, loss 0.87651100
iteration 7953, loss 0.91649448
iteration 7954, loss 0.85256590
iteration 7955, loss 0.86027753
iteration 7956, loss 0.92476576
iteration 7957, loss 0.89982285
iteration 7958, loss 0.92727579
iteration 7959, loss 0.94556723
iteration 7960, loss 0.89822382
iteration 7961, loss 1.05599138
iteration 7962, loss 0.89299171
iteration 7963, loss 0.95628461
iteration 7964, loss 0.79104821
iteration 7965, loss 0.91649113
iteration 7966, loss 0.95154596
iteration 7967, loss 1.07156811
iteration 7968, loss 0.82847902
iteration 7969, loss 0.80259608
iteration 7970, loss 0.81866650
iteration 7971, loss 1.04188639
iteration 7972, loss 1.05881959
iteration 7973, loss 0.82125004
iteration 7974, loss 0.95068347
iteration 7975, loss 0.77247441
iteration 7976, loss 0.93143372
iteration 7977, loss 0.89893056
iteration 7978, loss 0.97243986
iteration 7979, loss 0.79608737
iteration 7980, loss 0.85305925
iteration 7981, loss 0.87691356
iteration 7982, loss 0.87800807
iteration 7983, loss 0.84899501
iteration 7984, loss 0.83181579
iteration 7985, loss 0.97470605
iteration 7986, loss 0.81684067
iteration 7987, loss 1.10543076
iteration 7988, loss 0.93805511
iteration 7989, loss 0.78324145
iteration 7990, loss 0.84058504
iteration 7991, loss 0.89001141
iteration 7992, loss 0.92685903
iteration 7993, loss 0.75347695
iteration 7994, loss 0.91005160
iteration 7995, loss 0.85105782
iteration 7996, loss 0.95545559
iteration 7997, loss 0.83823740
iteration 7998, loss 0.82034406
iteration 7999, loss 0.94421961
iteration 8000, loss 0.75728415
iteration 8001, loss 0.86747420
iteration 8002, loss 0.89004143
iteration 8003, loss 1.00066952
iteration 8004, loss 0.81514670
iteration 8005, loss 1.07780292
iteration 8006, loss 0.80240860
iteration 8007, loss 0.81085571
iteration 8008, loss 0.92048468
iteration 8009, loss 0.94797031
iteration 8010, loss 0.80081328
iteration 8011, loss 0.87314231
iteration 8012, loss 0.98575661
iteration 8013, loss 0.85088978
iteration 8014, loss 0.84572966
iteration 8015, loss 0.93315554
iteration 8016, loss 0.88282842
iteration 8017, loss 0.83104559
iteration 8018, loss 0.81149017
iteration 8019, loss 0.93888097
iteration 8020, loss 0.78620472
iteration 8021, loss 0.87072600
iteration 8022, loss 0.84242965
iteration 8023, loss 0.84972908
iteration 8024, loss 0.80110579
iteration 8025, loss 0.90398325
iteration 8026, loss 0.83376653
iteration 8027, loss 0.87765403
iteration 8028, loss 1.10857964
iteration 8029, loss 0.89131643
iteration 8030, loss 0.94800522
iteration 8031, loss 1.05244969
iteration 8032, loss 0.86447844
iteration 8033, loss 0.96716071
iteration 8034, loss 0.94149285
iteration 8035, loss 0.83734647
iteration 8036, loss 0.93610983
iteration 8037, loss 0.91976071
iteration 8038, loss 0.84367870
iteration 8039, loss 0.90335487
iteration 8040, loss 0.86387616
iteration 8041, loss 0.90127461
iteration 8042, loss 0.92690519
iteration 8043, loss 0.87759046
iteration 8044, loss 0.85857906
iteration 8045, loss 0.87209363
iteration 8046, loss 0.87046377
iteration 8047, loss 1.02874696
iteration 8048, loss 0.80211333
iteration 8049, loss 0.91040619
iteration 8050, loss 1.06322188
iteration 8051, loss 0.99817875
iteration 8052, loss 1.00163881
iteration 8053, loss 0.90108301
iteration 8054, loss 0.82894252
iteration 8055, loss 0.81859332
iteration 8056, loss 0.84160984
iteration 8057, loss 0.83632897
iteration 8058, loss 0.84777800
iteration 8059, loss 0.86057090
iteration 8060, loss 0.89050484
iteration 8061, loss 0.79038561
iteration 8062, loss 0.84918108
iteration 8063, loss 0.81989706
iteration 8064, loss 0.94526040
iteration 8065, loss 0.80743456
iteration 8066, loss 0.93286612
iteration 8067, loss 0.89198702
iteration 8068, loss 0.82329800
iteration 8069, loss 0.86928209
iteration 8070, loss 0.92015873
iteration 8071, loss 0.84698669
iteration 8072, loss 0.82439641
iteration 8073, loss 0.84596374
iteration 8074, loss 0.85328791
iteration 8075, loss 0.89059012
iteration 8076, loss 0.88601112
iteration 8077, loss 0.89642936
iteration 8078, loss 0.79273681
iteration 8079, loss 0.85549961
iteration 8080, loss 0.90939248
iteration 8081, loss 0.87811745
iteration 8082, loss 0.88811198
iteration 8083, loss 0.81094748
iteration 8084, loss 0.88137223
iteration 8085, loss 0.86339806
iteration 8086, loss 0.80324934
iteration 8087, loss 0.83436919
iteration 8088, loss 0.85388562
iteration 8089, loss 1.03034760
iteration 8090, loss 1.22132583
iteration 8091, loss 1.06336435
iteration 8092, loss 0.74253015
iteration 8093, loss 0.84672911
iteration 8094, loss 0.95837190
iteration 8095, loss 0.85199929
iteration 8096, loss 0.81159474
iteration 8097, loss 0.88300955
iteration 8098, loss 0.87523350
iteration 8099, loss 0.83708003
iteration 8100, loss 0.87969729
iteration 8101, loss 0.90746973
iteration 8102, loss 0.79673955
iteration 8103, loss 0.81609163
iteration 8104, loss 0.80503008
iteration 8105, loss 0.80986703
iteration 8106, loss 0.87784927
iteration 8107, loss 0.79861990
iteration 8108, loss 0.91108435
iteration 8109, loss 0.98890193
iteration 8110, loss 0.93192078
iteration 8111, loss 0.93463542
iteration 8112, loss 0.95078185
iteration 8113, loss 0.93796028
iteration 8114, loss 0.93065995
iteration 8115, loss 1.05215581
iteration 8116, loss 1.05282125
iteration 8117, loss 0.81562963
iteration 8118, loss 0.87463956
iteration 8119, loss 0.85867931
iteration 8120, loss 0.87624459
iteration 8121, loss 0.84641276
iteration 8122, loss 0.94977988
iteration 8123, loss 0.78123331
iteration 8124, loss 1.01903043
iteration 8125, loss 0.84401820
iteration 8126, loss 1.06961971
iteration 8127, loss 1.18918624
iteration 8128, loss 0.98855386
iteration 8129, loss 1.05631027
iteration 8130, loss 0.96442866
iteration 8131, loss 1.14059050
iteration 8132, loss 0.98844593
iteration 8133, loss 0.87942929
iteration 8134, loss 0.95907620
iteration 8135, loss 0.83736624
iteration 8136, loss 0.86737151
iteration 8137, loss 0.79365756
iteration 8138, loss 0.87857079
iteration 8139, loss 0.80813245
iteration 8140, loss 0.91473646
iteration 8141, loss 0.92531815
iteration 8142, loss 0.84507379
iteration 8143, loss 0.89995681
iteration 8144, loss 1.04989583
iteration 8145, loss 1.03383648
iteration 8146, loss 0.89625334
iteration 8147, loss 1.03512608
iteration 8148, loss 0.87260445
iteration 8149, loss 0.81302069
iteration 8150, loss 0.85625902
iteration 8151, loss 0.83283873
iteration 8152, loss 0.83031396
iteration 8153, loss 0.84813280
iteration 8154, loss 0.85662133
iteration 8155, loss 0.86653887
iteration 8156, loss 0.83615429
iteration 8157, loss 0.81570219
iteration 8158, loss 0.82646307
iteration 8159, loss 0.87016737
iteration 8160, loss 0.84905721
iteration 8161, loss 0.81949552
iteration 8162, loss 0.80558047
iteration 8163, loss 1.08642478
iteration 8164, loss 0.86628276
iteration 8165, loss 0.83984016
iteration 8166, loss 0.90629185
iteration 8167, loss 0.91417323
iteration 8168, loss 0.83602694
iteration 8169, loss 0.84001724
iteration 8170, loss 0.96417998
iteration 8171, loss 0.87037773
iteration 8172, loss 0.90556115
iteration 8173, loss 0.96861182
iteration 8174, loss 1.00210950
iteration 8175, loss 0.91125168
iteration 8176, loss 0.77657965
iteration 8177, loss 0.82973382
iteration 8178, loss 1.03249004
iteration 8179, loss 0.79404500
iteration 8180, loss 0.90587808
iteration 8181, loss 0.86690226
iteration 8182, loss 0.79633050
iteration 8183, loss 0.98308974
iteration 8184, loss 0.89012885
iteration 8185, loss 0.95834066
iteration 8186, loss 1.02098873
iteration 8187, loss 0.90713962
iteration 8188, loss 0.89684389
iteration 8189, loss 0.88419429
iteration 8190, loss 0.81811702
iteration 8191, loss 0.87171144
iteration 8192, loss 0.85059585
iteration 8193, loss 0.81658302
iteration 8194, loss 0.83222020
iteration 8195, loss 0.87033639
iteration 8196, loss 0.84555267
iteration 8197, loss 0.83878845
iteration 8198, loss 0.86297471
iteration 8199, loss 0.85301322
iteration 8200, loss 0.85599540
iteration 8201, loss 0.89055922
iteration 8202, loss 0.94094010
iteration 8203, loss 0.85651595
iteration 8204, loss 0.80240734
iteration 8205, loss 0.83805026
iteration 8206, loss 0.87313522
iteration 8207, loss 1.03309089
iteration 8208, loss 0.85842763
iteration 8209, loss 1.05769917
iteration 8210, loss 1.14535242
iteration 8211, loss 1.06085255
iteration 8212, loss 0.95945980
iteration 8213, loss 0.86813494
iteration 8214, loss 0.93985292
iteration 8215, loss 0.88582583
iteration 8216, loss 0.84238292
iteration 8217, loss 0.84673472
iteration 8218, loss 0.83415727
iteration 8219, loss 0.89324530
iteration 8220, loss 1.01502859
iteration 8221, loss 0.96639791
iteration 8222, loss 0.89923876
iteration 8223, loss 0.81596849
iteration 8224, loss 0.81394084
iteration 8225, loss 0.91579316
iteration 8226, loss 0.87702315
iteration 8227, loss 0.80243799
iteration 8228, loss 0.93419254
iteration 8229, loss 0.83007266
iteration 8230, loss 0.82505297
iteration 8231, loss 0.85166198
iteration 8232, loss 0.86387639
iteration 8233, loss 0.82316028
iteration 8234, loss 0.81380103
iteration 8235, loss 0.85971580
iteration 8236, loss 0.85382198
iteration 8237, loss 0.86520016
iteration 8238, loss 1.00679021
iteration 8239, loss 0.88811257
iteration 8240, loss 1.00174921
iteration 8241, loss 0.83858548
iteration 8242, loss 0.90897599
iteration 8243, loss 0.80974923
iteration 8244, loss 0.91534563
iteration 8245, loss 0.85713471
iteration 8246, loss 0.85624265
iteration 8247, loss 0.96313883
iteration 8248, loss 0.87335820
iteration 8249, loss 1.05113058
iteration 8250, loss 0.98678573
iteration 8251, loss 0.96906832
iteration 8252, loss 0.87926567
iteration 8253, loss 0.95038242
iteration 8254, loss 0.94353893
iteration 8255, loss 0.84497868
iteration 8256, loss 0.83099379
iteration 8257, loss 0.97674737
iteration 8258, loss 0.82220698
iteration 8259, loss 0.90725351
iteration 8260, loss 0.87637761
iteration 8261, loss 0.79462629
iteration 8262, loss 0.94427164
iteration 8263, loss 0.92938257
iteration 8264, loss 1.06378102
iteration 8265, loss 1.09111854
iteration 8266, loss 1.06075090
iteration 8267, loss 1.06752405
iteration 8268, loss 0.70165565
iteration 8269, loss 0.88281041
iteration 8270, loss 0.92618522
iteration 8271, loss 0.88979126
iteration 8272, loss 0.77740169
iteration 8273, loss 0.82634474
iteration 8274, loss 0.84429839
iteration 8275, loss 0.87747475
iteration 8276, loss 0.79083251
iteration 8277, loss 0.96448412
iteration 8278, loss 1.05419770
iteration 8279, loss 0.99697117
iteration 8280, loss 1.16970421
iteration 8281, loss 0.87222093
iteration 8282, loss 1.06119360
iteration 8283, loss 1.13163251
iteration 8284, loss 0.89721800
iteration 8285, loss 1.10154386
iteration 8286, loss 0.91322378
iteration 8287, loss 0.79482077
iteration 8288, loss 0.89428621
iteration 8289, loss 0.92474434
iteration 8290, loss 0.81852641
iteration 8291, loss 0.79398677
iteration 8292, loss 0.84111654
iteration 8293, loss 0.91092003
iteration 8294, loss 0.82133464
iteration 8295, loss 0.83130144
iteration 8296, loss 0.90177516
iteration 8297, loss 0.88955567
iteration 8298, loss 0.96535999
iteration 8299, loss 1.00793182
iteration 8300, loss 0.88124740
iteration 8301, loss 0.95867185
iteration 8302, loss 0.89663492
iteration 8303, loss 0.86520830
iteration 8304, loss 0.88691753
iteration 8305, loss 1.03552160
iteration 8306, loss 0.97531991
iteration 8307, loss 0.82922549
iteration 8308, loss 0.80564191
iteration 8309, loss 0.89576788
iteration 8310, loss 0.81460842
iteration 8311, loss 0.93064530
iteration 8312, loss 0.78802393
iteration 8313, loss 0.99714243
iteration 8314, loss 0.97966570
iteration 8315, loss 1.07111198
iteration 8316, loss 0.91110485
iteration 8317, loss 0.77864572
iteration 8318, loss 0.87049415
iteration 8319, loss 1.01919616
iteration 8320, loss 0.87610613
iteration 8321, loss 0.72741170
iteration 8322, loss 1.03384224
iteration 8323, loss 1.10069001
iteration 8324, loss 0.99061649
iteration 8325, loss 0.90433236
iteration 8326, loss 0.76398714
iteration 8327, loss 0.99848274
iteration 8328, loss 0.88123885
iteration 8329, loss 0.79633251
iteration 8330, loss 0.87749803
iteration 8331, loss 0.84035900
iteration 8332, loss 0.85166737
iteration 8333, loss 0.91139550
iteration 8334, loss 0.78061909
iteration 8335, loss 0.86810662
iteration 8336, loss 0.90934401
iteration 8337, loss 0.85167099
iteration 8338, loss 0.86526590
iteration 8339, loss 0.81793152
iteration 8340, loss 0.85559566
iteration 8341, loss 0.94001691
iteration 8342, loss 0.83593804
iteration 8343, loss 0.82025664
iteration 8344, loss 0.85613094
iteration 8345, loss 0.83265809
iteration 8346, loss 0.82837214
iteration 8347, loss 0.87917514
iteration 8348, loss 0.88031537
iteration 8349, loss 0.83469633
iteration 8350, loss 0.94565195
iteration 8351, loss 0.93469053
iteration 8352, loss 0.83241641
iteration 8353, loss 1.07301241
iteration 8354, loss 0.78049672
iteration 8355, loss 0.85513844
iteration 8356, loss 0.85750373
iteration 8357, loss 0.95036641
iteration 8358, loss 0.80006511
iteration 8359, loss 0.91594367
iteration 8360, loss 0.96882934
iteration 8361, loss 0.90342017
iteration 8362, loss 0.91247999
iteration 8363, loss 0.99850284
iteration 8364, loss 0.89536418
iteration 8365, loss 0.83198687
iteration 8366, loss 0.81482825
iteration 8367, loss 0.88310268
iteration 8368, loss 0.88004425
iteration 8369, loss 0.86267539
iteration 8370, loss 0.98642889
iteration 8371, loss 0.88677100
iteration 8372, loss 0.98074220
iteration 8373, loss 1.35011225
iteration 8374, loss 1.02072225
iteration 8375, loss 1.19208982
iteration 8376, loss 0.96178051
iteration 8377, loss 0.91884639
iteration 8378, loss 0.93523454
iteration 8379, loss 0.93190761
iteration 8380, loss 0.90493601
iteration 8381, loss 0.93630413
iteration 8382, loss 0.91918628
iteration 8383, loss 1.01335808
iteration 8384, loss 0.89277888
iteration 8385, loss 0.84297361
iteration 8386, loss 0.83431594
iteration 8387, loss 1.02032046
iteration 8388, loss 1.04829080
iteration 8389, loss 1.08396590
iteration 8390, loss 0.83351646
iteration 8391, loss 0.91301179
iteration 8392, loss 0.94909745
iteration 8393, loss 0.80843404
iteration 8394, loss 0.83300059
iteration 8395, loss 0.95360013
iteration 8396, loss 0.89377682
iteration 8397, loss 0.99005330
iteration 8398, loss 0.86802303
iteration 8399, loss 0.77523608
iteration 8400, loss 0.94382325
iteration 8401, loss 0.90305160
iteration 8402, loss 0.83355006
iteration 8403, loss 0.83992738
iteration 8404, loss 0.81858562
iteration 8405, loss 0.88128780
iteration 8406, loss 0.84907712
iteration 8407, loss 0.80151819
iteration 8408, loss 0.87943481
iteration 8409, loss 0.90016024
iteration 8410, loss 0.83249309
iteration 8411, loss 0.92335006
iteration 8412, loss 0.84754528
iteration 8413, loss 0.88069439
iteration 8414, loss 0.90493124
iteration 8415, loss 0.88771966
iteration 8416, loss 0.97186393
iteration 8417, loss 0.86673852
iteration 8418, loss 0.83448605
iteration 8419, loss 1.02637542
iteration 8420, loss 0.80027377
iteration 8421, loss 0.95844735
iteration 8422, loss 1.03092306
iteration 8423, loss 1.07427692
iteration 8424, loss 1.05876787
iteration 8425, loss 0.95531069
iteration 8426, loss 0.84691347
iteration 8427, loss 1.02514044
iteration 8428, loss 0.85470615
iteration 8429, loss 1.14915062
iteration 8430, loss 0.79938374
iteration 8431, loss 0.90687141
iteration 8432, loss 0.84239998
iteration 8433, loss 0.80978067
iteration 8434, loss 0.86653685
iteration 8435, loss 0.93561152
iteration 8436, loss 0.81818278
iteration 8437, loss 0.79857242
iteration 8438, loss 0.88078787
iteration 8439, loss 0.83080212
iteration 8440, loss 0.98583254
iteration 8441, loss 0.74783407
iteration 8442, loss 1.12413369
iteration 8443, loss 0.88607962
iteration 8444, loss 1.04747735
iteration 8445, loss 0.98732504
iteration 8446, loss 0.85018170
iteration 8447, loss 0.80950307
iteration 8448, loss 0.86737748
iteration 8449, loss 0.80801280
iteration 8450, loss 0.81020429
iteration 8451, loss 0.86494275
iteration 8452, loss 0.87646834
iteration 8453, loss 0.82099750
iteration 8454, loss 0.84232306
iteration 8455, loss 0.89442193
iteration 8456, loss 1.08684418
iteration 8457, loss 0.82420956
iteration 8458, loss 0.89720379
iteration 8459, loss 0.83309195
iteration 8460, loss 0.95087101
iteration 8461, loss 1.13431810
iteration 8462, loss 0.86030902
iteration 8463, loss 0.81010964
iteration 8464, loss 0.88867003
iteration 8465, loss 0.84325696
iteration 8466, loss 0.81037580
iteration 8467, loss 0.94575845
iteration 8468, loss 0.94508510
iteration 8469, loss 0.82405261
iteration 8470, loss 0.99454585
iteration 8471, loss 0.84130682
iteration 8472, loss 1.24071152
iteration 8473, loss 0.89589463
iteration 8474, loss 1.26112273
iteration 8475, loss 1.13627068
iteration 8476, loss 0.78196947
iteration 8477, loss 0.77494840
iteration 8478, loss 0.94361481
iteration 8479, loss 0.90000575
iteration 8480, loss 0.79256611
iteration 8481, loss 0.82114580
iteration 8482, loss 0.85896324
iteration 8483, loss 0.93420814
iteration 8484, loss 1.05430969
iteration 8485, loss 0.90219001
iteration 8486, loss 0.80773529
iteration 8487, loss 0.85423896
iteration 8488, loss 0.83284995
iteration 8489, loss 0.82105446
iteration 8490, loss 0.85611335
iteration 8491, loss 0.83542874
iteration 8492, loss 0.86736464
iteration 8493, loss 0.89072092
iteration 8494, loss 0.84738404
iteration 8495, loss 0.91642858
iteration 8496, loss 1.13477308
iteration 8497, loss 0.85266982
iteration 8498, loss 1.00342077
iteration 8499, loss 0.84603842
iteration 8500, loss 0.81763679
iteration 8501, loss 0.81369477
iteration 8502, loss 0.87815755
iteration 8503, loss 0.81144831
iteration 8504, loss 0.83907641
iteration 8505, loss 0.85712735
iteration 8506, loss 0.83491494
iteration 8507, loss 0.85654280
iteration 8508, loss 0.77719100
iteration 8509, loss 0.82265607
iteration 8510, loss 0.89160155
iteration 8511, loss 1.04949271
iteration 8512, loss 0.93548397
iteration 8513, loss 0.82724354
iteration 8514, loss 0.81849290
iteration 8515, loss 0.87857344
iteration 8516, loss 0.90504175
iteration 8517, loss 0.85753927
iteration 8518, loss 0.76550202
iteration 8519, loss 0.87082459
iteration 8520, loss 1.01746897
iteration 8521, loss 0.91291721
iteration 8522, loss 0.98152630
iteration 8523, loss 0.81457224
iteration 8524, loss 1.10434500
iteration 8525, loss 0.80141650
iteration 8526, loss 0.89386128
iteration 8527, loss 0.94265379
iteration 8528, loss 0.87488325
iteration 8529, loss 1.01349134
iteration 8530, loss 0.86080959
iteration 8531, loss 1.14450548
iteration 8532, loss 1.08521266
iteration 8533, loss 0.98571467
iteration 8534, loss 1.03610287
iteration 8535, loss 0.75672531
iteration 8536, loss 0.98057755
iteration 8537, loss 0.89876818
iteration 8538, loss 0.92478258
iteration 8539, loss 0.84472080
iteration 8540, loss 0.88019137
iteration 8541, loss 0.84094142
iteration 8542, loss 0.87322800
iteration 8543, loss 0.89333575
iteration 8544, loss 0.80256703
iteration 8545, loss 0.95409682
iteration 8546, loss 0.78656286
iteration 8547, loss 1.06841936
iteration 8548, loss 0.90721792
iteration 8549, loss 0.84205547
iteration 8550, loss 0.95463235
iteration 8551, loss 0.97199891
iteration 8552, loss 1.03863560
iteration 8553, loss 0.95392171
iteration 8554, loss 0.96201263
iteration 8555, loss 0.90998746
iteration 8556, loss 0.93102753
iteration 8557, loss 0.81639400
iteration 8558, loss 0.82143452
iteration 8559, loss 0.85389350
iteration 8560, loss 0.82863023
iteration 8561, loss 0.85134197
iteration 8562, loss 0.95705143
iteration 8563, loss 0.80990949
iteration 8564, loss 0.88125922
iteration 8565, loss 0.85923027
iteration 8566, loss 0.84902922
iteration 8567, loss 0.81962440
iteration 8568, loss 0.81572784
iteration 8569, loss 0.84556946
iteration 8570, loss 0.82684666
iteration 8571, loss 1.10568681
iteration 8572, loss 0.76955090
iteration 8573, loss 1.01284032
iteration 8574, loss 1.01814659
iteration 8575, loss 0.89452784
iteration 8576, loss 0.92522231
iteration 8577, loss 0.83536583
iteration 8578, loss 0.93962653
iteration 8579, loss 0.95942597
iteration 8580, loss 0.73364199
iteration 8581, loss 0.89857412
iteration 8582, loss 0.92023283
iteration 8583, loss 0.79409497
iteration 8584, loss 1.01806795
iteration 8585, loss 0.97011179
iteration 8586, loss 0.89856562
iteration 8587, loss 0.94242637
iteration 8588, loss 0.88869046
iteration 8589, loss 0.87587894
iteration 8590, loss 0.87697636
iteration 8591, loss 0.85890221
iteration 8592, loss 1.03584884
iteration 8593, loss 0.76079334
iteration 8594, loss 0.99391404
iteration 8595, loss 0.96462890
iteration 8596, loss 0.99902231
iteration 8597, loss 0.88654679
iteration 8598, loss 0.83524680
iteration 8599, loss 0.92016575
iteration 8600, loss 0.91650795
iteration 8601, loss 0.85768941
iteration 8602, loss 0.90833418
iteration 8603, loss 0.76044313
iteration 8604, loss 0.90600077
iteration 8605, loss 0.90909235
iteration 8606, loss 0.81601402
iteration 8607, loss 0.83846497
iteration 8608, loss 0.85255106
iteration 8609, loss 0.89182701
iteration 8610, loss 0.91689585
iteration 8611, loss 1.09279667
iteration 8612, loss 0.84209736
iteration 8613, loss 0.84729280
iteration 8614, loss 0.83976747
iteration 8615, loss 0.92511611
iteration 8616, loss 0.82999158
iteration 8617, loss 0.84606043
iteration 8618, loss 0.96056576
iteration 8619, loss 0.91793461
iteration 8620, loss 0.78626912
iteration 8621, loss 0.94628605
iteration 8622, loss 0.82690590
iteration 8623, loss 0.87169941
iteration 8624, loss 0.87519620
iteration 8625, loss 0.87102511
iteration 8626, loss 0.79886451
iteration 8627, loss 0.91016999
iteration 8628, loss 0.84235862
iteration 8629, loss 0.86497728
iteration 8630, loss 0.89239875
iteration 8631, loss 0.87758237
iteration 8632, loss 0.92096659
iteration 8633, loss 1.13051195
iteration 8634, loss 0.94187013
iteration 8635, loss 0.80915680
iteration 8636, loss 0.91092061
iteration 8637, loss 0.86402580
iteration 8638, loss 0.89901158
iteration 8639, loss 0.87556140
iteration 8640, loss 0.84200076
iteration 8641, loss 0.99885553
iteration 8642, loss 0.85291536
iteration 8643, loss 0.82202890
iteration 8644, loss 0.85356123
iteration 8645, loss 0.80565827
iteration 8646, loss 0.89398506
iteration 8647, loss 0.84906946
iteration 8648, loss 0.82818429
iteration 8649, loss 0.87301057
iteration 8650, loss 0.86076324
iteration 8651, loss 0.89066174
iteration 8652, loss 0.88032839
iteration 8653, loss 0.87892618
iteration 8654, loss 0.77326772
iteration 8655, loss 0.77886454
iteration 8656, loss 0.88839211
iteration 8657, loss 0.92325531
iteration 8658, loss 0.92451431
iteration 8659, loss 0.94663201
iteration 8660, loss 0.79539782
iteration 8661, loss 0.84170750
iteration 8662, loss 0.86715918
iteration 8663, loss 0.81827601
iteration 8664, loss 0.81009302
iteration 8665, loss 0.83453071
iteration 8666, loss 0.92025075
iteration 8667, loss 0.92950369
iteration 8668, loss 0.89696574
iteration 8669, loss 0.85548124
iteration 8670, loss 0.99115483
iteration 8671, loss 0.84633166
iteration 8672, loss 0.92148055
iteration 8673, loss 0.99945132
iteration 8674, loss 0.97834092
iteration 8675, loss 0.88257193
iteration 8676, loss 0.77627970
iteration 8677, loss 0.92190833
iteration 8678, loss 0.88531899
iteration 8679, loss 0.87650041
iteration 8680, loss 0.87957623
iteration 8681, loss 0.82383554
iteration 8682, loss 0.89138002
iteration 8683, loss 0.89480636
iteration 8684, loss 0.90284184
iteration 8685, loss 0.78999540
iteration 8686, loss 0.86682421
iteration 8687, loss 0.93916502
iteration 8688, loss 0.87874718
iteration 8689, loss 0.89473419
iteration 8690, loss 0.82830114
iteration 8691, loss 0.81627455
iteration 8692, loss 0.86024390
iteration 8693, loss 0.81235041
iteration 8694, loss 0.85376624
iteration 8695, loss 0.89804864
iteration 8696, loss 0.82335541
iteration 8697, loss 0.88146033
iteration 8698, loss 0.95455159
iteration 8699, loss 0.79482919
iteration 8700, loss 0.89825963
iteration 8701, loss 0.91808551
iteration 8702, loss 0.91335882
iteration 8703, loss 0.80969133
iteration 8704, loss 0.85358212
iteration 8705, loss 0.83651969
iteration 8706, loss 0.91050017
iteration 8707, loss 0.89465487
iteration 8708, loss 0.89744647
iteration 8709, loss 0.95818763
iteration 8710, loss 0.79118203
iteration 8711, loss 0.83292075
iteration 8712, loss 0.87512207
iteration 8713, loss 0.87335291
iteration 8714, loss 0.76211681
iteration 8715, loss 0.99611626
iteration 8716, loss 1.15950237
iteration 8717, loss 0.83236564
iteration 8718, loss 0.93208519
iteration 8719, loss 0.99126835
iteration 8720, loss 0.84951444
iteration 8721, loss 0.85681940
iteration 8722, loss 0.97000199
iteration 8723, loss 0.89435365
iteration 8724, loss 0.96273118
iteration 8725, loss 0.85858606
iteration 8726, loss 0.80524948
iteration 8727, loss 0.81913097
iteration 8728, loss 0.86682787
iteration 8729, loss 0.79754307
iteration 8730, loss 0.83690256
iteration 8731, loss 0.83794980
iteration 8732, loss 0.89227032
iteration 8733, loss 0.85746704
iteration 8734, loss 0.86297465
iteration 8735, loss 0.82923814
iteration 8736, loss 0.99057644
iteration 8737, loss 0.88393973
iteration 8738, loss 0.81691277
iteration 8739, loss 0.87029696
iteration 8740, loss 0.81686153
iteration 8741, loss 0.89869581
iteration 8742, loss 1.08839907
iteration 8743, loss 0.84317526
iteration 8744, loss 1.01018892
iteration 8745, loss 1.03673275
iteration 8746, loss 1.11480309
iteration 8747, loss 1.05672620
iteration 8748, loss 1.26870477
iteration 8749, loss 0.85126806
iteration 8750, loss 1.12152448
iteration 8751, loss 0.89699823
iteration 8752, loss 0.90808718
iteration 8753, loss 0.86115179
iteration 8754, loss 0.83320658
iteration 8755, loss 0.86065514
iteration 8756, loss 0.89898424
iteration 8757, loss 0.84870500
iteration 8758, loss 1.00046382
iteration 8759, loss 0.81414767
iteration 8760, loss 0.80296816
iteration 8761, loss 0.92481611
iteration 8762, loss 0.82933978
iteration 8763, loss 0.82639502
iteration 8764, loss 0.84878346
iteration 8765, loss 0.88064689
iteration 8766, loss 1.08906730
iteration 8767, loss 0.85387553
iteration 8768, loss 1.03353327
iteration 8769, loss 0.90907240
iteration 8770, loss 0.97366940
iteration 8771, loss 0.80136335
iteration 8772, loss 0.80915810
iteration 8773, loss 0.88758079
iteration 8774, loss 0.82293044
iteration 8775, loss 0.85917141
iteration 8776, loss 0.82084334
iteration 8777, loss 0.80142943
iteration 8778, loss 0.90116016
iteration 8779, loss 0.85908378
iteration 8780, loss 0.83423788
iteration 8781, loss 1.11651559
iteration 8782, loss 0.86660862
iteration 8783, loss 0.82556140
iteration 8784, loss 0.89476649
iteration 8785, loss 0.91429413
iteration 8786, loss 0.92377308
iteration 8787, loss 1.06671161
iteration 8788, loss 0.93353800
iteration 8789, loss 0.85458445
iteration 8790, loss 0.91333395
iteration 8791, loss 0.86706374
iteration 8792, loss 0.82723174
iteration 8793, loss 0.88134885
iteration 8794, loss 0.89173871
iteration 8795, loss 0.88472757
iteration 8796, loss 0.82411137
iteration 8797, loss 0.85049585
iteration 8798, loss 0.86292810
iteration 8799, loss 0.82158813
iteration 8800, loss 0.83885134
iteration 8801, loss 0.82215863
iteration 8802, loss 0.93362562
iteration 8803, loss 0.87314160
iteration 8804, loss 0.96731909
iteration 8805, loss 0.85102325
iteration 8806, loss 0.93472955
iteration 8807, loss 0.89988269
iteration 8808, loss 0.93893234
iteration 8809, loss 0.76704272
iteration 8810, loss 0.93847794
iteration 8811, loss 0.88260860
iteration 8812, loss 0.79442803
iteration 8813, loss 0.86337531
iteration 8814, loss 0.95216331
iteration 8815, loss 1.19875686
iteration 8816, loss 1.00707501
iteration 8817, loss 0.88584867
iteration 8818, loss 0.87513407
iteration 8819, loss 0.73423038
iteration 8820, loss 1.01334887
iteration 8821, loss 0.94664832
iteration 8822, loss 0.95613590
iteration 8823, loss 0.87944573
iteration 8824, loss 0.86848301
iteration 8825, loss 0.89987766
iteration 8826, loss 0.97957187
iteration 8827, loss 0.80150191
iteration 8828, loss 0.82958886
iteration 8829, loss 0.97341853
iteration 8830, loss 0.83333201
iteration 8831, loss 0.86823262
iteration 8832, loss 0.82220472
iteration 8833, loss 0.93341247
iteration 8834, loss 0.89250057
iteration 8835, loss 0.77295894
iteration 8836, loss 0.80748053
iteration 8837, loss 0.87256720
iteration 8838, loss 0.82204788
iteration 8839, loss 0.79608991
iteration 8840, loss 0.83398540
iteration 8841, loss 0.84154746
iteration 8842, loss 0.82650313
iteration 8843, loss 0.84829129
iteration 8844, loss 0.81879257
iteration 8845, loss 0.92710074
iteration 8846, loss 0.91290561
iteration 8847, loss 0.84391355
iteration 8848, loss 0.87433643
iteration 8849, loss 0.78955569
iteration 8850, loss 0.90613208
iteration 8851, loss 0.90865577
iteration 8852, loss 0.95653700
iteration 8853, loss 0.85247427
iteration 8854, loss 0.83679865
iteration 8855, loss 0.83886582
iteration 8856, loss 0.83152361
iteration 8857, loss 0.95389943
iteration 8858, loss 0.97417481
iteration 8859, loss 0.89067437
iteration 8860, loss 0.81000008
iteration 8861, loss 0.90680988
iteration 8862, loss 0.85301756
iteration 8863, loss 0.81713748
iteration 8864, loss 0.85394107
iteration 8865, loss 0.90465260
iteration 8866, loss 1.13481708
iteration 8867, loss 1.00839285
iteration 8868, loss 0.88545127
iteration 8869, loss 0.81243249
iteration 8870, loss 1.10421456
iteration 8871, loss 0.89752941
iteration 8872, loss 0.96078211
iteration 8873, loss 0.87922375
iteration 8874, loss 0.89929883
iteration 8875, loss 1.02724449
iteration 8876, loss 0.81022526
iteration 8877, loss 0.98099738
iteration 8878, loss 0.87124304
iteration 8879, loss 0.84081114
iteration 8880, loss 0.90368475
iteration 8881, loss 0.79360051
iteration 8882, loss 0.97686032
iteration 8883, loss 0.85722390
iteration 8884, loss 0.88757427
iteration 8885, loss 0.86416852
iteration 8886, loss 0.83588547
iteration 8887, loss 0.85609267
iteration 8888, loss 0.89775480
iteration 8889, loss 0.79050106
iteration 8890, loss 1.12244538
iteration 8891, loss 0.88552680
iteration 8892, loss 0.97320691
iteration 8893, loss 0.94692373
iteration 8894, loss 0.86524307
iteration 8895, loss 1.00753603
iteration 8896, loss 0.76704316
iteration 8897, loss 0.94422771
iteration 8898, loss 0.95274950
iteration 8899, loss 0.83563012
iteration 8900, loss 0.85799785
iteration 8901, loss 0.84007796
iteration 8902, loss 0.87259537
iteration 8903, loss 0.86413047
iteration 8904, loss 0.81314740
iteration 8905, loss 0.86907310
iteration 8906, loss 0.88372154
iteration 8907, loss 0.81074523
iteration 8908, loss 0.88317233
iteration 8909, loss 1.00814300
iteration 8910, loss 0.93640286
iteration 8911, loss 0.90718093
iteration 8912, loss 0.98936820
iteration 8913, loss 0.78993284
iteration 8914, loss 0.86656079
iteration 8915, loss 0.82375970
iteration 8916, loss 0.95082570
iteration 8917, loss 0.78658529
iteration 8918, loss 0.84879444
iteration 8919, loss 0.86448143
iteration 8920, loss 0.80706176
iteration 8921, loss 0.85519722
iteration 8922, loss 0.83480058
iteration 8923, loss 0.82340794
iteration 8924, loss 0.85821640
iteration 8925, loss 0.87554485
iteration 8926, loss 0.85569327
iteration 8927, loss 1.02209692
iteration 8928, loss 0.90692677
iteration 8929, loss 0.85388286
iteration 8930, loss 0.84139200
iteration 8931, loss 1.07186709
iteration 8932, loss 0.88055642
iteration 8933, loss 1.08478772
iteration 8934, loss 0.79550049
iteration 8935, loss 0.86290587
iteration 8936, loss 0.86768499
iteration 8937, loss 1.02480778
iteration 8938, loss 1.00963678
iteration 8939, loss 0.85227650
iteration 8940, loss 0.81218162
iteration 8941, loss 0.83609359
iteration 8942, loss 0.84642907
iteration 8943, loss 0.84458223
iteration 8944, loss 0.84814879
iteration 8945, loss 0.85804366
iteration 8946, loss 0.86515335
iteration 8947, loss 0.88074354
iteration 8948, loss 0.82076264
iteration 8949, loss 0.79881425
iteration 8950, loss 0.84770567
iteration 8951, loss 0.88259736
iteration 8952, loss 0.88026306
iteration 8953, loss 0.87281116
iteration 8954, loss 0.81460645
iteration 8955, loss 0.83425289
iteration 8956, loss 0.83584348
iteration 8957, loss 0.83901967
iteration 8958, loss 0.84921978
iteration 8959, loss 0.80413023
iteration 8960, loss 0.85912089
iteration 8961, loss 0.82146312
iteration 8962, loss 0.85321093
iteration 8963, loss 0.93915127
iteration 8964, loss 0.87221483
iteration 8965, loss 0.83473740
iteration 8966, loss 0.91265977
iteration 8967, loss 0.92944277
iteration 8968, loss 0.98168732
iteration 8969, loss 0.92489056
iteration 8970, loss 0.73909591
iteration 8971, loss 0.87557379
iteration 8972, loss 0.91186355
iteration 8973, loss 0.85888277
iteration 8974, loss 0.87121139
iteration 8975, loss 1.04226039
iteration 8976, loss 0.92186101
iteration 8977, loss 0.95445137
iteration 8978, loss 0.78479801
iteration 8979, loss 0.88939838
iteration 8980, loss 0.94101817
iteration 8981, loss 0.80465128
iteration 8982, loss 0.86148358
iteration 8983, loss 0.85949742
iteration 8984, loss 0.85793169
iteration 8985, loss 0.84983767
iteration 8986, loss 0.84907412
iteration 8987, loss 0.85299114
iteration 8988, loss 0.87035886
iteration 8989, loss 0.90340605
iteration 8990, loss 0.91756404
iteration 8991, loss 0.79348932
iteration 8992, loss 1.05080731
iteration 8993, loss 0.91663876
iteration 8994, loss 0.83259159
iteration 8995, loss 0.96873873
iteration 8996, loss 0.79763828
iteration 8997, loss 0.86702201
iteration 8998, loss 0.86043451
iteration 8999, loss 0.85069913
iteration 9000, loss 0.82284858
iteration 9001, loss 0.86773732
iteration 9002, loss 0.86365265
iteration 9003, loss 0.87341005
iteration 9004, loss 0.96365378
iteration 9005, loss 1.05030344
iteration 9006, loss 0.83122630
iteration 9007, loss 1.07046244
iteration 9008, loss 0.89807351
iteration 9009, loss 0.87735013
iteration 9010, loss 0.95208093
iteration 9011, loss 1.13298887
iteration 9012, loss 0.97736314
iteration 9013, loss 0.82046504
iteration 9014, loss 0.94621801
iteration 9015, loss 0.84554937
iteration 9016, loss 0.90825262
iteration 9017, loss 0.78933657
iteration 9018, loss 0.96227063
iteration 9019, loss 1.00310950
iteration 9020, loss 0.88205856
iteration 9021, loss 0.84109430
iteration 9022, loss 0.85096494
iteration 9023, loss 0.82206399
iteration 9024, loss 0.80647422
iteration 9025, loss 0.97393034
iteration 9026, loss 0.98701653
iteration 9027, loss 1.05022037
iteration 9028, loss 1.24480150
iteration 9029, loss 0.93411269
iteration 9030, loss 0.85524296
iteration 9031, loss 0.82236617
iteration 9032, loss 0.87520495
iteration 9033, loss 0.85171428
iteration 9034, loss 0.80175960
iteration 9035, loss 0.88516073
iteration 9036, loss 0.97926293
iteration 9037, loss 1.03786241
iteration 9038, loss 0.89934920
iteration 9039, loss 0.82368322
iteration 9040, loss 0.81691167
iteration 9041, loss 0.86384543
iteration 9042, loss 0.84995360
iteration 9043, loss 0.81396597
iteration 9044, loss 0.80366134
iteration 9045, loss 0.81689261
iteration 9046, loss 0.84514572
iteration 9047, loss 0.99489900
iteration 9048, loss 0.84934863
iteration 9049, loss 1.00305250
iteration 9050, loss 1.06784465
iteration 9051, loss 0.86329148
iteration 9052, loss 0.92487965
iteration 9053, loss 0.82432163
iteration 9054, loss 0.84385220
iteration 9055, loss 0.82765570
iteration 9056, loss 0.85445098
iteration 9057, loss 0.90137348
iteration 9058, loss 0.80982005
iteration 9059, loss 0.81715820
iteration 9060, loss 0.84460088
iteration 9061, loss 0.87973730
iteration 9062, loss 0.91540719
iteration 9063, loss 0.93301192
iteration 9064, loss 0.80139328
iteration 9065, loss 0.83545930
iteration 9066, loss 0.93245867
iteration 9067, loss 0.87403292
iteration 9068, loss 0.89916485
iteration 9069, loss 0.89157822
iteration 9070, loss 0.82992821
iteration 9071, loss 0.86590074
iteration 9072, loss 0.87847446
iteration 9073, loss 0.82743888
iteration 9074, loss 0.94440177
iteration 9075, loss 0.82456650
iteration 9076, loss 0.98152927
iteration 9077, loss 0.79735458
iteration 9078, loss 0.87242145
iteration 9079, loss 0.88413373
iteration 9080, loss 0.83669370
iteration 9081, loss 0.90351546
iteration 9082, loss 0.72694869
iteration 9083, loss 0.91593963
iteration 9084, loss 0.95763629
iteration 9085, loss 1.01340512
iteration 9086, loss 0.91041460
iteration 9087, loss 0.80429779
iteration 9088, loss 0.92163393
iteration 9089, loss 0.84920834
iteration 9090, loss 0.99013933
iteration 9091, loss 0.84920985
iteration 9092, loss 1.08403378
iteration 9093, loss 0.91594111
iteration 9094, loss 0.91086885
iteration 9095, loss 0.81471110
iteration 9096, loss 0.94279430
iteration 9097, loss 0.92311987
iteration 9098, loss 0.91859476
iteration 9099, loss 0.87888259
iteration 9100, loss 0.84740977
iteration 9101, loss 0.83617879
iteration 9102, loss 0.81711063
iteration 9103, loss 0.87013759
iteration 9104, loss 0.86684674
iteration 9105, loss 0.83197502
iteration 9106, loss 0.90227760
iteration 9107, loss 1.00420589
iteration 9108, loss 0.85894628
iteration 9109, loss 0.80316052
iteration 9110, loss 0.79540446
iteration 9111, loss 1.16423679
iteration 9112, loss 0.80154407
iteration 9113, loss 0.83086153
iteration 9114, loss 0.92173210
iteration 9115, loss 0.83793279
iteration 9116, loss 0.84036092
iteration 9117, loss 0.89519008
iteration 9118, loss 0.84912209
iteration 9119, loss 0.93478773
iteration 9120, loss 1.11235890
iteration 9121, loss 1.12739715
iteration 9122, loss 0.95838904
iteration 9123, loss 0.92541636
iteration 9124, loss 0.75762919
iteration 9125, loss 0.86250946
iteration 9126, loss 0.93486677
iteration 9127, loss 0.80865959
iteration 9128, loss 0.93922418
iteration 9129, loss 0.92365876
iteration 9130, loss 0.89616575
iteration 9131, loss 0.83592981
iteration 9132, loss 1.07553962
iteration 9133, loss 1.01071813
iteration 9134, loss 0.93713769
iteration 9135, loss 0.77132663
iteration 9136, loss 0.98245557
iteration 9137, loss 0.94181617
iteration 9138, loss 0.88490407
iteration 9139, loss 0.87029355
iteration 9140, loss 0.80684288
iteration 9141, loss 0.84534645
iteration 9142, loss 0.84755183
iteration 9143, loss 0.80291805
iteration 9144, loss 0.84628487
iteration 9145, loss 0.84244255
iteration 9146, loss 0.94638542
iteration 9147, loss 0.80842038
iteration 9148, loss 0.93023127
iteration 9149, loss 0.97933502
iteration 9150, loss 1.00430204
iteration 9151, loss 0.82086354
iteration 9152, loss 1.13083217
iteration 9153, loss 0.93243850
iteration 9154, loss 0.88808095
iteration 9155, loss 0.82111438
iteration 9156, loss 0.93933133
iteration 9157, loss 0.87933353
iteration 9158, loss 0.89249186
iteration 9159, loss 0.84668429
iteration 9160, loss 1.01310728
iteration 9161, loss 0.91361003
iteration 9162, loss 1.00543188
iteration 9163, loss 0.90361866
iteration 9164, loss 0.87286579
iteration 9165, loss 0.93541348
iteration 9166, loss 1.03294920
iteration 9167, loss 0.86528238
iteration 9168, loss 0.88988455
iteration 9169, loss 0.80664642
iteration 9170, loss 0.85942781
iteration 9171, loss 0.75472801
iteration 9172, loss 0.89034165
iteration 9173, loss 0.93325330
iteration 9174, loss 1.05130991
iteration 9175, loss 0.97352350
iteration 9176, loss 0.95047269
iteration 9177, loss 0.88598351
iteration 9178, loss 0.94695158
iteration 9179, loss 0.84725889
iteration 9180, loss 1.01946699
iteration 9181, loss 0.96151638
iteration 9182, loss 0.93195326
iteration 9183, loss 0.87120853
iteration 9184, loss 0.90006122
iteration 9185, loss 0.81942454
iteration 9186, loss 0.80545814
iteration 9187, loss 0.97106068
iteration 9188, loss 0.84556442
iteration 9189, loss 0.97726117
iteration 9190, loss 0.92926108
iteration 9191, loss 0.87674695
iteration 9192, loss 0.91226628
iteration 9193, loss 0.89213992
iteration 9194, loss 1.02325701
iteration 9195, loss 0.86921606
iteration 9196, loss 0.92941872
iteration 9197, loss 0.85811726
iteration 9198, loss 0.94967734
iteration 9199, loss 0.88936175
iteration 9200, loss 0.93165166
iteration 9201, loss 0.91875947
iteration 9202, loss 0.97802396
iteration 9203, loss 0.85679616
iteration 9204, loss 0.91046158
iteration 9205, loss 0.84812522
iteration 9206, loss 0.83845035
iteration 9207, loss 0.86995623
iteration 9208, loss 0.92466838
iteration 9209, loss 1.07242140
iteration 9210, loss 0.95773653
iteration 9211, loss 0.93129532
iteration 9212, loss 1.09560219
iteration 9213, loss 0.86599198
iteration 9214, loss 1.21892112
iteration 9215, loss 1.05192216
iteration 9216, loss 0.91371282
iteration 9217, loss 1.01516713
iteration 9218, loss 0.76805390
iteration 9219, loss 0.94800069
iteration 9220, loss 1.02290918
iteration 9221, loss 0.89188481
iteration 9222, loss 0.84957143
iteration 9223, loss 0.97150999
iteration 9224, loss 0.90332215
iteration 9225, loss 0.88650557
iteration 9226, loss 0.87010734
iteration 9227, loss 0.83598230
iteration 9228, loss 0.78116817
iteration 9229, loss 0.87199014
iteration 9230, loss 0.94057400
iteration 9231, loss 0.94852172
iteration 9232, loss 0.98844663
iteration 9233, loss 0.78969344
iteration 9234, loss 1.07888338
iteration 9235, loss 0.90517974
iteration 9236, loss 0.89077376
iteration 9237, loss 0.91842700
iteration 9238, loss 0.82677157
iteration 9239, loss 0.83704505
iteration 9240, loss 0.90955138
iteration 9241, loss 0.90039910
iteration 9242, loss 0.79463726
iteration 9243, loss 0.92400054
iteration 9244, loss 0.80658465
iteration 9245, loss 0.85863169
iteration 9246, loss 0.86196859
iteration 9247, loss 0.81648410
iteration 9248, loss 0.84578880
iteration 9249, loss 0.85321046
iteration 9250, loss 0.83973768
iteration 9251, loss 0.86046229
iteration 9252, loss 0.87559940
iteration 9253, loss 0.87670760
iteration 9254, loss 0.79413350
iteration 9255, loss 0.97246354
iteration 9256, loss 0.85535572
iteration 9257, loss 0.84666396
iteration 9258, loss 0.87551556
iteration 9259, loss 1.00280798
iteration 9260, loss 0.88414504
iteration 9261, loss 0.87167341
iteration 9262, loss 0.88871424
iteration 9263, loss 0.84810202
iteration 9264, loss 0.87468770
iteration 9265, loss 0.81326622
iteration 9266, loss 0.98853687
iteration 9267, loss 1.00117320
iteration 9268, loss 0.82127837
iteration 9269, loss 0.79165936
iteration 9270, loss 0.85027390
iteration 9271, loss 0.90131550
iteration 9272, loss 0.91999692
iteration 9273, loss 1.03810291
iteration 9274, loss 0.90357664
iteration 9275, loss 0.89640634
iteration 9276, loss 0.77403630
iteration 9277, loss 0.85046483
iteration 9278, loss 0.83929111
iteration 9279, loss 0.80400592
iteration 9280, loss 0.83176806
iteration 9281, loss 0.96473898
iteration 9282, loss 1.21050121
iteration 9283, loss 0.90378959
iteration 9284, loss 0.98423081
iteration 9285, loss 0.91941978
iteration 9286, loss 0.70811423
iteration 9287, loss 0.92491264
iteration 9288, loss 0.96471552
iteration 9289, loss 0.83064045
iteration 9290, loss 0.76797160
iteration 9291, loss 0.92848799
iteration 9292, loss 0.99989877
iteration 9293, loss 0.86217867
iteration 9294, loss 0.86970803
iteration 9295, loss 0.79657527
iteration 9296, loss 0.88533268
iteration 9297, loss 0.87483044
iteration 9298, loss 0.86886643
iteration 9299, loss 1.02294923
iteration 9300, loss 0.80900042
iteration 9301, loss 0.82444656
iteration 9302, loss 0.92434762
iteration 9303, loss 0.83244425
iteration 9304, loss 0.98904650
iteration 9305, loss 1.16746963
iteration 9306, loss 1.01272477
iteration 9307, loss 0.80628407
iteration 9308, loss 0.87608982
iteration 9309, loss 1.07929916
iteration 9310, loss 0.81735510
iteration 9311, loss 0.86933438
iteration 9312, loss 0.89711410
iteration 9313, loss 0.86849449
iteration 9314, loss 0.82576906
iteration 9315, loss 0.87873002
iteration 9316, loss 0.82422662
iteration 9317, loss 0.78001827
iteration 9318, loss 0.87767292
iteration 9319, loss 0.87194406
iteration 9320, loss 1.01724799
iteration 9321, loss 0.83073002
iteration 9322, loss 0.86643641
iteration 9323, loss 0.95572476
iteration 9324, loss 0.84634165
iteration 9325, loss 0.84908863
iteration 9326, loss 0.94026277
iteration 9327, loss 0.92988784
iteration 9328, loss 0.85318021
iteration 9329, loss 0.79909780
iteration 9330, loss 0.89135085
iteration 9331, loss 0.85477110
iteration 9332, loss 0.90328590
iteration 9333, loss 0.79967068
iteration 9334, loss 0.88890805
iteration 9335, loss 0.87288418
iteration 9336, loss 0.83993274
iteration 9337, loss 0.81864894
iteration 9338, loss 0.86080177
iteration 9339, loss 0.79456090
iteration 9340, loss 0.90494986
iteration 9341, loss 0.99587655
iteration 9342, loss 0.78523378
iteration 9343, loss 0.86471494
iteration 9344, loss 0.90152872
iteration 9345, loss 0.82560258
iteration 9346, loss 0.92096814
iteration 9347, loss 0.82025561
iteration 9348, loss 0.86759917
iteration 9349, loss 0.86197741
iteration 9350, loss 0.82999325
iteration 9351, loss 0.85218052
iteration 9352, loss 0.87149472
iteration 9353, loss 0.85776232
iteration 9354, loss 0.95311880
iteration 9355, loss 0.80156749
iteration 9356, loss 0.93479042
iteration 9357, loss 0.96884222
iteration 9358, loss 0.82847089
iteration 9359, loss 0.90576026
iteration 9360, loss 1.04971736
iteration 9361, loss 1.07907447
iteration 9362, loss 1.17039059
iteration 9363, loss 1.01524779
iteration 9364, loss 0.88849077
iteration 9365, loss 0.90529440
iteration 9366, loss 0.87486057
iteration 9367, loss 0.83986128
iteration 9368, loss 0.83789424
iteration 9369, loss 0.83678803
iteration 9370, loss 0.86322749
iteration 9371, loss 0.86491857
iteration 9372, loss 0.89007029
iteration 9373, loss 1.16999302
iteration 9374, loss 1.04315654
iteration 9375, loss 0.88965753
iteration 9376, loss 0.83034962
iteration 9377, loss 0.77414100
iteration 9378, loss 0.87060260
iteration 9379, loss 0.91834014
iteration 9380, loss 1.04177824
iteration 9381, loss 1.06466214
iteration 9382, loss 0.83997880
iteration 9383, loss 0.79776571
iteration 9384, loss 0.97635226
iteration 9385, loss 0.91289431
iteration 9386, loss 0.85465435
iteration 9387, loss 0.86144009
iteration 9388, loss 0.92212218
iteration 9389, loss 0.92524597
iteration 9390, loss 0.85972685
iteration 9391, loss 0.93965046
iteration 9392, loss 0.95133296
iteration 9393, loss 0.94260146
iteration 9394, loss 0.86022823
iteration 9395, loss 0.85988011
iteration 9396, loss 0.85769944
iteration 9397, loss 0.85556686
iteration 9398, loss 0.92413041
iteration 9399, loss 0.86812248
iteration 9400, loss 0.83404189
iteration 9401, loss 0.84992685
iteration 9402, loss 0.88676907
iteration 9403, loss 0.87318098
iteration 9404, loss 0.84247786
iteration 9405, loss 0.88084462
iteration 9406, loss 0.91459785
iteration 9407, loss 0.90306147
iteration 9408, loss 0.83603565
iteration 9409, loss 0.83857488
iteration 9410, loss 0.83327220
iteration 9411, loss 0.85430720
iteration 9412, loss 0.91074542
iteration 9413, loss 0.96338399
iteration 9414, loss 0.80559607
iteration 9415, loss 0.88252111
iteration 9416, loss 0.84052470
iteration 9417, loss 0.87457686
iteration 9418, loss 0.86681536
iteration 9419, loss 0.92388451
iteration 9420, loss 0.83938620
iteration 9421, loss 0.83829545
iteration 9422, loss 0.82921663
iteration 9423, loss 0.90891372
iteration 9424, loss 0.99197424
iteration 9425, loss 1.00333668
iteration 9426, loss 0.86521139
iteration 9427, loss 0.88751585
iteration 9428, loss 0.91697731
iteration 9429, loss 0.88900425
iteration 9430, loss 0.94490536
iteration 9431, loss 0.91199191
iteration 9432, loss 0.87969078
iteration 9433, loss 0.84227300
iteration 9434, loss 0.87050176
iteration 9435, loss 0.81761088
iteration 9436, loss 0.90892506
iteration 9437, loss 0.87538657
iteration 9438, loss 0.96636100
iteration 9439, loss 0.81686879
iteration 9440, loss 1.09343738
iteration 9441, loss 0.86844796
iteration 9442, loss 0.85380993
iteration 9443, loss 0.84727918
iteration 9444, loss 0.81754199
iteration 9445, loss 0.99094517
iteration 9446, loss 0.97217109
iteration 9447, loss 0.85937367
iteration 9448, loss 0.87277494
iteration 9449, loss 0.95302302
iteration 9450, loss 0.85987096
iteration 9451, loss 0.80734364
iteration 9452, loss 0.90875932
iteration 9453, loss 0.92774024
iteration 9454, loss 0.90094127
iteration 9455, loss 0.92522231
iteration 9456, loss 0.79228148
iteration 9457, loss 0.81986657
iteration 9458, loss 0.87126663
iteration 9459, loss 0.79413755
iteration 9460, loss 0.96595797
iteration 9461, loss 0.83929457
iteration 9462, loss 1.09233467
iteration 9463, loss 0.88402645
iteration 9464, loss 0.98030720
iteration 9465, loss 0.91547995
iteration 9466, loss 0.84950310
iteration 9467, loss 0.89234933
iteration 9468, loss 0.93145809
iteration 9469, loss 0.97085598
iteration 9470, loss 0.83406962
iteration 9471, loss 1.00683114
iteration 9472, loss 0.78895827
iteration 9473, loss 1.08249575
iteration 9474, loss 1.09682890
iteration 9475, loss 0.86079814
iteration 9476, loss 0.77516325
iteration 9477, loss 0.80792698
iteration 9478, loss 0.91478667
iteration 9479, loss 0.85830760
iteration 9480, loss 0.82969209
iteration 9481, loss 0.87616406
iteration 9482, loss 0.87247418
iteration 9483, loss 0.85381719
iteration 9484, loss 0.94211519
iteration 9485, loss 0.86780991
iteration 9486, loss 0.88003615
iteration 9487, loss 0.89667103
iteration 9488, loss 1.05818560
iteration 9489, loss 0.83269211
iteration 9490, loss 0.96731355
iteration 9491, loss 1.20009662
iteration 9492, loss 0.97320948
iteration 9493, loss 1.04299719
iteration 9494, loss 0.87612960
iteration 9495, loss 1.09384010
iteration 9496, loss 0.95559700
iteration 9497, loss 0.96481998
iteration 9498, loss 0.99446292
iteration 9499, loss 1.00732122
iteration 9500, loss 1.01293748
iteration 9501, loss 0.89005946
iteration 9502, loss 0.90650719
iteration 9503, loss 0.84448684
iteration 9504, loss 1.06977206
iteration 9505, loss 0.86677419
iteration 9506, loss 0.84699995
iteration 9507, loss 0.87767174
iteration 9508, loss 0.83117433
iteration 9509, loss 0.80748676
iteration 9510, loss 0.84779353
iteration 9511, loss 0.90739925
iteration 9512, loss 0.82132255
iteration 9513, loss 1.07097977
iteration 9514, loss 0.80013704
iteration 9515, loss 1.08060354
iteration 9516, loss 1.13587984
iteration 9517, loss 0.92419371
iteration 9518, loss 0.92450977
iteration 9519, loss 0.78235041
iteration 9520, loss 0.93596791
iteration 9521, loss 0.90078233
iteration 9522, loss 0.83352480
iteration 9523, loss 1.00366306
iteration 9524, loss 0.87533988
iteration 9525, loss 0.81729971
iteration 9526, loss 0.80888746
iteration 9527, loss 0.86083148
iteration 9528, loss 0.95665997
iteration 9529, loss 0.80786755
iteration 9530, loss 0.84765531
iteration 9531, loss 0.85931564
iteration 9532, loss 0.81486233
iteration 9533, loss 0.94266346
iteration 9534, loss 0.83924396
iteration 9535, loss 0.81341958
iteration 9536, loss 0.85950846
iteration 9537, loss 0.83562062
iteration 9538, loss 0.90981625
iteration 9539, loss 0.84592378
iteration 9540, loss 0.83100244
iteration 9541, loss 0.82604869
iteration 9542, loss 0.83970961
iteration 9543, loss 0.87345204
iteration 9544, loss 0.76604042
iteration 9545, loss 0.90291083
iteration 9546, loss 0.91161893
iteration 9547, loss 0.78926898
iteration 9548, loss 0.89583530
iteration 9549, loss 0.85221610
iteration 9550, loss 0.85233619
iteration 9551, loss 0.86085294
iteration 9552, loss 0.81833741
iteration 9553, loss 0.82678573
iteration 9554, loss 0.94136269
iteration 9555, loss 0.95185909
iteration 9556, loss 0.85409696
iteration 9557, loss 0.87390682
iteration 9558, loss 1.01921226
iteration 9559, loss 1.31850997
iteration 9560, loss 0.97086382
iteration 9561, loss 1.08398524
iteration 9562, loss 1.04523462
iteration 9563, loss 0.85790741
iteration 9564, loss 0.86304210
iteration 9565, loss 0.86486095
iteration 9566, loss 0.83153791
iteration 9567, loss 0.80106896
iteration 9568, loss 0.83980875
iteration 9569, loss 0.91529198
iteration 9570, loss 0.88041575
iteration 9571, loss 0.90651200
iteration 9572, loss 0.90381267
iteration 9573, loss 0.80310689
iteration 9574, loss 0.92122735
iteration 9575, loss 0.99110494
iteration 9576, loss 0.92275490
iteration 9577, loss 0.74176004
iteration 9578, loss 1.07638002
iteration 9579, loss 0.85103978
iteration 9580, loss 0.93838426
iteration 9581, loss 1.05808585
iteration 9582, loss 0.89115881
iteration 9583, loss 0.89928414
iteration 9584, loss 0.94749038
iteration 9585, loss 0.80463612
iteration 9586, loss 0.86809939
iteration 9587, loss 1.00983143
iteration 9588, loss 0.86052668
iteration 9589, loss 0.77724437
iteration 9590, loss 0.89761950
iteration 9591, loss 1.04726107
iteration 9592, loss 0.90657322
iteration 9593, loss 0.94985521
iteration 9594, loss 0.84623682
iteration 9595, loss 0.84908729
iteration 9596, loss 0.91325242
iteration 9597, loss 0.86747009
iteration 9598, loss 0.87252576
iteration 9599, loss 0.85938101
iteration 9600, loss 0.79357320
iteration 9601, loss 0.87602256
iteration 9602, loss 0.83444502
iteration 9603, loss 0.93969875
iteration 9604, loss 0.79749233
iteration 9605, loss 0.82405814
iteration 9606, loss 0.83247697
iteration 9607, loss 0.85845803
iteration 9608, loss 0.81583607
iteration 9609, loss 0.82150466
iteration 9610, loss 0.87251272
iteration 9611, loss 0.78023604
iteration 9612, loss 0.77572353
iteration 9613, loss 0.88509796
iteration 9614, loss 0.85726332
iteration 9615, loss 0.87255382
iteration 9616, loss 0.77115105
iteration 9617, loss 0.89795239
iteration 9618, loss 1.20799627
iteration 9619, loss 0.92286080
iteration 9620, loss 0.77132351
iteration 9621, loss 0.85442571
iteration 9622, loss 0.98023217
iteration 9623, loss 0.96142422
iteration 9624, loss 0.83564834
iteration 9625, loss 0.80190260
iteration 9626, loss 0.87938121
iteration 9627, loss 0.81190033
iteration 9628, loss 0.84628944
iteration 9629, loss 0.94894173
iteration 9630, loss 0.83708555
iteration 9631, loss 0.91521926
iteration 9632, loss 0.84592802
iteration 9633, loss 0.80495960
iteration 9634, loss 0.81234305
iteration 9635, loss 0.86101445
iteration 9636, loss 0.89903566
iteration 9637, loss 0.80210753
iteration 9638, loss 0.93541775
iteration 9639, loss 0.94052947
iteration 9640, loss 0.86292377
iteration 9641, loss 0.92527749
iteration 9642, loss 0.88030656
iteration 9643, loss 0.91314826
iteration 9644, loss 0.97370225
iteration 9645, loss 1.15141897
iteration 9646, loss 0.89374582
iteration 9647, loss 0.92959547
iteration 9648, loss 0.94269063
iteration 9649, loss 0.80997472
iteration 9650, loss 0.85005739
iteration 9651, loss 0.86849940
iteration 9652, loss 0.88269139
iteration 9653, loss 0.93625939
iteration 9654, loss 1.06002551
iteration 9655, loss 0.93697389
iteration 9656, loss 0.81976281
iteration 9657, loss 0.89252068
iteration 9658, loss 0.85954310
iteration 9659, loss 0.80570929
iteration 9660, loss 0.85519703
iteration 9661, loss 0.88406175
iteration 9662, loss 1.01891874
iteration 9663, loss 0.94711665
iteration 9664, loss 0.89765701
iteration 9665, loss 1.02082666
iteration 9666, loss 0.83610906
iteration 9667, loss 1.10507623
iteration 9668, loss 0.94651630
iteration 9669, loss 1.06052939
iteration 9670, loss 0.83143385
iteration 9671, loss 0.87480118
iteration 9672, loss 0.86833524
iteration 9673, loss 0.87171692
iteration 9674, loss 0.84902395
iteration 9675, loss 1.10299497
iteration 9676, loss 0.98369385
iteration 9677, loss 0.84827398
iteration 9678, loss 0.79591973
iteration 9679, loss 0.82859466
iteration 9680, loss 0.90677538
iteration 9681, loss 0.93272784
iteration 9682, loss 0.84752968
iteration 9683, loss 0.79597633
iteration 9684, loss 0.83280871
iteration 9685, loss 0.86801636
iteration 9686, loss 0.96935275
iteration 9687, loss 0.99835276
iteration 9688, loss 0.87533270
iteration 9689, loss 1.05318881
iteration 9690, loss 1.12472480
iteration 9691, loss 0.93341601
iteration 9692, loss 0.84500630
iteration 9693, loss 0.84197227
iteration 9694, loss 0.90702683
iteration 9695, loss 0.89754633
iteration 9696, loss 0.86685369
iteration 9697, loss 0.83147175
iteration 9698, loss 0.74542573
iteration 9699, loss 0.98909517
iteration 9700, loss 0.91908862
iteration 9701, loss 0.93095677
iteration 9702, loss 0.90244737
iteration 9703, loss 1.00433974
iteration 9704, loss 0.95902587
iteration 9705, loss 1.12928625
iteration 9706, loss 1.13170765
iteration 9707, loss 1.12862878
iteration 9708, loss 0.89506147
iteration 9709, loss 0.77852724
iteration 9710, loss 0.96701190
iteration 9711, loss 0.83139049
iteration 9712, loss 0.87147387
iteration 9713, loss 1.03924716
iteration 9714, loss 1.01352953
iteration 9715, loss 0.79047580
iteration 9716, loss 0.81917193
iteration 9717, loss 0.86405646
iteration 9718, loss 0.89696137
iteration 9719, loss 0.86320832
iteration 9720, loss 0.80880231
iteration 9721, loss 0.87498458
iteration 9722, loss 0.89998888
iteration 9723, loss 0.86196926
iteration 9724, loss 0.80321506
iteration 9725, loss 0.90188333
iteration 9726, loss 0.85974011
iteration 9727, loss 0.86058749
iteration 9728, loss 0.89985223
iteration 9729, loss 0.87625271
iteration 9730, loss 0.83055339
iteration 9731, loss 0.83103905
iteration 9732, loss 0.91853129
iteration 9733, loss 0.87945129
iteration 9734, loss 0.82717004
iteration 9735, loss 0.80194961
iteration 9736, loss 0.87205413
iteration 9737, loss 0.93611821
iteration 9738, loss 0.85260981
iteration 9739, loss 0.83091051
iteration 9740, loss 0.84500690
iteration 9741, loss 0.83765136
iteration 9742, loss 0.95869575
iteration 9743, loss 0.90065445
iteration 9744, loss 0.90699379
iteration 9745, loss 0.88150551
iteration 9746, loss 1.02687689
iteration 9747, loss 0.88516298
iteration 9748, loss 0.87238927
iteration 9749, loss 1.11821029
iteration 9750, loss 1.12112824
iteration 9751, loss 0.99063383
iteration 9752, loss 1.06685682
iteration 9753, loss 0.91753949
iteration 9754, loss 1.23737136
iteration 9755, loss 0.89397136
iteration 9756, loss 0.98663468
iteration 9757, loss 0.97148381
iteration 9758, loss 0.88171768
iteration 9759, loss 0.82511339
iteration 9760, loss 1.03771471
iteration 9761, loss 1.11995255
iteration 9762, loss 0.81883620
iteration 9763, loss 0.93008627
iteration 9764, loss 1.10759649
iteration 9765, loss 1.14205831
iteration 9766, loss 0.85310082
iteration 9767, loss 0.82164169
iteration 9768, loss 0.76111084
iteration 9769, loss 0.88328006
iteration 9770, loss 0.89448272
iteration 9771, loss 0.80694954
iteration 9772, loss 0.85551807
iteration 9773, loss 0.87655575
iteration 9774, loss 0.79175436
iteration 9775, loss 0.91706311
iteration 9776, loss 1.11050741
iteration 9777, loss 0.89541421
iteration 9778, loss 0.86342647
iteration 9779, loss 0.85786464
iteration 9780, loss 0.91949506
iteration 9781, loss 0.80530165
iteration 9782, loss 0.78693487
iteration 9783, loss 0.87292902
iteration 9784, loss 0.95280207
iteration 9785, loss 0.82390319
iteration 9786, loss 0.86960577
iteration 9787, loss 0.78744379
iteration 9788, loss 0.93674955
iteration 9789, loss 0.81510006
iteration 9790, loss 0.93470264
iteration 9791, loss 0.92473688
iteration 9792, loss 0.99613228
iteration 9793, loss 1.03998301
iteration 9794, loss 0.91085985
iteration 9795, loss 0.89520064
iteration 9796, loss 0.99056095
iteration 9797, loss 0.88958730
iteration 9798, loss 0.85214832
iteration 9799, loss 0.87755514
iteration 9800, loss 0.83177107
iteration 9801, loss 0.88249896
iteration 9802, loss 0.83798728
iteration 9803, loss 0.89055670
iteration 9804, loss 0.84499396
iteration 9805, loss 0.86234064
iteration 9806, loss 0.87923631
iteration 9807, loss 0.86036753
iteration 9808, loss 0.79031022
iteration 9809, loss 0.94489487
iteration 9810, loss 0.84215236
iteration 9811, loss 0.84412248
iteration 9812, loss 0.86672604
iteration 9813, loss 0.92060507
iteration 9814, loss 0.90308193
iteration 9815, loss 0.83983084
iteration 9816, loss 0.85488165
iteration 9817, loss 0.91793360
iteration 9818, loss 0.86381887
iteration 9819, loss 0.87327344
iteration 9820, loss 0.82327238
iteration 9821, loss 0.83745474
iteration 9822, loss 0.84062072
iteration 9823, loss 0.91332220
iteration 9824, loss 0.96258912
iteration 9825, loss 0.87655230
iteration 9826, loss 0.80705039
iteration 9827, loss 0.85107906
iteration 9828, loss 0.90770190
iteration 9829, loss 0.86224916
iteration 9830, loss 0.88293706
iteration 9831, loss 0.83703259
iteration 9832, loss 0.95902435
iteration 9833, loss 1.13046002
iteration 9834, loss 0.96937940
iteration 9835, loss 1.02351034
iteration 9836, loss 1.14027163
iteration 9837, loss 0.84056519
iteration 9838, loss 0.90628453
iteration 9839, loss 0.96822644
iteration 9840, loss 0.95941159
iteration 9841, loss 0.87664467
iteration 9842, loss 0.82106151
iteration 9843, loss 0.86153160
iteration 9844, loss 0.84789371
iteration 9845, loss 0.84124488
iteration 9846, loss 0.85589384
iteration 9847, loss 0.89400399
iteration 9848, loss 1.03370309
iteration 9849, loss 0.98411689
iteration 9850, loss 0.82515754
iteration 9851, loss 0.85802378
iteration 9852, loss 0.81860305
iteration 9853, loss 0.99617436
iteration 9854, loss 0.85639644
iteration 9855, loss 0.89441902
iteration 9856, loss 0.82171416
iteration 9857, loss 0.87475147
iteration 9858, loss 0.84394518
iteration 9859, loss 0.94627297
iteration 9860, loss 0.97669554
iteration 9861, loss 1.01847499
iteration 9862, loss 0.84485510
iteration 9863, loss 0.81366908
iteration 9864, loss 0.82881982
iteration 9865, loss 0.91146064
iteration 9866, loss 0.97402885
iteration 9867, loss 1.11730580
iteration 9868, loss 0.93151808
iteration 9869, loss 0.72261770
iteration 9870, loss 0.81327140
iteration 9871, loss 0.80979871
iteration 9872, loss 0.90124903
iteration 9873, loss 0.78550524
iteration 9874, loss 0.79364407
iteration 9875, loss 0.84976731
iteration 9876, loss 0.87421453
iteration 9877, loss 0.78658227
iteration 9878, loss 0.89212263
iteration 9879, loss 0.84693460
iteration 9880, loss 0.78896934
iteration 9881, loss 0.83227905
iteration 9882, loss 0.85948836
iteration 9883, loss 0.93353746
iteration 9884, loss 1.11324226
iteration 9885, loss 0.88866743
iteration 9886, loss 0.82262978
iteration 9887, loss 0.85298131
iteration 9888, loss 0.85059648
iteration 9889, loss 0.81925999
iteration 9890, loss 0.81984348
iteration 9891, loss 0.87400700
iteration 9892, loss 0.97744040
iteration 9893, loss 1.06580772
iteration 9894, loss 0.85296287
iteration 9895, loss 0.88394039
iteration 9896, loss 0.85830991
iteration 9897, loss 0.93669121
iteration 9898, loss 0.92475695
iteration 9899, loss 1.03898828
iteration 9900, loss 0.88070156
iteration 9901, loss 0.91433620
iteration 9902, loss 0.86088787
iteration 9903, loss 0.88997464
iteration 9904, loss 0.95121535
iteration 9905, loss 0.83197747
iteration 9906, loss 0.88368282
iteration 9907, loss 0.86155602
iteration 9908, loss 0.92804247
iteration 9909, loss 0.89302602
iteration 9910, loss 0.81034357
iteration 9911, loss 0.95595256
iteration 9912, loss 0.81539922
iteration 9913, loss 0.95363787
iteration 9914, loss 1.36764576
iteration 9915, loss 0.98095065
iteration 9916, loss 0.97634641
iteration 9917, loss 1.15277161
iteration 9918, loss 1.15750397
iteration 9919, loss 0.87955380
iteration 9920, loss 0.86145533
iteration 9921, loss 0.83498588
iteration 9922, loss 0.93661721
iteration 9923, loss 0.88040922
iteration 9924, loss 0.92231363
iteration 9925, loss 0.83878724
iteration 9926, loss 0.91005405
iteration 9927, loss 0.86541432
iteration 9928, loss 0.91783431
iteration 9929, loss 0.80081196
iteration 9930, loss 0.90012797
iteration 9931, loss 0.81617232
iteration 9932, loss 0.86376389
iteration 9933, loss 0.80495664
iteration 9934, loss 0.84305369
iteration 9935, loss 0.84085843
iteration 9936, loss 0.86386144
iteration 9937, loss 0.81818426
iteration 9938, loss 0.89497477
iteration 9939, loss 1.03304685
iteration 9940, loss 1.12986414
iteration 9941, loss 1.23936394
iteration 9942, loss 0.97453158
iteration 9943, loss 0.76832600
iteration 9944, loss 0.82431246
iteration 9945, loss 0.83475896
iteration 9946, loss 0.91055161
iteration 9947, loss 1.04089328
iteration 9948, loss 0.92452328
iteration 9949, loss 0.87520744
iteration 9950, loss 0.84317369
iteration 9951, loss 0.86452310
iteration 9952, loss 0.90988310
iteration 9953, loss 0.95368299
iteration 9954, loss 0.87997584
iteration 9955, loss 0.82718680
iteration 9956, loss 0.81068085
iteration 9957, loss 0.95184567
iteration 9958, loss 0.78737415
iteration 9959, loss 1.05246610
iteration 9960, loss 0.87526742
iteration 9961, loss 0.87859400
iteration 9962, loss 0.86639708
iteration 9963, loss 0.84003127
iteration 9964, loss 0.93008150
iteration 9965, loss 0.99113390
iteration 9966, loss 0.80621087
iteration 9967, loss 0.88571067
iteration 9968, loss 0.83003740
iteration 9969, loss 0.82293349
iteration 9970, loss 0.90847023
iteration 9971, loss 0.87546455
iteration 9972, loss 0.80562047
iteration 9973, loss 0.90625111
iteration 9974, loss 0.85626378
iteration 9975, loss 0.79238089
iteration 9976, loss 0.83372564
iteration 9977, loss 0.95549963
iteration 9978, loss 1.08642304
iteration 9979, loss 1.12318578
iteration 9980, loss 0.89885108
iteration 9981, loss 0.77102080
iteration 9982, loss 0.77269519
iteration 9983, loss 0.98317403
iteration 9984, loss 0.79717630
iteration 9985, loss 0.92905266
iteration 9986, loss 0.79580478
iteration 9987, loss 0.87372976
iteration 9988, loss 0.86769982
iteration 9989, loss 0.78602805
iteration 9990, loss 0.88575651
iteration 9991, loss 0.96394635
iteration 9992, loss 0.86983983
iteration 9993, loss 0.91684688
iteration 9994, loss 0.93114721
iteration 9995, loss 1.00415213
iteration 9996, loss 0.86360222
iteration 9997, loss 0.77897785
iteration 9998, loss 1.00386918
iteration 9999, loss 0.93269002
