#params: learningRate 0.010, momentum 0.100, numIterations 100000, printEvery 1000, printFirst 2000
iteration 0, loss 0.47531618
iteration 1, loss 0.48076258
iteration 2, loss 0.48594709
iteration 3, loss 0.49108179
iteration 4, loss 0.49597754
iteration 5, loss 0.50071677
iteration 6, loss 0.50529681
iteration 7, loss 0.50983745
iteration 8, loss 0.51413381
iteration 9, loss 0.51828755
iteration 10, loss 0.52222510
iteration 11, loss 0.52609250
iteration 12, loss 0.52990318
iteration 13, loss 0.53345347
iteration 14, loss 0.53691067
iteration 15, loss 0.54026069
iteration 16, loss 0.54345880
iteration 17, loss 0.54648802
iteration 18, loss 0.54953401
iteration 19, loss 0.55237573
iteration 20, loss 0.55514263
iteration 21, loss 0.55780061
iteration 22, loss 0.56039018
iteration 23, loss 0.56286641
iteration 24, loss 0.56519234
iteration 25, loss 0.56747591
iteration 26, loss 0.56969683
iteration 27, loss 0.57178183
iteration 28, loss 0.57381321
iteration 29, loss 0.57577817
iteration 30, loss 0.57766562
iteration 31, loss 0.57950480
iteration 32, loss 0.58127345
iteration 33, loss 0.58294303
iteration 34, loss 0.58456773
iteration 35, loss 0.58611843
iteration 36, loss 0.58763021
iteration 37, loss 0.58907672
iteration 38, loss 0.59046478
iteration 39, loss 0.59181423
iteration 40, loss 0.59312878
iteration 41, loss 0.59438066
iteration 42, loss 0.59558466
iteration 43, loss 0.59675169
iteration 44, loss 0.59787288
iteration 45, loss 0.59895856
iteration 46, loss 0.60001014
iteration 47, loss 0.60102908
iteration 48, loss 0.60199251
iteration 49, loss 0.60294842
iteration 50, loss 0.60386560
iteration 51, loss 0.60475788
iteration 52, loss 0.60559706
iteration 53, loss 0.60640250
iteration 54, loss 0.60720912
iteration 55, loss 0.60796683
iteration 56, loss 0.60871485
iteration 57, loss 0.60945107
iteration 58, loss 0.61012764
iteration 59, loss 0.61080442
iteration 60, loss 0.61144818
iteration 61, loss 0.61208405
iteration 62, loss 0.61268959
iteration 63, loss 0.61327542
iteration 64, loss 0.61383949
iteration 65, loss 0.61439504
iteration 66, loss 0.61492786
iteration 67, loss 0.61544709
iteration 68, loss 0.61594645
iteration 69, loss 0.61642733
iteration 70, loss 0.61692402
iteration 71, loss 0.61736215
iteration 72, loss 0.61780068
iteration 73, loss 0.61822928
iteration 74, loss 0.61864675
iteration 75, loss 0.61904463
iteration 76, loss 0.61943390
iteration 77, loss 0.61981029
iteration 78, loss 0.62018494
iteration 79, loss 0.62053704
iteration 80, loss 0.62088465
iteration 81, loss 0.62121606
iteration 82, loss 0.62154274
iteration 83, loss 0.62185446
iteration 84, loss 0.62216158
iteration 85, loss 0.62245823
iteration 86, loss 0.62274884
iteration 87, loss 0.62303074
iteration 88, loss 0.62330015
iteration 89, loss 0.62356474
iteration 90, loss 0.62382108
iteration 91, loss 0.62407100
iteration 92, loss 0.62430980
iteration 93, loss 0.62454599
iteration 94, loss 0.62477376
iteration 95, loss 0.62499566
iteration 96, loss 0.62521348
iteration 97, loss 0.62542480
iteration 98, loss 0.62562598
iteration 99, loss 0.62582076
iteration 100, loss 0.62601178
iteration 101, loss 0.62620042
iteration 102, loss 0.62637859
iteration 103, loss 0.62655360
iteration 104, loss 0.62673208
iteration 105, loss 0.62689834
iteration 106, loss 0.62706236
iteration 107, loss 0.62721992
iteration 108, loss 0.62736499
iteration 109, loss 0.62751476
iteration 110, loss 0.62765960
iteration 111, loss 0.62780148
iteration 112, loss 0.62794412
iteration 113, loss 0.62807551
iteration 114, loss 0.62820492
iteration 115, loss 0.62833447
iteration 116, loss 0.62845431
iteration 117, loss 0.62857309
iteration 118, loss 0.62868759
iteration 119, loss 0.62880073
iteration 120, loss 0.62891018
iteration 121, loss 0.62901710
iteration 122, loss 0.62912247
iteration 123, loss 0.62922387
iteration 124, loss 0.62932319
iteration 125, loss 0.62942083
iteration 126, loss 0.62952836
iteration 127, loss 0.62960263
iteration 128, loss 0.62969036
iteration 129, loss 0.62977713
iteration 130, loss 0.62986044
iteration 131, loss 0.62994334
iteration 132, loss 0.63002185
iteration 133, loss 0.63009793
iteration 134, loss 0.63017402
iteration 135, loss 0.63024964
iteration 136, loss 0.63032074
iteration 137, loss 0.63040472
iteration 138, loss 0.63045754
iteration 139, loss 0.63052527
iteration 140, loss 0.63058792
iteration 141, loss 0.63065059
iteration 142, loss 0.63072657
iteration 143, loss 0.63077046
iteration 144, loss 0.63082702
iteration 145, loss 0.63088334
iteration 146, loss 0.63093817
iteration 147, loss 0.63099148
iteration 148, loss 0.63104163
iteration 149, loss 0.63110774
iteration 150, loss 0.63114494
iteration 151, loss 0.63118855
iteration 152, loss 0.63123752
iteration 153, loss 0.63128064
iteration 154, loss 0.63132685
iteration 155, loss 0.63136968
iteration 156, loss 0.63140903
iteration 157, loss 0.63145055
iteration 158, loss 0.63149351
iteration 159, loss 0.63153166
iteration 160, loss 0.63156624
iteration 161, loss 0.63159880
iteration 162, loss 0.63164007
iteration 163, loss 0.63168694
iteration 164, loss 0.63170432
iteration 165, loss 0.63174034
iteration 166, loss 0.63176999
iteration 167, loss 0.63180387
iteration 168, loss 0.63183395
iteration 169, loss 0.63186426
iteration 170, loss 0.63190579
iteration 171, loss 0.63191805
iteration 172, loss 0.63194506
iteration 173, loss 0.63197389
iteration 174, loss 0.63199777
iteration 175, loss 0.63202065
iteration 176, loss 0.63206588
iteration 177, loss 0.63207181
iteration 178, loss 0.63211187
iteration 179, loss 0.63211816
iteration 180, loss 0.63215419
iteration 181, loss 0.63217746
iteration 182, loss 0.63218208
iteration 183, loss 0.63220126
iteration 184, loss 0.63221994
iteration 185, loss 0.63225869
iteration 186, loss 0.63225990
iteration 187, loss 0.63227713
iteration 188, loss 0.63229657
iteration 189, loss 0.63231576
iteration 190, loss 0.63232973
iteration 191, loss 0.63234515
iteration 192, loss 0.63236628
iteration 193, loss 0.63239196
iteration 194, loss 0.63239128
iteration 195, loss 0.63240674
iteration 196, loss 0.63241916
iteration 197, loss 0.63243549
iteration 198, loss 0.63244977
iteration 199, loss 0.63246119
iteration 200, loss 0.63247188
iteration 201, loss 0.63248564
iteration 202, loss 0.63249896
iteration 203, loss 0.63251033
iteration 204, loss 0.63252244
iteration 205, loss 0.63253381
iteration 206, loss 0.63254454
iteration 207, loss 0.63255252
iteration 208, loss 0.63256679
iteration 209, loss 0.63257484
iteration 210, loss 0.63258492
iteration 211, loss 0.63259133
iteration 212, loss 0.63260210
iteration 213, loss 0.63261200
iteration 214, loss 0.63261849
iteration 215, loss 0.63262902
iteration 216, loss 0.63263658
iteration 217, loss 0.63264615
iteration 218, loss 0.63265140
iteration 219, loss 0.63265864
iteration 220, loss 0.63266697
iteration 221, loss 0.63267072
iteration 222, loss 0.63268134
iteration 223, loss 0.63268632
iteration 224, loss 0.63268964
iteration 225, loss 0.63269918
iteration 226, loss 0.63270413
iteration 227, loss 0.63270873
iteration 228, loss 0.63271548
iteration 229, loss 0.63273779
iteration 230, loss 0.63272344
iteration 231, loss 0.63272986
iteration 232, loss 0.63273656
iteration 233, loss 0.63274125
iteration 234, loss 0.63274526
iteration 235, loss 0.63275082
iteration 236, loss 0.63275682
iteration 237, loss 0.63275982
iteration 238, loss 0.63276392
iteration 239, loss 0.63277031
iteration 240, loss 0.63278419
iteration 241, loss 0.63277539
iteration 242, loss 0.63277957
iteration 243, loss 0.63278217
iteration 244, loss 0.63278674
iteration 245, loss 0.63278829
iteration 246, loss 0.63279053
iteration 247, loss 0.63279491
iteration 248, loss 0.63279408
iteration 249, loss 0.63279700
iteration 250, loss 0.63280001
iteration 251, loss 0.63280244
iteration 252, loss 0.63280739
iteration 253, loss 0.63280991
iteration 254, loss 0.63281033
iteration 255, loss 0.63281089
iteration 256, loss 0.63281494
iteration 257, loss 0.63281795
iteration 258, loss 0.63281870
iteration 259, loss 0.63282203
iteration 260, loss 0.63282274
iteration 261, loss 0.63282335
iteration 262, loss 0.63282662
iteration 263, loss 0.63282664
iteration 264, loss 0.63282927
iteration 265, loss 0.63282884
iteration 266, loss 0.63282979
iteration 267, loss 0.63284922
iteration 268, loss 0.63283486
iteration 269, loss 0.63283692
iteration 270, loss 0.63283819
iteration 271, loss 0.63283719
iteration 272, loss 0.63283882
iteration 273, loss 0.63284008
iteration 274, loss 0.63284073
iteration 275, loss 0.63284226
iteration 276, loss 0.63284232
iteration 277, loss 0.63283769
iteration 278, loss 0.63284228
iteration 279, loss 0.63283928
iteration 280, loss 0.63284199
iteration 281, loss 0.63286099
iteration 282, loss 0.63284330
iteration 283, loss 0.63284579
iteration 284, loss 0.63284142
iteration 285, loss 0.63283936
iteration 286, loss 0.63284211
iteration 287, loss 0.63284307
iteration 288, loss 0.63284477
iteration 289, loss 0.63284684
iteration 290, loss 0.63286082
iteration 291, loss 0.63284316
iteration 292, loss 0.63284428
iteration 293, loss 0.63284559
iteration 294, loss 0.63284290
iteration 295, loss 0.63284668
iteration 296, loss 0.63284517
iteration 297, loss 0.63284445
iteration 298, loss 0.63284170
iteration 299, loss 0.63284491
iteration 300, loss 0.63284411
iteration 301, loss 0.63284237
iteration 302, loss 0.63284351
iteration 303, loss 0.63283946
iteration 304, loss 0.63283935
iteration 305, loss 0.63283880
iteration 306, loss 0.63283926
iteration 307, loss 0.63283799
iteration 308, loss 0.63283721
iteration 309, loss 0.63285188
iteration 310, loss 0.63283568
iteration 311, loss 0.63283572
iteration 312, loss 0.63283185
iteration 313, loss 0.63282907
iteration 314, loss 0.63282794
iteration 315, loss 0.63282661
iteration 316, loss 0.63282917
iteration 317, loss 0.63282947
iteration 318, loss 0.63282869
iteration 319, loss 0.63282369
iteration 320, loss 0.63282356
iteration 321, loss 0.63282496
iteration 322, loss 0.63283616
iteration 323, loss 0.63282281
iteration 324, loss 0.63282138
iteration 325, loss 0.63281810
iteration 326, loss 0.63281987
iteration 327, loss 0.63281837
iteration 328, loss 0.63281557
iteration 329, loss 0.63281750
iteration 330, loss 0.63283114
iteration 331, loss 0.63281128
iteration 332, loss 0.63281026
iteration 333, loss 0.63280712
iteration 334, loss 0.63280634
iteration 335, loss 0.63282154
iteration 336, loss 0.63280480
iteration 337, loss 0.63280290
iteration 338, loss 0.63280293
iteration 339, loss 0.63279951
iteration 340, loss 0.63279805
iteration 341, loss 0.63279949
iteration 342, loss 0.63279621
iteration 343, loss 0.63279657
iteration 344, loss 0.63279524
iteration 345, loss 0.63279363
iteration 346, loss 0.63279149
iteration 347, loss 0.63278825
iteration 348, loss 0.63278950
iteration 349, loss 0.63278403
iteration 350, loss 0.63280009
iteration 351, loss 0.63278419
iteration 352, loss 0.63278275
iteration 353, loss 0.63278363
iteration 354, loss 0.63277997
iteration 355, loss 0.63277756
iteration 356, loss 0.63277595
iteration 357, loss 0.63278601
iteration 358, loss 0.63277063
iteration 359, loss 0.63277188
iteration 360, loss 0.63276736
iteration 361, loss 0.63276424
iteration 362, loss 0.63276367
iteration 363, loss 0.63277682
iteration 364, loss 0.63275943
iteration 365, loss 0.63275901
iteration 366, loss 0.63275823
iteration 367, loss 0.63275431
iteration 368, loss 0.63275119
iteration 369, loss 0.63275084
iteration 370, loss 0.63274979
iteration 371, loss 0.63274659
iteration 372, loss 0.63274466
iteration 373, loss 0.63274227
iteration 374, loss 0.63273865
iteration 375, loss 0.63273408
iteration 376, loss 0.63273680
iteration 377, loss 0.63273403
iteration 378, loss 0.63273153
iteration 379, loss 0.63272795
iteration 380, loss 0.63274303
iteration 381, loss 0.63272578
iteration 382, loss 0.63272428
iteration 383, loss 0.63272066
iteration 384, loss 0.63271897
iteration 385, loss 0.63271711
iteration 386, loss 0.63271280
iteration 387, loss 0.63271186
iteration 388, loss 0.63270814
iteration 389, loss 0.63270843
iteration 390, loss 0.63270480
iteration 391, loss 0.63270315
iteration 392, loss 0.63270128
iteration 393, loss 0.63269941
iteration 394, loss 0.63269649
iteration 395, loss 0.63271024
iteration 396, loss 0.63269335
iteration 397, loss 0.63268979
iteration 398, loss 0.63270068
iteration 399, loss 0.63268181
iteration 400, loss 0.63268286
iteration 401, loss 0.63267941
iteration 402, loss 0.63267491
iteration 403, loss 0.63267915
iteration 404, loss 0.63267302
iteration 405, loss 0.63266815
iteration 406, loss 0.63266334
iteration 407, loss 0.63266165
iteration 408, loss 0.63265960
iteration 409, loss 0.63265726
iteration 410, loss 0.63265594
iteration 411, loss 0.63265455
iteration 412, loss 0.63265258
iteration 413, loss 0.63264911
iteration 414, loss 0.63265155
iteration 415, loss 0.63264482
iteration 416, loss 0.63264092
iteration 417, loss 0.63263877
iteration 418, loss 0.63263593
iteration 419, loss 0.63263329
iteration 420, loss 0.63263165
iteration 421, loss 0.63262708
iteration 422, loss 0.63262535
iteration 423, loss 0.63262513
iteration 424, loss 0.63262167
iteration 425, loss 0.63261996
iteration 426, loss 0.63261430
iteration 427, loss 0.63261107
iteration 428, loss 0.63262543
iteration 429, loss 0.63260706
iteration 430, loss 0.63260399
iteration 431, loss 0.63260014
iteration 432, loss 0.63259637
iteration 433, loss 0.63259377
iteration 434, loss 0.63259089
iteration 435, loss 0.63258697
iteration 436, loss 0.63258363
iteration 437, loss 0.63258251
iteration 438, loss 0.63257594
iteration 439, loss 0.63257620
iteration 440, loss 0.63257163
iteration 441, loss 0.63257055
iteration 442, loss 0.63256851
iteration 443, loss 0.63256393
iteration 444, loss 0.63255861
iteration 445, loss 0.63255741
iteration 446, loss 0.63255410
iteration 447, loss 0.63254997
iteration 448, loss 0.63254516
iteration 449, loss 0.63254466
iteration 450, loss 0.63254201
iteration 451, loss 0.63253707
iteration 452, loss 0.63253241
iteration 453, loss 0.63253148
iteration 454, loss 0.63253105
iteration 455, loss 0.63252496
iteration 456, loss 0.63252172
iteration 457, loss 0.63251697
iteration 458, loss 0.63251803
iteration 459, loss 0.63251217
iteration 460, loss 0.63250892
iteration 461, loss 0.63250750
iteration 462, loss 0.63250345
iteration 463, loss 0.63249790
iteration 464, loss 0.63249507
iteration 465, loss 0.63249273
iteration 466, loss 0.63250266
iteration 467, loss 0.63248436
iteration 468, loss 0.63248150
iteration 469, loss 0.63247602
iteration 470, loss 0.63247526
iteration 471, loss 0.63247238
iteration 472, loss 0.63246905
iteration 473, loss 0.63246567
iteration 474, loss 0.63246106
iteration 475, loss 0.63245700
iteration 476, loss 0.63246677
iteration 477, loss 0.63246597
iteration 478, loss 0.63244545
iteration 479, loss 0.63244183
iteration 480, loss 0.63243712
iteration 481, loss 0.63243016
iteration 482, loss 0.63242781
iteration 483, loss 0.63242423
iteration 484, loss 0.63242185
iteration 485, loss 0.63241516
iteration 486, loss 0.63243032
iteration 487, loss 0.63241363
iteration 488, loss 0.63240997
iteration 489, loss 0.63240588
iteration 490, loss 0.63239455
iteration 491, loss 0.63239252
iteration 492, loss 0.63238991
iteration 493, loss 0.63239066
iteration 494, loss 0.63238421
iteration 495, loss 0.63237996
iteration 496, loss 0.63237423
iteration 497, loss 0.63238631
iteration 498, loss 0.63236812
iteration 499, loss 0.63236236
iteration 500, loss 0.63235974
iteration 501, loss 0.63235223
iteration 502, loss 0.63234904
iteration 503, loss 0.63234784
iteration 504, loss 0.63234330
iteration 505, loss 0.63233789
iteration 506, loss 0.63233085
iteration 507, loss 0.63232521
iteration 508, loss 0.63232407
iteration 509, loss 0.63232070
iteration 510, loss 0.63231526
iteration 511, loss 0.63231086
iteration 512, loss 0.63230543
iteration 513, loss 0.63229833
iteration 514, loss 0.63229606
iteration 515, loss 0.63229070
iteration 516, loss 0.63228626
iteration 517, loss 0.63228069
iteration 518, loss 0.63227950
iteration 519, loss 0.63227185
iteration 520, loss 0.63228805
iteration 521, loss 0.63226728
iteration 522, loss 0.63226112
iteration 523, loss 0.63225803
iteration 524, loss 0.63225668
iteration 525, loss 0.63225077
iteration 526, loss 0.63224610
iteration 527, loss 0.63224044
iteration 528, loss 0.63224716
iteration 529, loss 0.63222458
iteration 530, loss 0.63224029
iteration 531, loss 0.63222048
iteration 532, loss 0.63221579
iteration 533, loss 0.63220873
iteration 534, loss 0.63220460
iteration 535, loss 0.63219960
iteration 536, loss 0.63219132
iteration 537, loss 0.63218991
iteration 538, loss 0.63218521
iteration 539, loss 0.63217845
iteration 540, loss 0.63217456
iteration 541, loss 0.63216795
iteration 542, loss 0.63216120
iteration 543, loss 0.63215493
iteration 544, loss 0.63214977
iteration 545, loss 0.63214823
iteration 546, loss 0.63214398
iteration 547, loss 0.63213640
iteration 548, loss 0.63213232
iteration 549, loss 0.63212921
iteration 550, loss 0.63212184
iteration 551, loss 0.63211542
iteration 552, loss 0.63212923
iteration 553, loss 0.63210695
iteration 554, loss 0.63210202
iteration 555, loss 0.63209383
iteration 556, loss 0.63209021
iteration 557, loss 0.63208368
iteration 558, loss 0.63207905
iteration 559, loss 0.63207218
iteration 560, loss 0.63206380
iteration 561, loss 0.63207688
iteration 562, loss 0.63205561
iteration 563, loss 0.63204749
iteration 564, loss 0.63204535
iteration 565, loss 0.63204038
iteration 566, loss 0.63203453
iteration 567, loss 0.63203908
iteration 568, loss 0.63201971
iteration 569, loss 0.63201410
iteration 570, loss 0.63200838
iteration 571, loss 0.63200281
iteration 572, loss 0.63199674
iteration 573, loss 0.63199003
iteration 574, loss 0.63198411
iteration 575, loss 0.63197710
iteration 576, loss 0.63197346
iteration 577, loss 0.63197864
iteration 578, loss 0.63195930
iteration 579, loss 0.63196560
iteration 580, loss 0.63194958
iteration 581, loss 0.63194030
iteration 582, loss 0.63193660
iteration 583, loss 0.63193074
iteration 584, loss 0.63192326
iteration 585, loss 0.63191524
iteration 586, loss 0.63190690
iteration 587, loss 0.63190654
iteration 588, loss 0.63189897
iteration 589, loss 0.63188945
iteration 590, loss 0.63188329
iteration 591, loss 0.63187343
iteration 592, loss 0.63186865
iteration 593, loss 0.63186479
iteration 594, loss 0.63185674
iteration 595, loss 0.63185095
iteration 596, loss 0.63184219
iteration 597, loss 0.63183886
iteration 598, loss 0.63183066
iteration 599, loss 0.63182489
iteration 600, loss 0.63181408
iteration 601, loss 0.63180519
iteration 602, loss 0.63180163
iteration 603, loss 0.63179745
iteration 604, loss 0.63178808
iteration 605, loss 0.63178135
iteration 606, loss 0.63177153
iteration 607, loss 0.63176666
iteration 608, loss 0.63175855
iteration 609, loss 0.63175447
iteration 610, loss 0.63174785
iteration 611, loss 0.63173725
iteration 612, loss 0.63172756
iteration 613, loss 0.63172407
iteration 614, loss 0.63171316
iteration 615, loss 0.63170635
iteration 616, loss 0.63170079
iteration 617, loss 0.63169152
iteration 618, loss 0.63168528
iteration 619, loss 0.63167455
iteration 620, loss 0.63167215
iteration 621, loss 0.63166257
iteration 622, loss 0.63165726
iteration 623, loss 0.63164440
iteration 624, loss 0.63163768
iteration 625, loss 0.63162860
iteration 626, loss 0.63162283
iteration 627, loss 0.63161680
iteration 628, loss 0.63162339
iteration 629, loss 0.63161858
iteration 630, loss 0.63160998
iteration 631, loss 0.63158151
iteration 632, loss 0.63157151
iteration 633, loss 0.63156833
iteration 634, loss 0.63155963
iteration 635, loss 0.63155224
iteration 636, loss 0.63153953
iteration 637, loss 0.63153288
iteration 638, loss 0.63152498
iteration 639, loss 0.63151942
iteration 640, loss 0.63150839
iteration 641, loss 0.63149855
iteration 642, loss 0.63149527
iteration 643, loss 0.63148837
iteration 644, loss 0.63147779
iteration 645, loss 0.63146858
iteration 646, loss 0.63146028
iteration 647, loss 0.63144953
iteration 648, loss 0.63144480
iteration 649, loss 0.63144590
iteration 650, loss 0.63142507
iteration 651, loss 0.63143389
iteration 652, loss 0.63140911
iteration 653, loss 0.63139858
iteration 654, loss 0.63138857
iteration 655, loss 0.63137512
iteration 656, loss 0.63136927
iteration 657, loss 0.63135703
iteration 658, loss 0.63134709
iteration 659, loss 0.63134327
iteration 660, loss 0.63133437
iteration 661, loss 0.63132357
iteration 662, loss 0.63132791
iteration 663, loss 0.63130262
iteration 664, loss 0.63129104
iteration 665, loss 0.63128272
iteration 666, loss 0.63127008
iteration 667, loss 0.63126334
iteration 668, loss 0.63125726
iteration 669, loss 0.63124149
iteration 670, loss 0.63123323
iteration 671, loss 0.63122549
iteration 672, loss 0.63121932
iteration 673, loss 0.63122386
iteration 674, loss 0.63119513
iteration 675, loss 0.63118407
iteration 676, loss 0.63117516
iteration 677, loss 0.63116503
iteration 678, loss 0.63115313
iteration 679, loss 0.63114322
iteration 680, loss 0.63113108
iteration 681, loss 0.63112116
iteration 682, loss 0.63111284
iteration 683, loss 0.63110553
iteration 684, loss 0.63109601
iteration 685, loss 0.63108556
iteration 686, loss 0.63107456
iteration 687, loss 0.63106435
iteration 688, loss 0.63105180
iteration 689, loss 0.63104119
iteration 690, loss 0.63102928
iteration 691, loss 0.63102100
iteration 692, loss 0.63100841
iteration 693, loss 0.63099564
iteration 694, loss 0.63100425
iteration 695, loss 0.63097390
iteration 696, loss 0.63095756
iteration 697, loss 0.63094634
iteration 698, loss 0.63093903
iteration 699, loss 0.63092875
iteration 700, loss 0.63091973
iteration 701, loss 0.63090426
iteration 702, loss 0.63089187
iteration 703, loss 0.63087943
iteration 704, loss 0.63086808
iteration 705, loss 0.63085497
iteration 706, loss 0.63084336
iteration 707, loss 0.63083589
iteration 708, loss 0.63082538
iteration 709, loss 0.63081372
iteration 710, loss 0.63081538
iteration 711, loss 0.63078969
iteration 712, loss 0.63078072
iteration 713, loss 0.63076983
iteration 714, loss 0.63075246
iteration 715, loss 0.63074090
iteration 716, loss 0.63072907
iteration 717, loss 0.63071720
iteration 718, loss 0.63070384
iteration 719, loss 0.63069220
iteration 720, loss 0.63067338
iteration 721, loss 0.63066325
iteration 722, loss 0.63065564
iteration 723, loss 0.63064334
iteration 724, loss 0.63062872
iteration 725, loss 0.63061550
iteration 726, loss 0.63059865
iteration 727, loss 0.63058129
iteration 728, loss 0.63057174
iteration 729, loss 0.63056225
iteration 730, loss 0.63056363
iteration 731, loss 0.63053407
iteration 732, loss 0.63052837
iteration 733, loss 0.63050691
iteration 734, loss 0.63049718
iteration 735, loss 0.63048444
iteration 736, loss 0.63047241
iteration 737, loss 0.63045454
iteration 738, loss 0.63045314
iteration 739, loss 0.63042360
iteration 740, loss 0.63041391
iteration 741, loss 0.63039829
iteration 742, loss 0.63038781
iteration 743, loss 0.63038664
iteration 744, loss 0.63035590
iteration 745, loss 0.63034412
iteration 746, loss 0.63033148
iteration 747, loss 0.63031354
iteration 748, loss 0.63029916
iteration 749, loss 0.63028408
iteration 750, loss 0.63027283
iteration 751, loss 0.63025650
iteration 752, loss 0.63024055
iteration 753, loss 0.63023051
iteration 754, loss 0.63020626
iteration 755, loss 0.63019385
iteration 756, loss 0.63018064
iteration 757, loss 0.63016611
iteration 758, loss 0.63014907
iteration 759, loss 0.63013368
iteration 760, loss 0.63012538
iteration 761, loss 0.63010550
iteration 762, loss 0.63008558
iteration 763, loss 0.63006765
iteration 764, loss 0.63005321
iteration 765, loss 0.63003784
iteration 766, loss 0.63002246
iteration 767, loss 0.63000991
iteration 768, loss 0.63000038
iteration 769, loss 0.62997908
iteration 770, loss 0.62996440
iteration 771, loss 0.62994583
iteration 772, loss 0.62994186
iteration 773, loss 0.62991068
iteration 774, loss 0.62989780
iteration 775, loss 0.62988291
iteration 776, loss 0.62986377
iteration 777, loss 0.62985583
iteration 778, loss 0.62983558
iteration 779, loss 0.62981302
iteration 780, loss 0.62979592
iteration 781, loss 0.62977697
iteration 782, loss 0.62976779
iteration 783, loss 0.62974890
iteration 784, loss 0.62973112
iteration 785, loss 0.62971269
iteration 786, loss 0.62969423
iteration 787, loss 0.62967831
iteration 788, loss 0.62965524
iteration 789, loss 0.62963768
iteration 790, loss 0.62962394
iteration 791, loss 0.62960470
iteration 792, loss 0.62959090
iteration 793, loss 0.62957398
iteration 794, loss 0.62955070
iteration 795, loss 0.62953349
iteration 796, loss 0.62951708
iteration 797, loss 0.62950021
iteration 798, loss 0.62949065
iteration 799, loss 0.62946377
iteration 800, loss 0.62944420
iteration 801, loss 0.62942321
iteration 802, loss 0.62940465
iteration 803, loss 0.62938645
iteration 804, loss 0.62936615
iteration 805, loss 0.62936419
iteration 806, loss 0.62932451
iteration 807, loss 0.62930545
iteration 808, loss 0.62929861
iteration 809, loss 0.62927108
iteration 810, loss 0.62925520
iteration 811, loss 0.62923160
iteration 812, loss 0.62921440
iteration 813, loss 0.62919554
iteration 814, loss 0.62917975
iteration 815, loss 0.62915638
iteration 816, loss 0.62913833
iteration 817, loss 0.62911099
iteration 818, loss 0.62909803
iteration 819, loss 0.62907805
iteration 820, loss 0.62905029
iteration 821, loss 0.62903473
iteration 822, loss 0.62900901
iteration 823, loss 0.62901272
iteration 824, loss 0.62897463
iteration 825, loss 0.62894974
iteration 826, loss 0.62893268
iteration 827, loss 0.62890209
iteration 828, loss 0.62888817
iteration 829, loss 0.62886413
iteration 830, loss 0.62883695
iteration 831, loss 0.62881521
iteration 832, loss 0.62879888
iteration 833, loss 0.62877229
iteration 834, loss 0.62876337
iteration 835, loss 0.62872820
iteration 836, loss 0.62871216
iteration 837, loss 0.62868982
iteration 838, loss 0.62866776
iteration 839, loss 0.62864372
iteration 840, loss 0.62861512
iteration 841, loss 0.62859611
iteration 842, loss 0.62857950
iteration 843, loss 0.62855975
iteration 844, loss 0.62853074
iteration 845, loss 0.62850896
iteration 846, loss 0.62848040
iteration 847, loss 0.62845788
iteration 848, loss 0.62843195
iteration 849, loss 0.62841213
iteration 850, loss 0.62839779
iteration 851, loss 0.62837012
iteration 852, loss 0.62835054
iteration 853, loss 0.62832537
iteration 854, loss 0.62829576
iteration 855, loss 0.62826800
iteration 856, loss 0.62823840
iteration 857, loss 0.62824091
iteration 858, loss 0.62819861
iteration 859, loss 0.62818112
iteration 860, loss 0.62815549
iteration 861, loss 0.62813590
iteration 862, loss 0.62810565
iteration 863, loss 0.62807849
iteration 864, loss 0.62805159
iteration 865, loss 0.62802256
iteration 866, loss 0.62799487
iteration 867, loss 0.62797803
iteration 868, loss 0.62795251
iteration 869, loss 0.62792610
iteration 870, loss 0.62789658
iteration 871, loss 0.62786951
iteration 872, loss 0.62785524
iteration 873, loss 0.62783102
iteration 874, loss 0.62780162
iteration 875, loss 0.62776893
iteration 876, loss 0.62773759
iteration 877, loss 0.62770587
iteration 878, loss 0.62770532
iteration 879, loss 0.62765886
iteration 880, loss 0.62763267
iteration 881, loss 0.62760745
iteration 882, loss 0.62758501
iteration 883, loss 0.62755244
iteration 884, loss 0.62752987
iteration 885, loss 0.62749945
iteration 886, loss 0.62748648
iteration 887, loss 0.62744927
iteration 888, loss 0.62742881
iteration 889, loss 0.62738466
iteration 890, loss 0.62736242
iteration 891, loss 0.62733928
iteration 892, loss 0.62730890
iteration 893, loss 0.62727496
iteration 894, loss 0.62724909
iteration 895, loss 0.62722962
iteration 896, loss 0.62720138
iteration 897, loss 0.62716557
iteration 898, loss 0.62713538
iteration 899, loss 0.62710527
iteration 900, loss 0.62707614
iteration 901, loss 0.62705166
iteration 902, loss 0.62701057
iteration 903, loss 0.62698185
iteration 904, loss 0.62695084
iteration 905, loss 0.62691617
iteration 906, loss 0.62688465
iteration 907, loss 0.62685455
iteration 908, loss 0.62682431
iteration 909, loss 0.62679695
iteration 910, loss 0.62676631
iteration 911, loss 0.62674083
iteration 912, loss 0.62670664
iteration 913, loss 0.62667546
iteration 914, loss 0.62664390
iteration 915, loss 0.62662234
iteration 916, loss 0.62659170
iteration 917, loss 0.62655376
iteration 918, loss 0.62652566
iteration 919, loss 0.62650509
iteration 920, loss 0.62646450
iteration 921, loss 0.62642610
iteration 922, loss 0.62639386
iteration 923, loss 0.62636174
iteration 924, loss 0.62632849
iteration 925, loss 0.62629423
iteration 926, loss 0.62625353
iteration 927, loss 0.62622011
iteration 928, loss 0.62618533
iteration 929, loss 0.62615432
iteration 930, loss 0.62612950
iteration 931, loss 0.62609458
iteration 932, loss 0.62608614
iteration 933, loss 0.62603694
iteration 934, loss 0.62601061
iteration 935, loss 0.62596224
iteration 936, loss 0.62594341
iteration 937, loss 0.62589667
iteration 938, loss 0.62585411
iteration 939, loss 0.62582387
iteration 940, loss 0.62579487
iteration 941, loss 0.62576149
iteration 942, loss 0.62572512
iteration 943, loss 0.62568083
iteration 944, loss 0.62564354
iteration 945, loss 0.62561053
iteration 946, loss 0.62557860
iteration 947, loss 0.62554471
iteration 948, loss 0.62549365
iteration 949, loss 0.62546454
iteration 950, loss 0.62542148
iteration 951, loss 0.62539157
iteration 952, loss 0.62535912
iteration 953, loss 0.62532455
iteration 954, loss 0.62529551
iteration 955, loss 0.62525868
iteration 956, loss 0.62523374
iteration 957, loss 0.62516863
iteration 958, loss 0.62514561
iteration 959, loss 0.62509685
iteration 960, loss 0.62505534
iteration 961, loss 0.62502576
iteration 962, loss 0.62498252
iteration 963, loss 0.62494710
iteration 964, loss 0.62490827
iteration 965, loss 0.62486872
iteration 966, loss 0.62483919
iteration 967, loss 0.62480565
iteration 968, loss 0.62475902
iteration 969, loss 0.62471897
iteration 970, loss 0.62469427
iteration 971, loss 0.62463436
iteration 972, loss 0.62461617
iteration 973, loss 0.62457167
iteration 974, loss 0.62451823
iteration 975, loss 0.62447191
iteration 976, loss 0.62443870
iteration 977, loss 0.62440040
iteration 978, loss 0.62436197
iteration 979, loss 0.62431040
iteration 980, loss 0.62426493
iteration 981, loss 0.62421959
iteration 982, loss 0.62417888
iteration 983, loss 0.62415358
iteration 984, loss 0.62410998
iteration 985, loss 0.62406738
iteration 986, loss 0.62400985
iteration 987, loss 0.62396810
iteration 988, loss 0.62393738
iteration 989, loss 0.62390267
iteration 990, loss 0.62388515
iteration 991, loss 0.62383457
iteration 992, loss 0.62377255
iteration 993, loss 0.62374618
iteration 994, loss 0.62368598
iteration 995, loss 0.62364438
iteration 996, loss 0.62360036
iteration 997, loss 0.62354588
iteration 998, loss 0.62352256
iteration 999, loss 0.62347464
iteration 1000, loss 0.62343200
iteration 1001, loss 0.62337884
iteration 1002, loss 0.62332889
iteration 1003, loss 0.62330549
iteration 1004, loss 0.62325299
iteration 1005, loss 0.62319938
iteration 1006, loss 0.62315418
iteration 1007, loss 0.62311257
iteration 1008, loss 0.62306915
iteration 1009, loss 0.62302315
iteration 1010, loss 0.62297645
iteration 1011, loss 0.62292324
iteration 1012, loss 0.62288498
iteration 1013, loss 0.62283485
iteration 1014, loss 0.62278852
iteration 1015, loss 0.62274011
iteration 1016, loss 0.62268951
iteration 1017, loss 0.62266528
iteration 1018, loss 0.62260917
iteration 1019, loss 0.62255337
iteration 1020, loss 0.62250148
iteration 1021, loss 0.62245678
iteration 1022, loss 0.62239466
iteration 1023, loss 0.62238065
iteration 1024, loss 0.62232283
iteration 1025, loss 0.62226212
iteration 1026, loss 0.62220716
iteration 1027, loss 0.62217037
iteration 1028, loss 0.62211737
iteration 1029, loss 0.62206777
iteration 1030, loss 0.62202916
iteration 1031, loss 0.62198966
iteration 1032, loss 0.62193707
iteration 1033, loss 0.62187841
iteration 1034, loss 0.62181853
iteration 1035, loss 0.62176312
iteration 1036, loss 0.62171893
iteration 1037, loss 0.62168065
iteration 1038, loss 0.62162895
iteration 1039, loss 0.62157695
iteration 1040, loss 0.62151626
iteration 1041, loss 0.62146529
iteration 1042, loss 0.62141724
iteration 1043, loss 0.62136428
iteration 1044, loss 0.62130656
iteration 1045, loss 0.62126155
iteration 1046, loss 0.62121897
iteration 1047, loss 0.62116326
iteration 1048, loss 0.62111158
iteration 1049, loss 0.62106231
iteration 1050, loss 0.62101964
iteration 1051, loss 0.62095361
iteration 1052, loss 0.62090387
iteration 1053, loss 0.62082564
iteration 1054, loss 0.62079437
iteration 1055, loss 0.62074409
iteration 1056, loss 0.62067488
iteration 1057, loss 0.62064502
iteration 1058, loss 0.62056348
iteration 1059, loss 0.62052331
iteration 1060, loss 0.62045849
iteration 1061, loss 0.62041031
iteration 1062, loss 0.62036403
iteration 1063, loss 0.62030985
iteration 1064, loss 0.62024643
iteration 1065, loss 0.62019941
iteration 1066, loss 0.62013217
iteration 1067, loss 0.62009781
iteration 1068, loss 0.62002104
iteration 1069, loss 0.61999361
iteration 1070, loss 0.61991485
iteration 1071, loss 0.61987200
iteration 1072, loss 0.61979330
iteration 1073, loss 0.61973720
iteration 1074, loss 0.61966962
iteration 1075, loss 0.61963001
iteration 1076, loss 0.61956139
iteration 1077, loss 0.61950486
iteration 1078, loss 0.61947148
iteration 1079, loss 0.61938614
iteration 1080, loss 0.61932695
iteration 1081, loss 0.61926774
iteration 1082, loss 0.61919735
iteration 1083, loss 0.61913945
iteration 1084, loss 0.61908584
iteration 1085, loss 0.61905298
iteration 1086, loss 0.61901343
iteration 1087, loss 0.61892113
iteration 1088, loss 0.61886578
iteration 1089, loss 0.61879924
iteration 1090, loss 0.61878065
iteration 1091, loss 0.61869635
iteration 1092, loss 0.61863450
iteration 1093, loss 0.61855416
iteration 1094, loss 0.61849683
iteration 1095, loss 0.61844215
iteration 1096, loss 0.61836847
iteration 1097, loss 0.61832484
iteration 1098, loss 0.61826485
iteration 1099, loss 0.61817808
iteration 1100, loss 0.61812806
iteration 1101, loss 0.61807189
iteration 1102, loss 0.61801458
iteration 1103, loss 0.61794697
iteration 1104, loss 0.61788171
iteration 1105, loss 0.61782064
iteration 1106, loss 0.61775795
iteration 1107, loss 0.61769439
iteration 1108, loss 0.61763444
iteration 1109, loss 0.61756329
iteration 1110, loss 0.61750554
iteration 1111, loss 0.61742502
iteration 1112, loss 0.61736420
iteration 1113, loss 0.61733988
iteration 1114, loss 0.61725509
iteration 1115, loss 0.61719732
iteration 1116, loss 0.61714585
iteration 1117, loss 0.61703987
iteration 1118, loss 0.61697534
iteration 1119, loss 0.61692603
iteration 1120, loss 0.61685610
iteration 1121, loss 0.61682393
iteration 1122, loss 0.61672545
iteration 1123, loss 0.61669015
iteration 1124, loss 0.61662343
iteration 1125, loss 0.61654584
iteration 1126, loss 0.61648857
iteration 1127, loss 0.61641193
iteration 1128, loss 0.61633767
iteration 1129, loss 0.61627204
iteration 1130, loss 0.61619476
iteration 1131, loss 0.61613871
iteration 1132, loss 0.61608080
iteration 1133, loss 0.61600518
iteration 1134, loss 0.61594718
iteration 1135, loss 0.61585850
iteration 1136, loss 0.61579508
iteration 1137, loss 0.61573122
iteration 1138, loss 0.61566584
iteration 1139, loss 0.61557391
iteration 1140, loss 0.61554727
iteration 1141, loss 0.61544976
iteration 1142, loss 0.61538899
iteration 1143, loss 0.61530425
iteration 1144, loss 0.61524525
iteration 1145, loss 0.61517990
iteration 1146, loss 0.61510420
iteration 1147, loss 0.61502447
iteration 1148, loss 0.61496642
iteration 1149, loss 0.61490927
iteration 1150, loss 0.61482898
iteration 1151, loss 0.61474964
iteration 1152, loss 0.61468010
iteration 1153, loss 0.61458893
iteration 1154, loss 0.61453354
iteration 1155, loss 0.61445477
iteration 1156, loss 0.61438499
iteration 1157, loss 0.61431494
iteration 1158, loss 0.61424891
iteration 1159, loss 0.61418693
iteration 1160, loss 0.61412072
iteration 1161, loss 0.61403745
iteration 1162, loss 0.61396904
iteration 1163, loss 0.61389748
iteration 1164, loss 0.61381377
iteration 1165, loss 0.61375034
iteration 1166, loss 0.61365306
iteration 1167, loss 0.61359873
iteration 1168, loss 0.61349910
iteration 1169, loss 0.61342503
iteration 1170, loss 0.61336805
iteration 1171, loss 0.61329517
iteration 1172, loss 0.61321396
iteration 1173, loss 0.61314111
iteration 1174, loss 0.61310357
iteration 1175, loss 0.61301574
iteration 1176, loss 0.61294043
iteration 1177, loss 0.61285213
iteration 1178, loss 0.61278312
iteration 1179, loss 0.61269975
iteration 1180, loss 0.61262101
iteration 1181, loss 0.61254323
iteration 1182, loss 0.61247125
iteration 1183, loss 0.61240836
iteration 1184, loss 0.61231389
iteration 1185, loss 0.61224281
iteration 1186, loss 0.61215625
iteration 1187, loss 0.61207872
iteration 1188, loss 0.61201366
iteration 1189, loss 0.61192751
iteration 1190, loss 0.61184690
iteration 1191, loss 0.61179924
iteration 1192, loss 0.61170109
iteration 1193, loss 0.61159815
iteration 1194, loss 0.61153958
iteration 1195, loss 0.61147378
iteration 1196, loss 0.61137661
iteration 1197, loss 0.61128606
iteration 1198, loss 0.61124244
iteration 1199, loss 0.61116761
iteration 1200, loss 0.61105617
iteration 1201, loss 0.61098079
iteration 1202, loss 0.61090595
iteration 1203, loss 0.61083560
iteration 1204, loss 0.61074761
iteration 1205, loss 0.61067490
iteration 1206, loss 0.61059257
iteration 1207, loss 0.61050359
iteration 1208, loss 0.61041576
iteration 1209, loss 0.61034094
iteration 1210, loss 0.61025444
iteration 1211, loss 0.61017550
iteration 1212, loss 0.61009472
iteration 1213, loss 0.61006014
iteration 1214, loss 0.60996008
iteration 1215, loss 0.60984773
iteration 1216, loss 0.60977266
iteration 1217, loss 0.60969634
iteration 1218, loss 0.60959339
iteration 1219, loss 0.60954412
iteration 1220, loss 0.60945649
iteration 1221, loss 0.60936331
iteration 1222, loss 0.60928104
iteration 1223, loss 0.60919242
iteration 1224, loss 0.60915956
iteration 1225, loss 0.60903385
iteration 1226, loss 0.60893697
iteration 1227, loss 0.60884995
iteration 1228, loss 0.60878965
iteration 1229, loss 0.60867594
iteration 1230, loss 0.60860731
iteration 1231, loss 0.60853469
iteration 1232, loss 0.60845303
iteration 1233, loss 0.60835596
iteration 1234, loss 0.60828940
iteration 1235, loss 0.60820993
iteration 1236, loss 0.60811263
iteration 1237, loss 0.60802908
iteration 1238, loss 0.60794480
iteration 1239, loss 0.60786966
iteration 1240, loss 0.60777215
iteration 1241, loss 0.60767857
iteration 1242, loss 0.60761740
iteration 1243, loss 0.60750801
iteration 1244, loss 0.60741152
iteration 1245, loss 0.60732573
iteration 1246, loss 0.60724117
iteration 1247, loss 0.60715605
iteration 1248, loss 0.60711775
iteration 1249, loss 0.60701371
iteration 1250, loss 0.60692658
iteration 1251, loss 0.60681147
iteration 1252, loss 0.60672299
iteration 1253, loss 0.60664296
iteration 1254, loss 0.60654348
iteration 1255, loss 0.60647873
iteration 1256, loss 0.60638386
iteration 1257, loss 0.60629044
iteration 1258, loss 0.60621028
iteration 1259, loss 0.60610443
iteration 1260, loss 0.60602444
iteration 1261, loss 0.60593332
iteration 1262, loss 0.60585385
iteration 1263, loss 0.60577294
iteration 1264, loss 0.60566044
iteration 1265, loss 0.60557903
iteration 1266, loss 0.60550560
iteration 1267, loss 0.60537072
iteration 1268, loss 0.60527555
iteration 1269, loss 0.60521512
iteration 1270, loss 0.60512436
iteration 1271, loss 0.60503920
iteration 1272, loss 0.60496281
iteration 1273, loss 0.60485948
iteration 1274, loss 0.60475556
iteration 1275, loss 0.60469645
iteration 1276, loss 0.60458550
iteration 1277, loss 0.60449428
iteration 1278, loss 0.60438594
iteration 1279, loss 0.60430217
iteration 1280, loss 0.60420436
iteration 1281, loss 0.60413552
iteration 1282, loss 0.60404429
iteration 1283, loss 0.60395019
iteration 1284, loss 0.60387311
iteration 1285, loss 0.60375129
iteration 1286, loss 0.60366500
iteration 1287, loss 0.60357411
iteration 1288, loss 0.60347158
iteration 1289, loss 0.60344162
iteration 1290, loss 0.60331863
iteration 1291, loss 0.60320307
iteration 1292, loss 0.60313442
iteration 1293, loss 0.60303413
iteration 1294, loss 0.60297783
iteration 1295, loss 0.60288148
iteration 1296, loss 0.60278496
iteration 1297, loss 0.60267140
iteration 1298, loss 0.60256152
iteration 1299, loss 0.60249721
iteration 1300, loss 0.60239031
iteration 1301, loss 0.60230279
iteration 1302, loss 0.60221828
iteration 1303, loss 0.60210935
iteration 1304, loss 0.60203595
iteration 1305, loss 0.60194528
iteration 1306, loss 0.60183638
iteration 1307, loss 0.60171259
iteration 1308, loss 0.60163821
iteration 1309, loss 0.60151448
iteration 1310, loss 0.60143187
iteration 1311, loss 0.60134153
iteration 1312, loss 0.60126602
iteration 1313, loss 0.60115503
iteration 1314, loss 0.60106965
iteration 1315, loss 0.60100009
iteration 1316, loss 0.60089678
iteration 1317, loss 0.60080589
iteration 1318, loss 0.60069554
iteration 1319, loss 0.60059311
iteration 1320, loss 0.60051346
iteration 1321, loss 0.60038201
iteration 1322, loss 0.60030673
iteration 1323, loss 0.60021927
iteration 1324, loss 0.60012680
iteration 1325, loss 0.59999818
iteration 1326, loss 0.59992341
iteration 1327, loss 0.59982908
iteration 1328, loss 0.59976118
iteration 1329, loss 0.59966212
iteration 1330, loss 0.59955858
iteration 1331, loss 0.59944027
iteration 1332, loss 0.59932596
iteration 1333, loss 0.59924445
iteration 1334, loss 0.59917204
iteration 1335, loss 0.59904335
iteration 1336, loss 0.59896311
iteration 1337, loss 0.59888380
iteration 1338, loss 0.59874759
iteration 1339, loss 0.59865374
iteration 1340, loss 0.59857622
iteration 1341, loss 0.59849333
iteration 1342, loss 0.59839763
iteration 1343, loss 0.59829249
iteration 1344, loss 0.59818687
iteration 1345, loss 0.59809797
iteration 1346, loss 0.59798137
iteration 1347, loss 0.59790030
iteration 1348, loss 0.59778781
iteration 1349, loss 0.59768596
iteration 1350, loss 0.59761141
iteration 1351, loss 0.59749697
iteration 1352, loss 0.59736813
iteration 1353, loss 0.59727456
iteration 1354, loss 0.59717128
iteration 1355, loss 0.59709245
iteration 1356, loss 0.59697398
iteration 1357, loss 0.59688532
iteration 1358, loss 0.59677621
iteration 1359, loss 0.59668785
iteration 1360, loss 0.59659791
iteration 1361, loss 0.59652487
iteration 1362, loss 0.59641893
iteration 1363, loss 0.59631023
iteration 1364, loss 0.59620607
iteration 1365, loss 0.59610129
iteration 1366, loss 0.59600188
iteration 1367, loss 0.59589351
iteration 1368, loss 0.59581764
iteration 1369, loss 0.59574242
iteration 1370, loss 0.59561035
iteration 1371, loss 0.59551188
iteration 1372, loss 0.59539115
iteration 1373, loss 0.59528592
iteration 1374, loss 0.59519437
iteration 1375, loss 0.59508233
iteration 1376, loss 0.59498886
iteration 1377, loss 0.59489872
iteration 1378, loss 0.59479617
iteration 1379, loss 0.59469763
iteration 1380, loss 0.59458470
iteration 1381, loss 0.59447364
iteration 1382, loss 0.59437813
iteration 1383, loss 0.59431502
iteration 1384, loss 0.59418855
iteration 1385, loss 0.59407682
iteration 1386, loss 0.59399741
iteration 1387, loss 0.59389628
iteration 1388, loss 0.59378331
iteration 1389, loss 0.59368331
iteration 1390, loss 0.59359150
iteration 1391, loss 0.59349788
iteration 1392, loss 0.59339439
iteration 1393, loss 0.59333237
iteration 1394, loss 0.59321683
iteration 1395, loss 0.59312091
iteration 1396, loss 0.59302133
iteration 1397, loss 0.59290809
iteration 1398, loss 0.59280502
iteration 1399, loss 0.59268679
iteration 1400, loss 0.59256067
iteration 1401, loss 0.59246019
iteration 1402, loss 0.59236212
iteration 1403, loss 0.59227377
iteration 1404, loss 0.59220558
iteration 1405, loss 0.59209362
iteration 1406, loss 0.59198409
iteration 1407, loss 0.59185527
iteration 1408, loss 0.59177173
iteration 1409, loss 0.59166623
iteration 1410, loss 0.59156175
iteration 1411, loss 0.59146149
iteration 1412, loss 0.59138424
iteration 1413, loss 0.59126559
iteration 1414, loss 0.59115126
iteration 1415, loss 0.59104764
iteration 1416, loss 0.59094229
iteration 1417, loss 0.59084452
iteration 1418, loss 0.59075492
iteration 1419, loss 0.59064764
iteration 1420, loss 0.59054230
iteration 1421, loss 0.59043839
iteration 1422, loss 0.59032380
iteration 1423, loss 0.59024020
iteration 1424, loss 0.59015476
iteration 1425, loss 0.59004488
iteration 1426, loss 0.58990567
iteration 1427, loss 0.58980620
iteration 1428, loss 0.58972243
iteration 1429, loss 0.58963222
iteration 1430, loss 0.58955234
iteration 1431, loss 0.58941237
iteration 1432, loss 0.58933304
iteration 1433, loss 0.58923085
iteration 1434, loss 0.58913869
iteration 1435, loss 0.58901266
iteration 1436, loss 0.58888803
iteration 1437, loss 0.58879134
iteration 1438, loss 0.58868972
iteration 1439, loss 0.58859287
iteration 1440, loss 0.58849400
iteration 1441, loss 0.58841251
iteration 1442, loss 0.58831519
iteration 1443, loss 0.58818676
iteration 1444, loss 0.58807380
iteration 1445, loss 0.58798823
iteration 1446, loss 0.58788968
iteration 1447, loss 0.58780803
iteration 1448, loss 0.58766094
iteration 1449, loss 0.58756280
iteration 1450, loss 0.58747469
iteration 1451, loss 0.58737593
iteration 1452, loss 0.58725319
iteration 1453, loss 0.58713041
iteration 1454, loss 0.58701886
iteration 1455, loss 0.58693084
iteration 1456, loss 0.58686234
iteration 1457, loss 0.58675916
iteration 1458, loss 0.58665124
iteration 1459, loss 0.58654532
iteration 1460, loss 0.58644373
iteration 1461, loss 0.58635604
iteration 1462, loss 0.58622216
iteration 1463, loss 0.58613131
iteration 1464, loss 0.58600502
iteration 1465, loss 0.58588980
iteration 1466, loss 0.58577531
iteration 1467, loss 0.58573282
iteration 1468, loss 0.58560342
iteration 1469, loss 0.58550250
iteration 1470, loss 0.58537391
iteration 1471, loss 0.58525604
iteration 1472, loss 0.58515395
iteration 1473, loss 0.58505174
iteration 1474, loss 0.58494471
iteration 1475, loss 0.58487437
iteration 1476, loss 0.58475169
iteration 1477, loss 0.58466212
iteration 1478, loss 0.58453520
iteration 1479, loss 0.58443903
iteration 1480, loss 0.58434078
iteration 1481, loss 0.58426653
iteration 1482, loss 0.58413893
iteration 1483, loss 0.58403153
iteration 1484, loss 0.58395303
iteration 1485, loss 0.58384518
iteration 1486, loss 0.58370742
iteration 1487, loss 0.58362233
iteration 1488, loss 0.58352089
iteration 1489, loss 0.58338640
iteration 1490, loss 0.58331680
iteration 1491, loss 0.58321942
iteration 1492, loss 0.58311693
iteration 1493, loss 0.58297694
iteration 1494, loss 0.58288852
iteration 1495, loss 0.58278403
iteration 1496, loss 0.58269127
iteration 1497, loss 0.58258795
iteration 1498, loss 0.58248906
iteration 1499, loss 0.58238134
iteration 1500, loss 0.58229678
iteration 1501, loss 0.58218720
iteration 1502, loss 0.58209106
iteration 1503, loss 0.58196503
iteration 1504, loss 0.58186006
iteration 1505, loss 0.58174859
iteration 1506, loss 0.58165314
iteration 1507, loss 0.58154927
iteration 1508, loss 0.58143467
iteration 1509, loss 0.58132868
iteration 1510, loss 0.58122516
iteration 1511, loss 0.58117577
iteration 1512, loss 0.58105280
iteration 1513, loss 0.58092129
iteration 1514, loss 0.58082116
iteration 1515, loss 0.58070008
iteration 1516, loss 0.58059502
iteration 1517, loss 0.58051739
iteration 1518, loss 0.58041558
iteration 1519, loss 0.58031837
iteration 1520, loss 0.58019522
iteration 1521, loss 0.58009877
iteration 1522, loss 0.57998260
iteration 1523, loss 0.57988580
iteration 1524, loss 0.57977499
iteration 1525, loss 0.57967515
iteration 1526, loss 0.57959799
iteration 1527, loss 0.57950012
iteration 1528, loss 0.57939912
iteration 1529, loss 0.57927992
iteration 1530, loss 0.57917264
iteration 1531, loss 0.57911949
iteration 1532, loss 0.57896751
iteration 1533, loss 0.57888085
iteration 1534, loss 0.57878676
iteration 1535, loss 0.57868432
iteration 1536, loss 0.57854394
iteration 1537, loss 0.57846961
iteration 1538, loss 0.57835802
iteration 1539, loss 0.57826625
iteration 1540, loss 0.57815930
iteration 1541, loss 0.57801787
iteration 1542, loss 0.57791509
iteration 1543, loss 0.57781483
iteration 1544, loss 0.57771090
iteration 1545, loss 0.57760301
iteration 1546, loss 0.57751528
iteration 1547, loss 0.57740816
iteration 1548, loss 0.57730287
iteration 1549, loss 0.57720334
iteration 1550, loss 0.57712211
iteration 1551, loss 0.57700795
iteration 1552, loss 0.57689262
iteration 1553, loss 0.57681537
iteration 1554, loss 0.57671659
iteration 1555, loss 0.57660642
iteration 1556, loss 0.57650005
iteration 1557, loss 0.57640073
iteration 1558, loss 0.57631382
iteration 1559, loss 0.57620932
iteration 1560, loss 0.57606143
iteration 1561, loss 0.57598850
iteration 1562, loss 0.57588259
iteration 1563, loss 0.57575294
iteration 1564, loss 0.57568325
iteration 1565, loss 0.57557955
iteration 1566, loss 0.57544609
iteration 1567, loss 0.57539013
iteration 1568, loss 0.57529401
iteration 1569, loss 0.57516026
iteration 1570, loss 0.57506933
iteration 1571, loss 0.57495686
iteration 1572, loss 0.57483514
iteration 1573, loss 0.57473007
iteration 1574, loss 0.57465051
iteration 1575, loss 0.57453271
iteration 1576, loss 0.57442504
iteration 1577, loss 0.57433149
iteration 1578, loss 0.57423111
iteration 1579, loss 0.57412851
iteration 1580, loss 0.57401610
iteration 1581, loss 0.57391600
iteration 1582, loss 0.57381361
iteration 1583, loss 0.57372191
iteration 1584, loss 0.57361693
iteration 1585, loss 0.57354106
iteration 1586, loss 0.57342411
iteration 1587, loss 0.57334345
iteration 1588, loss 0.57323560
iteration 1589, loss 0.57314624
iteration 1590, loss 0.57302835
iteration 1591, loss 0.57292142
iteration 1592, loss 0.57282667
iteration 1593, loss 0.57270355
iteration 1594, loss 0.57262446
iteration 1595, loss 0.57248620
iteration 1596, loss 0.57239753
iteration 1597, loss 0.57230198
iteration 1598, loss 0.57221810
iteration 1599, loss 0.57209956
iteration 1600, loss 0.57199446
iteration 1601, loss 0.57188413
iteration 1602, loss 0.57180785
iteration 1603, loss 0.57171688
iteration 1604, loss 0.57160369
iteration 1605, loss 0.57150825
iteration 1606, loss 0.57139097
iteration 1607, loss 0.57133207
iteration 1608, loss 0.57122128
iteration 1609, loss 0.57111103
iteration 1610, loss 0.57100024
iteration 1611, loss 0.57091530
iteration 1612, loss 0.57079147
iteration 1613, loss 0.57070284
iteration 1614, loss 0.57059723
iteration 1615, loss 0.57048689
iteration 1616, loss 0.57039788
iteration 1617, loss 0.57030441
iteration 1618, loss 0.57019009
iteration 1619, loss 0.57009830
iteration 1620, loss 0.56997179
iteration 1621, loss 0.56986585
iteration 1622, loss 0.56976760
iteration 1623, loss 0.56971429
iteration 1624, loss 0.56959789
iteration 1625, loss 0.56948897
iteration 1626, loss 0.56937816
iteration 1627, loss 0.56928938
iteration 1628, loss 0.56917965
iteration 1629, loss 0.56908305
iteration 1630, loss 0.56898703
iteration 1631, loss 0.56892675
iteration 1632, loss 0.56880154
iteration 1633, loss 0.56872320
iteration 1634, loss 0.56858766
iteration 1635, loss 0.56848455
iteration 1636, loss 0.56839792
iteration 1637, loss 0.56830518
iteration 1638, loss 0.56819564
iteration 1639, loss 0.56813083
iteration 1640, loss 0.56803138
iteration 1641, loss 0.56791182
iteration 1642, loss 0.56779618
iteration 1643, loss 0.56772967
iteration 1644, loss 0.56760218
iteration 1645, loss 0.56749675
iteration 1646, loss 0.56741224
iteration 1647, loss 0.56730295
iteration 1648, loss 0.56720045
iteration 1649, loss 0.56713015
iteration 1650, loss 0.56701403
iteration 1651, loss 0.56692036
iteration 1652, loss 0.56680221
iteration 1653, loss 0.56672165
iteration 1654, loss 0.56664487
iteration 1655, loss 0.56655131
iteration 1656, loss 0.56643020
iteration 1657, loss 0.56633422
iteration 1658, loss 0.56621053
iteration 1659, loss 0.56611314
iteration 1660, loss 0.56602259
iteration 1661, loss 0.56590732
iteration 1662, loss 0.56586453
iteration 1663, loss 0.56574646
iteration 1664, loss 0.56561680
iteration 1665, loss 0.56553553
iteration 1666, loss 0.56548103
iteration 1667, loss 0.56534926
iteration 1668, loss 0.56527704
iteration 1669, loss 0.56518053
iteration 1670, loss 0.56507215
iteration 1671, loss 0.56498703
iteration 1672, loss 0.56486002
iteration 1673, loss 0.56473883
iteration 1674, loss 0.56467061
iteration 1675, loss 0.56454851
iteration 1676, loss 0.56445693
iteration 1677, loss 0.56436061
iteration 1678, loss 0.56427687
iteration 1679, loss 0.56416150
iteration 1680, loss 0.56407152
iteration 1681, loss 0.56400418
iteration 1682, loss 0.56389278
iteration 1683, loss 0.56378063
iteration 1684, loss 0.56370133
iteration 1685, loss 0.56361723
iteration 1686, loss 0.56353524
iteration 1687, loss 0.56342571
iteration 1688, loss 0.56331322
iteration 1689, loss 0.56321605
iteration 1690, loss 0.56317730
iteration 1691, loss 0.56306149
iteration 1692, loss 0.56296089
iteration 1693, loss 0.56285980
iteration 1694, loss 0.56275583
iteration 1695, loss 0.56268120
iteration 1696, loss 0.56256111
iteration 1697, loss 0.56245466
iteration 1698, loss 0.56234889
iteration 1699, loss 0.56229334
iteration 1700, loss 0.56215935
iteration 1701, loss 0.56207793
iteration 1702, loss 0.56199034
iteration 1703, loss 0.56189371
iteration 1704, loss 0.56179143
iteration 1705, loss 0.56169878
iteration 1706, loss 0.56161874
iteration 1707, loss 0.56156297
iteration 1708, loss 0.56144302
iteration 1709, loss 0.56132683
iteration 1710, loss 0.56123853
iteration 1711, loss 0.56112157
iteration 1712, loss 0.56105853
iteration 1713, loss 0.56095336
iteration 1714, loss 0.56082551
iteration 1715, loss 0.56076590
iteration 1716, loss 0.56069008
iteration 1717, loss 0.56061015
iteration 1718, loss 0.56049886
iteration 1719, loss 0.56038375
iteration 1720, loss 0.56029470
iteration 1721, loss 0.56019787
iteration 1722, loss 0.56009632
iteration 1723, loss 0.56004537
iteration 1724, loss 0.55994570
iteration 1725, loss 0.55984838
iteration 1726, loss 0.55971237
iteration 1727, loss 0.55962155
iteration 1728, loss 0.55952833
iteration 1729, loss 0.55943510
iteration 1730, loss 0.55936410
iteration 1731, loss 0.55926111
iteration 1732, loss 0.55918572
iteration 1733, loss 0.55906911
iteration 1734, loss 0.55898042
iteration 1735, loss 0.55889828
iteration 1736, loss 0.55879742
iteration 1737, loss 0.55870879
iteration 1738, loss 0.55861987
iteration 1739, loss 0.55852732
iteration 1740, loss 0.55842631
iteration 1741, loss 0.55831829
iteration 1742, loss 0.55824598
iteration 1743, loss 0.55815431
iteration 1744, loss 0.55806191
iteration 1745, loss 0.55795672
iteration 1746, loss 0.55788984
iteration 1747, loss 0.55779367
iteration 1748, loss 0.55768186
iteration 1749, loss 0.55758248
iteration 1750, loss 0.55748912
iteration 1751, loss 0.55747415
iteration 1752, loss 0.55734130
iteration 1753, loss 0.55724274
iteration 1754, loss 0.55715219
iteration 1755, loss 0.55705497
iteration 1756, loss 0.55696905
iteration 1757, loss 0.55691101
iteration 1758, loss 0.55679915
iteration 1759, loss 0.55673642
iteration 1760, loss 0.55664112
iteration 1761, loss 0.55652633
iteration 1762, loss 0.55643995
iteration 1763, loss 0.55636385
iteration 1764, loss 0.55625575
iteration 1765, loss 0.55615936
iteration 1766, loss 0.55607239
iteration 1767, loss 0.55596393
iteration 1768, loss 0.55587654
iteration 1769, loss 0.55578405
iteration 1770, loss 0.55571609
iteration 1771, loss 0.55559630
iteration 1772, loss 0.55549620
iteration 1773, loss 0.55542551
iteration 1774, loss 0.55532384
iteration 1775, loss 0.55524620
iteration 1776, loss 0.55518838
iteration 1777, loss 0.55511226
iteration 1778, loss 0.55501360
iteration 1779, loss 0.55488762
iteration 1780, loss 0.55480620
iteration 1781, loss 0.55471441
iteration 1782, loss 0.55461353
iteration 1783, loss 0.55452968
iteration 1784, loss 0.55444004
iteration 1785, loss 0.55438979
iteration 1786, loss 0.55426836
iteration 1787, loss 0.55419063
iteration 1788, loss 0.55414733
iteration 1789, loss 0.55405657
iteration 1790, loss 0.55394163
iteration 1791, loss 0.55382852
iteration 1792, loss 0.55374368
iteration 1793, loss 0.55365434
iteration 1794, loss 0.55358888
iteration 1795, loss 0.55349177
iteration 1796, loss 0.55338300
iteration 1797, loss 0.55329473
iteration 1798, loss 0.55319895
iteration 1799, loss 0.55312902
iteration 1800, loss 0.55305211
iteration 1801, loss 0.55296702
iteration 1802, loss 0.55287417
iteration 1803, loss 0.55278174
iteration 1804, loss 0.55267609
iteration 1805, loss 0.55261372
iteration 1806, loss 0.55252673
iteration 1807, loss 0.55241260
iteration 1808, loss 0.55237095
iteration 1809, loss 0.55225250
iteration 1810, loss 0.55214576
iteration 1811, loss 0.55206680
iteration 1812, loss 0.55197243
iteration 1813, loss 0.55192502
iteration 1814, loss 0.55184463
iteration 1815, loss 0.55173651
iteration 1816, loss 0.55163099
iteration 1817, loss 0.55156906
iteration 1818, loss 0.55147772
iteration 1819, loss 0.55139081
iteration 1820, loss 0.55130367
iteration 1821, loss 0.55122352
iteration 1822, loss 0.55111737
iteration 1823, loss 0.55103359
iteration 1824, loss 0.55095754
iteration 1825, loss 0.55088586
iteration 1826, loss 0.55085212
iteration 1827, loss 0.55075833
iteration 1828, loss 0.55063268
iteration 1829, loss 0.55055587
iteration 1830, loss 0.55043344
iteration 1831, loss 0.55036322
iteration 1832, loss 0.55029327
iteration 1833, loss 0.55023852
iteration 1834, loss 0.55012736
iteration 1835, loss 0.55003821
iteration 1836, loss 0.54991916
iteration 1837, loss 0.54984780
iteration 1838, loss 0.54985272
iteration 1839, loss 0.54972205
iteration 1840, loss 0.54959424
iteration 1841, loss 0.54951712
iteration 1842, loss 0.54943028
iteration 1843, loss 0.54934169
iteration 1844, loss 0.54930229
iteration 1845, loss 0.54921172
iteration 1846, loss 0.54914517
iteration 1847, loss 0.54906470
iteration 1848, loss 0.54898131
iteration 1849, loss 0.54889571
iteration 1850, loss 0.54882279
iteration 1851, loss 0.54872056
iteration 1852, loss 0.54865088
iteration 1853, loss 0.54854237
iteration 1854, loss 0.54843113
iteration 1855, loss 0.54836413
iteration 1856, loss 0.54828743
iteration 1857, loss 0.54819882
iteration 1858, loss 0.54814117
iteration 1859, loss 0.54804196
iteration 1860, loss 0.54796907
iteration 1861, loss 0.54786424
iteration 1862, loss 0.54777734
iteration 1863, loss 0.54769920
iteration 1864, loss 0.54758529
iteration 1865, loss 0.54757612
iteration 1866, loss 0.54747916
iteration 1867, loss 0.54738190
iteration 1868, loss 0.54732980
iteration 1869, loss 0.54720549
iteration 1870, loss 0.54710807
iteration 1871, loss 0.54702591
iteration 1872, loss 0.54695148
iteration 1873, loss 0.54688258
iteration 1874, loss 0.54681233
iteration 1875, loss 0.54669154
iteration 1876, loss 0.54661424
iteration 1877, loss 0.54652768
iteration 1878, loss 0.54649418
iteration 1879, loss 0.54637519
iteration 1880, loss 0.54631598
iteration 1881, loss 0.54625123
iteration 1882, loss 0.54614691
iteration 1883, loss 0.54607706
iteration 1884, loss 0.54599462
iteration 1885, loss 0.54588344
iteration 1886, loss 0.54583946
iteration 1887, loss 0.54575682
iteration 1888, loss 0.54566646
iteration 1889, loss 0.54561249
iteration 1890, loss 0.54552535
iteration 1891, loss 0.54546015
iteration 1892, loss 0.54533065
iteration 1893, loss 0.54527676
iteration 1894, loss 0.54516339
iteration 1895, loss 0.54506790
iteration 1896, loss 0.54506211
iteration 1897, loss 0.54499199
iteration 1898, loss 0.54487959
iteration 1899, loss 0.54477810
iteration 1900, loss 0.54472523
iteration 1901, loss 0.54462497
iteration 1902, loss 0.54453235
iteration 1903, loss 0.54452442
iteration 1904, loss 0.54439597
iteration 1905, loss 0.54429061
iteration 1906, loss 0.54421250
iteration 1907, loss 0.54412255
iteration 1908, loss 0.54402669
iteration 1909, loss 0.54402859
iteration 1910, loss 0.54387623
iteration 1911, loss 0.54384363
iteration 1912, loss 0.54375720
iteration 1913, loss 0.54367987
iteration 1914, loss 0.54360933
iteration 1915, loss 0.54349955
iteration 1916, loss 0.54342965
iteration 1917, loss 0.54334931
iteration 1918, loss 0.54325414
iteration 1919, loss 0.54317084
iteration 1920, loss 0.54311864
iteration 1921, loss 0.54309117
iteration 1922, loss 0.54300666
iteration 1923, loss 0.54292790
iteration 1924, loss 0.54284437
iteration 1925, loss 0.54274396
iteration 1926, loss 0.54266747
iteration 1927, loss 0.54258859
iteration 1928, loss 0.54249389
iteration 1929, loss 0.54237902
iteration 1930, loss 0.54230239
iteration 1931, loss 0.54227622
iteration 1932, loss 0.54218912
iteration 1933, loss 0.54215058
iteration 1934, loss 0.54200538
iteration 1935, loss 0.54195067
iteration 1936, loss 0.54187309
iteration 1937, loss 0.54185656
iteration 1938, loss 0.54173722
iteration 1939, loss 0.54166569
iteration 1940, loss 0.54156769
iteration 1941, loss 0.54145586
iteration 1942, loss 0.54137898
iteration 1943, loss 0.54133793
iteration 1944, loss 0.54124286
iteration 1945, loss 0.54116519
iteration 1946, loss 0.54110486
iteration 1947, loss 0.54103688
iteration 1948, loss 0.54097720
iteration 1949, loss 0.54087358
iteration 1950, loss 0.54082160
iteration 1951, loss 0.54076130
iteration 1952, loss 0.54066677
iteration 1953, loss 0.54059409
iteration 1954, loss 0.54049515
iteration 1955, loss 0.54045190
iteration 1956, loss 0.54033744
iteration 1957, loss 0.54027968
iteration 1958, loss 0.54018048
iteration 1959, loss 0.54014562
iteration 1960, loss 0.54005278
iteration 1961, loss 0.53996716
iteration 1962, loss 0.53992291
iteration 1963, loss 0.53985076
iteration 1964, loss 0.53974324
iteration 1965, loss 0.53968558
iteration 1966, loss 0.53957299
iteration 1967, loss 0.53952247
iteration 1968, loss 0.53947233
iteration 1969, loss 0.53935338
iteration 1970, loss 0.53928537
iteration 1971, loss 0.53923690
iteration 1972, loss 0.53914141
iteration 1973, loss 0.53911532
iteration 1974, loss 0.53903077
iteration 1975, loss 0.53890288
iteration 1976, loss 0.53884817
iteration 1977, loss 0.53874624
iteration 1978, loss 0.53870002
iteration 1979, loss 0.53868101
iteration 1980, loss 0.53856924
iteration 1981, loss 0.53851421
iteration 1982, loss 0.53839810
iteration 1983, loss 0.53833111
iteration 1984, loss 0.53826576
iteration 1985, loss 0.53816809
iteration 1986, loss 0.53810647
iteration 1987, loss 0.53802341
iteration 1988, loss 0.53792875
iteration 1989, loss 0.53787069
iteration 1990, loss 0.53777121
iteration 1991, loss 0.53771237
iteration 1992, loss 0.53767260
iteration 1993, loss 0.53760500
iteration 1994, loss 0.53747806
iteration 1995, loss 0.53747077
iteration 1996, loss 0.53736151
iteration 1997, loss 0.53734783
iteration 1998, loss 0.53726965
iteration 1999, loss 0.53719417
iteration 2000, loss 0.53709776
iteration 3000, loss 0.48484982
iteration 4000, loss 0.44901892
iteration 5000, loss 0.41783672
iteration 6000, loss 0.39667488
iteration 7000, loss 0.38205397
iteration 8000, loss 0.37111523
iteration 9000, loss 0.36244538
iteration 10000, loss 0.35546474
iteration 11000, loss 0.34986480
iteration 12000, loss 0.34538035
iteration 13000, loss 0.34174699
iteration 14000, loss 0.33880505
iteration 15000, loss 0.33638966
iteration 16000, loss 0.33436514
iteration 17000, loss 0.33265105
iteration 18000, loss 0.33117870
iteration 19000, loss 0.32990994
iteration 20000, loss 0.32879158
iteration 21000, loss 0.32781450
iteration 22000, loss 0.32694682
iteration 23000, loss 0.32617357
iteration 24000, loss 0.32547718
iteration 25000, loss 0.32485262
iteration 26000, loss 0.32428645
iteration 27000, loss 0.32377354
iteration 28000, loss 0.32330680
iteration 29000, loss 0.32287892
iteration 30000, loss 0.32248623
iteration 31000, loss 0.32212377
iteration 32000, loss 0.32178803
iteration 33000, loss 0.32147847
iteration 34000, loss 0.32119133
iteration 35000, loss 0.32092267
iteration 36000, loss 0.32067237
iteration 37000, loss 0.32043800
iteration 38000, loss 0.32021815
iteration 39000, loss 0.32001092
iteration 40000, loss 0.31981650
iteration 41000, loss 0.31963235
iteration 42000, loss 0.31945934
iteration 43000, loss 0.31929487
iteration 44000, loss 0.31913892
iteration 45000, loss 0.31899113
iteration 46000, loss 0.31885120
iteration 47000, loss 0.31871708
iteration 48000, loss 0.31858881
iteration 49000, loss 0.31846776
iteration 50000, loss 0.31835180
iteration 51000, loss 0.31824005
iteration 52000, loss 0.31813394
iteration 53000, loss 0.31803203
iteration 54000, loss 0.31793409
iteration 55000, loss 0.31784057
iteration 56000, loss 0.31775059
iteration 57000, loss 0.31766355
iteration 58000, loss 0.31758037
iteration 59000, loss 0.31750005
iteration 60000, loss 0.31742287
iteration 61000, loss 0.31734815
iteration 62000, loss 0.31727618
iteration 63000, loss 0.31720667
iteration 64000, loss 0.31713972
iteration 65000, loss 0.31707471
iteration 66000, loss 0.31701208
iteration 67000, loss 0.31695135
iteration 68000, loss 0.31689232
iteration 69000, loss 0.31683545
iteration 70000, loss 0.31678011
iteration 71000, loss 0.31672652
iteration 72000, loss 0.31667465
iteration 73000, loss 0.31662422
iteration 74000, loss 0.31657523
iteration 75000, loss 0.31652774
iteration 76000, loss 0.31648148
iteration 77000, loss 0.31643638
iteration 78000, loss 0.31639259
iteration 79000, loss 0.31635002
iteration 80000, loss 0.31630855
iteration 81000, loss 0.31626822
iteration 82000, loss 0.31622896
iteration 83000, loss 0.31619069
iteration 84000, loss 0.31615328
iteration 85000, loss 0.31611705
iteration 86000, loss 0.31608132
iteration 87000, loss 0.31604684
iteration 88000, loss 0.31601291
iteration 89000, loss 0.31598000
iteration 90000, loss 0.31594774
iteration 91000, loss 0.31591639
iteration 92000, loss 0.31588559
iteration 93000, loss 0.31585538
iteration 94000, loss 0.31582620
iteration 95000, loss 0.31579746
iteration 96000, loss 0.31576916
iteration 97000, loss 0.31574173
iteration 98000, loss 0.31571484
iteration 99000, loss 0.31568854
