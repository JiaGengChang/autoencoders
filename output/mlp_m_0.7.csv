#params: learningRate 0.010, momentum 0.700, numIterations 100000, printEvery 1000, printFirst 2000
iteration 0, loss 0.47791144
iteration 1, loss 0.49220166
iteration 2, loss 0.50665855
iteration 3, loss 0.52009353
iteration 4, loss 0.53177580
iteration 5, loss 0.54225114
iteration 6, loss 0.55164249
iteration 7, loss 0.56033624
iteration 8, loss 0.56739833
iteration 9, loss 0.57395345
iteration 10, loss 0.57988486
iteration 11, loss 0.58505391
iteration 12, loss 0.58997193
iteration 13, loss 0.59395592
iteration 14, loss 0.59745985
iteration 15, loss 0.60071829
iteration 16, loss 0.60377268
iteration 17, loss 0.60640555
iteration 18, loss 0.60898604
iteration 19, loss 0.61093503
iteration 20, loss 0.61280001
iteration 21, loss 0.61464397
iteration 22, loss 0.61627979
iteration 23, loss 0.61771770
iteration 24, loss 0.61901187
iteration 25, loss 0.62008681
iteration 26, loss 0.62120471
iteration 27, loss 0.62239449
iteration 28, loss 0.62307116
iteration 29, loss 0.62398213
iteration 30, loss 0.62473081
iteration 31, loss 0.62548052
iteration 32, loss 0.62605273
iteration 33, loss 0.62669127
iteration 34, loss 0.62714926
iteration 35, loss 0.62757550
iteration 36, loss 0.62801118
iteration 37, loss 0.62843255
iteration 38, loss 0.62881816
iteration 39, loss 0.62921626
iteration 40, loss 0.62949203
iteration 41, loss 0.62981209
iteration 42, loss 0.63019112
iteration 43, loss 0.63032638
iteration 44, loss 0.63049716
iteration 45, loss 0.63069149
iteration 46, loss 0.63093944
iteration 47, loss 0.63110702
iteration 48, loss 0.63130175
iteration 49, loss 0.63148992
iteration 50, loss 0.63154881
iteration 51, loss 0.63177835
iteration 52, loss 0.63186830
iteration 53, loss 0.63203780
iteration 54, loss 0.63207514
iteration 55, loss 0.63209968
iteration 56, loss 0.63226083
iteration 57, loss 0.63250991
iteration 58, loss 0.63242621
iteration 59, loss 0.63254102
iteration 60, loss 0.63244031
iteration 61, loss 0.63266643
iteration 62, loss 0.63273271
iteration 63, loss 0.63261242
iteration 64, loss 0.63274635
iteration 65, loss 0.63278681
iteration 66, loss 0.63270184
iteration 67, loss 0.63288250
iteration 68, loss 0.63279509
iteration 69, loss 0.63293115
iteration 70, loss 0.63311520
iteration 71, loss 0.63297289
iteration 72, loss 0.63310384
iteration 73, loss 0.63301960
iteration 74, loss 0.63296684
iteration 75, loss 0.63300286
iteration 76, loss 0.63301521
iteration 77, loss 0.63307080
iteration 78, loss 0.63306482
iteration 79, loss 0.63304366
iteration 80, loss 0.63305742
iteration 81, loss 0.63302400
iteration 82, loss 0.63303071
iteration 83, loss 0.63306985
iteration 84, loss 0.63312190
iteration 85, loss 0.63305152
iteration 86, loss 0.63324197
iteration 87, loss 0.63315511
iteration 88, loss 0.63309701
iteration 89, loss 0.63318662
iteration 90, loss 0.63308187
iteration 91, loss 0.63313503
iteration 92, loss 0.63310068
iteration 93, loss 0.63310845
iteration 94, loss 0.63313188
iteration 95, loss 0.63306497
iteration 96, loss 0.63317271
iteration 97, loss 0.63307389
iteration 98, loss 0.63308939
iteration 99, loss 0.63310717
iteration 100, loss 0.63306322
iteration 101, loss 0.63321270
iteration 102, loss 0.63306303
iteration 103, loss 0.63308096
iteration 104, loss 0.63319827
iteration 105, loss 0.63318214
iteration 106, loss 0.63306970
iteration 107, loss 0.63331343
iteration 108, loss 0.63317014
iteration 109, loss 0.63302237
iteration 110, loss 0.63298125
iteration 111, loss 0.63306152
iteration 112, loss 0.63318838
iteration 113, loss 0.63299997
iteration 114, loss 0.63303439
iteration 115, loss 0.63317460
iteration 116, loss 0.63302724
iteration 117, loss 0.63302852
iteration 118, loss 0.63300849
iteration 119, loss 0.63302138
iteration 120, loss 0.63304154
iteration 121, loss 0.63296262
iteration 122, loss 0.63314399
iteration 123, loss 0.63303349
iteration 124, loss 0.63295328
iteration 125, loss 0.63305594
iteration 126, loss 0.63324282
iteration 127, loss 0.63292542
iteration 128, loss 0.63291645
iteration 129, loss 0.63292357
iteration 130, loss 0.63287615
iteration 131, loss 0.63288546
iteration 132, loss 0.63296925
iteration 133, loss 0.63289759
iteration 134, loss 0.63285315
iteration 135, loss 0.63290468
iteration 136, loss 0.63299387
iteration 137, loss 0.63310664
iteration 138, loss 0.63286016
iteration 139, loss 0.63284078
iteration 140, loss 0.63287039
iteration 141, loss 0.63281166
iteration 142, loss 0.63311946
iteration 143, loss 0.63279626
iteration 144, loss 0.63292587
iteration 145, loss 0.63279107
iteration 146, loss 0.63280484
iteration 147, loss 0.63295353
iteration 148, loss 0.63273357
iteration 149, loss 0.63299720
iteration 150, loss 0.63308706
iteration 151, loss 0.63281287
iteration 152, loss 0.63275585
iteration 153, loss 0.63271046
iteration 154, loss 0.63281677
iteration 155, loss 0.63266931
iteration 156, loss 0.63276381
iteration 157, loss 0.63267009
iteration 158, loss 0.63286348
iteration 159, loss 0.63274091
iteration 160, loss 0.63267916
iteration 161, loss 0.63270469
iteration 162, loss 0.63277785
iteration 163, loss 0.63288120
iteration 164, loss 0.63264109
iteration 165, loss 0.63261391
iteration 166, loss 0.63257963
iteration 167, loss 0.63259922
iteration 168, loss 0.63282331
iteration 169, loss 0.63267846
iteration 170, loss 0.63282410
iteration 171, loss 0.63258060
iteration 172, loss 0.63257058
iteration 173, loss 0.63248285
iteration 174, loss 0.63254810
iteration 175, loss 0.63248548
iteration 176, loss 0.63271833
iteration 177, loss 0.63250428
iteration 178, loss 0.63268745
iteration 179, loss 0.63238108
iteration 180, loss 0.63274065
iteration 181, loss 0.63260325
iteration 182, loss 0.63239263
iteration 183, loss 0.63239404
iteration 184, loss 0.63241476
iteration 185, loss 0.63263491
iteration 186, loss 0.63225643
iteration 187, loss 0.63226530
iteration 188, loss 0.63222590
iteration 189, loss 0.63222317
iteration 190, loss 0.63220220
iteration 191, loss 0.63226815
iteration 192, loss 0.63230887
iteration 193, loss 0.63249071
iteration 194, loss 0.63218039
iteration 195, loss 0.63210329
iteration 196, loss 0.63216730
iteration 197, loss 0.63211100
iteration 198, loss 0.63216110
iteration 199, loss 0.63203644
iteration 200, loss 0.63199168
iteration 201, loss 0.63202768
iteration 202, loss 0.63205151
iteration 203, loss 0.63193088
iteration 204, loss 0.63201241
iteration 205, loss 0.63196777
iteration 206, loss 0.63184393
iteration 207, loss 0.63183447
iteration 208, loss 0.63199360
iteration 209, loss 0.63186645
iteration 210, loss 0.63187870
iteration 211, loss 0.63190707
iteration 212, loss 0.63172966
iteration 213, loss 0.63170866
iteration 214, loss 0.63169968
iteration 215, loss 0.63166436
iteration 216, loss 0.63161481
iteration 217, loss 0.63175421
iteration 218, loss 0.63156694
iteration 219, loss 0.63153282
iteration 220, loss 0.63154801
iteration 221, loss 0.63162857
iteration 222, loss 0.63163664
iteration 223, loss 0.63157960
iteration 224, loss 0.63146286
iteration 225, loss 0.63140991
iteration 226, loss 0.63130804
iteration 227, loss 0.63132614
iteration 228, loss 0.63125405
iteration 229, loss 0.63161132
iteration 230, loss 0.63138065
iteration 231, loss 0.63128750
iteration 232, loss 0.63116228
iteration 233, loss 0.63121765
iteration 234, loss 0.63110848
iteration 235, loss 0.63103410
iteration 236, loss 0.63126885
iteration 237, loss 0.63101069
iteration 238, loss 0.63089251
iteration 239, loss 0.63089114
iteration 240, loss 0.63114445
iteration 241, loss 0.63087160
iteration 242, loss 0.63080916
iteration 243, loss 0.63080590
iteration 244, loss 0.63067547
iteration 245, loss 0.63073524
iteration 246, loss 0.63062243
iteration 247, loss 0.63064190
iteration 248, loss 0.63061914
iteration 249, loss 0.63052935
iteration 250, loss 0.63046050
iteration 251, loss 0.63046024
iteration 252, loss 0.63033965
iteration 253, loss 0.63032567
iteration 254, loss 0.63034981
iteration 255, loss 0.63019521
iteration 256, loss 0.63013483
iteration 257, loss 0.63016242
iteration 258, loss 0.63007631
iteration 259, loss 0.62999324
iteration 260, loss 0.62993750
iteration 261, loss 0.62990803
iteration 262, loss 0.62997662
iteration 263, loss 0.62974454
iteration 264, loss 0.62980164
iteration 265, loss 0.62967517
iteration 266, loss 0.62960678
iteration 267, loss 0.62980557
iteration 268, loss 0.62953816
iteration 269, loss 0.62942993
iteration 270, loss 0.62956718
iteration 271, loss 0.62952705
iteration 272, loss 0.62930615
iteration 273, loss 0.62918399
iteration 274, loss 0.62922346
iteration 275, loss 0.62904888
iteration 276, loss 0.62903805
iteration 277, loss 0.62915330
iteration 278, loss 0.62901486
iteration 279, loss 0.62887716
iteration 280, loss 0.62887087
iteration 281, loss 0.62892026
iteration 282, loss 0.62865237
iteration 283, loss 0.62868461
iteration 284, loss 0.62863637
iteration 285, loss 0.62839689
iteration 286, loss 0.62833232
iteration 287, loss 0.62822030
iteration 288, loss 0.62818596
iteration 289, loss 0.62813489
iteration 290, loss 0.62822797
iteration 291, loss 0.62793903
iteration 292, loss 0.62779796
iteration 293, loss 0.62792233
iteration 294, loss 0.62780211
iteration 295, loss 0.62776156
iteration 296, loss 0.62753471
iteration 297, loss 0.62745765
iteration 298, loss 0.62731480
iteration 299, loss 0.62739725
iteration 300, loss 0.62724506
iteration 301, loss 0.62724722
iteration 302, loss 0.62721132
iteration 303, loss 0.62704693
iteration 304, loss 0.62673286
iteration 305, loss 0.62661911
iteration 306, loss 0.62660640
iteration 307, loss 0.62650544
iteration 308, loss 0.62648711
iteration 309, loss 0.62654643
iteration 310, loss 0.62622718
iteration 311, loss 0.62607276
iteration 312, loss 0.62601960
iteration 313, loss 0.62591057
iteration 314, loss 0.62590992
iteration 315, loss 0.62567483
iteration 316, loss 0.62557866
iteration 317, loss 0.62563599
iteration 318, loss 0.62533479
iteration 319, loss 0.62532463
iteration 320, loss 0.62509338
iteration 321, loss 0.62514563
iteration 322, loss 0.62518117
iteration 323, loss 0.62483012
iteration 324, loss 0.62472633
iteration 325, loss 0.62458257
iteration 326, loss 0.62467763
iteration 327, loss 0.62432756
iteration 328, loss 0.62426045
iteration 329, loss 0.62420780
iteration 330, loss 0.62417887
iteration 331, loss 0.62388372
iteration 332, loss 0.62371515
iteration 333, loss 0.62359911
iteration 334, loss 0.62339006
iteration 335, loss 0.62348836
iteration 336, loss 0.62306567
iteration 337, loss 0.62297259
iteration 338, loss 0.62302096
iteration 339, loss 0.62273523
iteration 340, loss 0.62250987
iteration 341, loss 0.62257503
iteration 342, loss 0.62228371
iteration 343, loss 0.62214787
iteration 344, loss 0.62199870
iteration 345, loss 0.62196074
iteration 346, loss 0.62168373
iteration 347, loss 0.62150526
iteration 348, loss 0.62150420
iteration 349, loss 0.62125659
iteration 350, loss 0.62130275
iteration 351, loss 0.62103036
iteration 352, loss 0.62078237
iteration 353, loss 0.62065992
iteration 354, loss 0.62032824
iteration 355, loss 0.62009236
iteration 356, loss 0.62009697
iteration 357, loss 0.62012664
iteration 358, loss 0.61970908
iteration 359, loss 0.61977866
iteration 360, loss 0.61935404
iteration 361, loss 0.61912550
iteration 362, loss 0.61892254
iteration 363, loss 0.61913482
iteration 364, loss 0.61866288
iteration 365, loss 0.61846433
iteration 366, loss 0.61843531
iteration 367, loss 0.61813857
iteration 368, loss 0.61784490
iteration 369, loss 0.61765791
iteration 370, loss 0.61754419
iteration 371, loss 0.61729712
iteration 372, loss 0.61705564
iteration 373, loss 0.61689221
iteration 374, loss 0.61683546
iteration 375, loss 0.61659389
iteration 376, loss 0.61650548
iteration 377, loss 0.61616478
iteration 378, loss 0.61581407
iteration 379, loss 0.61563370
iteration 380, loss 0.61571941
iteration 381, loss 0.61540778
iteration 382, loss 0.61531960
iteration 383, loss 0.61489085
iteration 384, loss 0.61475557
iteration 385, loss 0.61445076
iteration 386, loss 0.61429614
iteration 387, loss 0.61416040
iteration 388, loss 0.61371099
iteration 389, loss 0.61371310
iteration 390, loss 0.61329227
iteration 391, loss 0.61306163
iteration 392, loss 0.61313383
iteration 393, loss 0.61277041
iteration 394, loss 0.61252318
iteration 395, loss 0.61243285
iteration 396, loss 0.61205988
iteration 397, loss 0.61176897
iteration 398, loss 0.61167544
iteration 399, loss 0.61134443
iteration 400, loss 0.61113712
iteration 401, loss 0.61079572
iteration 402, loss 0.61045581
iteration 403, loss 0.61044831
iteration 404, loss 0.61001152
iteration 405, loss 0.60990102
iteration 406, loss 0.60952190
iteration 407, loss 0.60920621
iteration 408, loss 0.60896854
iteration 409, loss 0.60880705
iteration 410, loss 0.60846083
iteration 411, loss 0.60837915
iteration 412, loss 0.60796882
iteration 413, loss 0.60766599
iteration 414, loss 0.60767561
iteration 415, loss 0.60740345
iteration 416, loss 0.60700370
iteration 417, loss 0.60675535
iteration 418, loss 0.60643454
iteration 419, loss 0.60614586
iteration 420, loss 0.60589761
iteration 421, loss 0.60567300
iteration 422, loss 0.60538476
iteration 423, loss 0.60515864
iteration 424, loss 0.60488692
iteration 425, loss 0.60456896
iteration 426, loss 0.60425812
iteration 427, loss 0.60394522
iteration 428, loss 0.60408785
iteration 429, loss 0.60358051
iteration 430, loss 0.60328427
iteration 431, loss 0.60291228
iteration 432, loss 0.60267091
iteration 433, loss 0.60230359
iteration 434, loss 0.60200784
iteration 435, loss 0.60171159
iteration 436, loss 0.60149136
iteration 437, loss 0.60141686
iteration 438, loss 0.60094263
iteration 439, loss 0.60073675
iteration 440, loss 0.60032375
iteration 441, loss 0.59997501
iteration 442, loss 0.60003749
iteration 443, loss 0.59969351
iteration 444, loss 0.59942046
iteration 445, loss 0.59914594
iteration 446, loss 0.59884686
iteration 447, loss 0.59856692
iteration 448, loss 0.59804274
iteration 449, loss 0.59780883
iteration 450, loss 0.59734688
iteration 451, loss 0.59728191
iteration 452, loss 0.59682146
iteration 453, loss 0.59662040
iteration 454, loss 0.59639011
iteration 455, loss 0.59598275
iteration 456, loss 0.59557801
iteration 457, loss 0.59536683
iteration 458, loss 0.59519102
iteration 459, loss 0.59493500
iteration 460, loss 0.59443201
iteration 461, loss 0.59415522
iteration 462, loss 0.59380791
iteration 463, loss 0.59365160
iteration 464, loss 0.59317260
iteration 465, loss 0.59303514
iteration 466, loss 0.59301076
iteration 467, loss 0.59240263
iteration 468, loss 0.59218633
iteration 469, loss 0.59156573
iteration 470, loss 0.59143383
iteration 471, loss 0.59102992
iteration 472, loss 0.59090299
iteration 473, loss 0.59041969
iteration 474, loss 0.59015274
iteration 475, loss 0.59012803
iteration 476, loss 0.58985898
iteration 477, loss 0.58959923
iteration 478, loss 0.58906238
iteration 479, loss 0.58855074
iteration 480, loss 0.58837573
iteration 481, loss 0.58795182
iteration 482, loss 0.58769267
iteration 483, loss 0.58725799
iteration 484, loss 0.58741700
iteration 485, loss 0.58676821
iteration 486, loss 0.58676881
iteration 487, loss 0.58619591
iteration 488, loss 0.58580860
iteration 489, loss 0.58560565
iteration 490, loss 0.58535800
iteration 491, loss 0.58492451
iteration 492, loss 0.58461499
iteration 493, loss 0.58440478
iteration 494, loss 0.58406156
iteration 495, loss 0.58359656
iteration 496, loss 0.58332103
iteration 497, loss 0.58330018
iteration 498, loss 0.58296069
iteration 499, loss 0.58249582
iteration 500, loss 0.58230731
iteration 501, loss 0.58164347
iteration 502, loss 0.58134549
iteration 503, loss 0.58121320
iteration 504, loss 0.58072280
iteration 505, loss 0.58054137
iteration 506, loss 0.58017578
iteration 507, loss 0.57994433
iteration 508, loss 0.57956581
iteration 509, loss 0.57938895
iteration 510, loss 0.57901543
iteration 511, loss 0.57857215
iteration 512, loss 0.57821202
iteration 513, loss 0.57794416
iteration 514, loss 0.57783931
iteration 515, loss 0.57741477
iteration 516, loss 0.57704017
iteration 517, loss 0.57678639
iteration 518, loss 0.57660250
iteration 519, loss 0.57631515
iteration 520, loss 0.57606571
iteration 521, loss 0.57552932
iteration 522, loss 0.57529757
iteration 523, loss 0.57492023
iteration 524, loss 0.57490428
iteration 525, loss 0.57425991
iteration 526, loss 0.57393597
iteration 527, loss 0.57362309
iteration 528, loss 0.57373273
iteration 529, loss 0.57297172
iteration 530, loss 0.57314210
iteration 531, loss 0.57274651
iteration 532, loss 0.57214202
iteration 533, loss 0.57212948
iteration 534, loss 0.57168429
iteration 535, loss 0.57123221
iteration 536, loss 0.57101932
iteration 537, loss 0.57059492
iteration 538, loss 0.57035732
iteration 539, loss 0.57000362
iteration 540, loss 0.56980441
iteration 541, loss 0.56929575
iteration 542, loss 0.56903237
iteration 543, loss 0.56888864
iteration 544, loss 0.56859086
iteration 545, loss 0.56840961
iteration 546, loss 0.56803989
iteration 547, loss 0.56777941
iteration 548, loss 0.56732900
iteration 549, loss 0.56707745
iteration 550, loss 0.56667620
iteration 551, loss 0.56627803
iteration 552, loss 0.56635375
iteration 553, loss 0.56588270
iteration 554, loss 0.56555313
iteration 555, loss 0.56542186
iteration 556, loss 0.56491490
iteration 557, loss 0.56482885
iteration 558, loss 0.56451868
iteration 559, loss 0.56422492
iteration 560, loss 0.56395547
iteration 561, loss 0.56377301
iteration 562, loss 0.56318545
iteration 563, loss 0.56284152
iteration 564, loss 0.56288608
iteration 565, loss 0.56243285
iteration 566, loss 0.56211925
iteration 567, loss 0.56208567
iteration 568, loss 0.56147333
iteration 569, loss 0.56121633
iteration 570, loss 0.56101709
iteration 571, loss 0.56085367
iteration 572, loss 0.56026848
iteration 573, loss 0.56007540
iteration 574, loss 0.55965896
iteration 575, loss 0.55948852
iteration 576, loss 0.55959890
iteration 577, loss 0.55922994
iteration 578, loss 0.55862420
iteration 579, loss 0.55857857
iteration 580, loss 0.55819353
iteration 581, loss 0.55782296
iteration 582, loss 0.55778473
iteration 583, loss 0.55717847
iteration 584, loss 0.55690092
iteration 585, loss 0.55661580
iteration 586, loss 0.55648181
iteration 587, loss 0.55641048
iteration 588, loss 0.55598928
iteration 589, loss 0.55576941
iteration 590, loss 0.55551670
iteration 591, loss 0.55520670
iteration 592, loss 0.55486241
iteration 593, loss 0.55442483
iteration 594, loss 0.55419877
iteration 595, loss 0.55389694
iteration 596, loss 0.55390323
iteration 597, loss 0.55378153
iteration 598, loss 0.55328677
iteration 599, loss 0.55303778
iteration 600, loss 0.55269312
iteration 601, loss 0.55245682
iteration 602, loss 0.55213692
iteration 603, loss 0.55196623
iteration 604, loss 0.55190539
iteration 605, loss 0.55181128
iteration 606, loss 0.55133683
iteration 607, loss 0.55081770
iteration 608, loss 0.55051562
iteration 609, loss 0.55041115
iteration 610, loss 0.55011446
iteration 611, loss 0.54997775
iteration 612, loss 0.54970780
iteration 613, loss 0.54929056
iteration 614, loss 0.54909337
iteration 615, loss 0.54885522
iteration 616, loss 0.54861015
iteration 617, loss 0.54827966
iteration 618, loss 0.54803392
iteration 619, loss 0.54791990
iteration 620, loss 0.54783631
iteration 621, loss 0.54733903
iteration 622, loss 0.54723742
iteration 623, loss 0.54709127
iteration 624, loss 0.54653138
iteration 625, loss 0.54632698
iteration 626, loss 0.54615510
iteration 627, loss 0.54579582
iteration 628, loss 0.54592220
iteration 629, loss 0.54544087
iteration 630, loss 0.54530132
iteration 631, loss 0.54494590
iteration 632, loss 0.54461121
iteration 633, loss 0.54467385
iteration 634, loss 0.54428078
iteration 635, loss 0.54390640
iteration 636, loss 0.54365760
iteration 637, loss 0.54341859
iteration 638, loss 0.54318054
iteration 639, loss 0.54289278
iteration 640, loss 0.54250342
iteration 641, loss 0.54248076
iteration 642, loss 0.54260976
iteration 643, loss 0.54210641
iteration 644, loss 0.54209915
iteration 645, loss 0.54143348
iteration 646, loss 0.54146916
iteration 647, loss 0.54104712
iteration 648, loss 0.54089810
iteration 649, loss 0.54103454
iteration 650, loss 0.54058350
iteration 651, loss 0.54049799
iteration 652, loss 0.53980124
iteration 653, loss 0.53957621
iteration 654, loss 0.53939403
iteration 655, loss 0.53947215
iteration 656, loss 0.53927790
iteration 657, loss 0.53878444
iteration 658, loss 0.53859526
iteration 659, loss 0.53862201
iteration 660, loss 0.53822280
iteration 661, loss 0.53797345
iteration 662, loss 0.53800498
iteration 663, loss 0.53730648
iteration 664, loss 0.53709817
iteration 665, loss 0.53678583
iteration 666, loss 0.53668372
iteration 667, loss 0.53648044
iteration 668, loss 0.53630930
iteration 669, loss 0.53626102
iteration 670, loss 0.53594550
iteration 671, loss 0.53554574
iteration 672, loss 0.53559189
iteration 673, loss 0.53570229
iteration 674, loss 0.53491110
iteration 675, loss 0.53487906
iteration 676, loss 0.53443502
iteration 677, loss 0.53418325
iteration 678, loss 0.53419098
iteration 679, loss 0.53372425
iteration 680, loss 0.53368527
iteration 681, loss 0.53368448
iteration 682, loss 0.53338386
iteration 683, loss 0.53311929
iteration 684, loss 0.53281832
iteration 685, loss 0.53310726
iteration 686, loss 0.53250435
iteration 687, loss 0.53201371
iteration 688, loss 0.53209662
iteration 689, loss 0.53195602
iteration 690, loss 0.53156641
iteration 691, loss 0.53162987
iteration 692, loss 0.53133273
iteration 693, loss 0.53132143
iteration 694, loss 0.53100028
iteration 695, loss 0.53037132
iteration 696, loss 0.53031940
iteration 697, loss 0.52995363
iteration 698, loss 0.53020897
iteration 699, loss 0.52978327
iteration 700, loss 0.52948806
iteration 701, loss 0.52936664
iteration 702, loss 0.52944527
iteration 703, loss 0.52898585
iteration 704, loss 0.52890595
iteration 705, loss 0.52847936
iteration 706, loss 0.52819382
iteration 707, loss 0.52801746
iteration 708, loss 0.52791192
iteration 709, loss 0.52763122
iteration 710, loss 0.52792445
iteration 711, loss 0.52764849
iteration 712, loss 0.52741056
iteration 713, loss 0.52694997
iteration 714, loss 0.52689680
iteration 715, loss 0.52657032
iteration 716, loss 0.52633530
iteration 717, loss 0.52612962
iteration 718, loss 0.52602045
iteration 719, loss 0.52559437
iteration 720, loss 0.52561214
iteration 721, loss 0.52549664
iteration 722, loss 0.52520289
iteration 723, loss 0.52494332
iteration 724, loss 0.52479636
iteration 725, loss 0.52454797
iteration 726, loss 0.52432429
iteration 727, loss 0.52427723
iteration 728, loss 0.52399446
iteration 729, loss 0.52412400
iteration 730, loss 0.52400943
iteration 731, loss 0.52360819
iteration 732, loss 0.52329081
iteration 733, loss 0.52340029
iteration 734, loss 0.52291511
iteration 735, loss 0.52297576
iteration 736, loss 0.52244831
iteration 737, loss 0.52260951
iteration 738, loss 0.52241941
iteration 739, loss 0.52164364
iteration 740, loss 0.52184734
iteration 741, loss 0.52148287
iteration 742, loss 0.52125585
iteration 743, loss 0.52126292
iteration 744, loss 0.52112977
iteration 745, loss 0.52091152
iteration 746, loss 0.52075899
iteration 747, loss 0.52048719
iteration 748, loss 0.52022966
iteration 749, loss 0.52005940
iteration 750, loss 0.51984718
iteration 751, loss 0.51961557
iteration 752, loss 0.51967122
iteration 753, loss 0.51965842
iteration 754, loss 0.51962126
iteration 755, loss 0.51936950
iteration 756, loss 0.51900669
iteration 757, loss 0.51872102
iteration 758, loss 0.51841081
iteration 759, loss 0.51823639
iteration 760, loss 0.51820739
iteration 761, loss 0.51784978
iteration 762, loss 0.51788676
iteration 763, loss 0.51771407
iteration 764, loss 0.51756788
iteration 765, loss 0.51722648
iteration 766, loss 0.51702760
iteration 767, loss 0.51729186
iteration 768, loss 0.51674001
iteration 769, loss 0.51679673
iteration 770, loss 0.51659400
iteration 771, loss 0.51618913
iteration 772, loss 0.51636228
iteration 773, loss 0.51598306
iteration 774, loss 0.51566707
iteration 775, loss 0.51567815
iteration 776, loss 0.51557020
iteration 777, loss 0.51534316
iteration 778, loss 0.51494439
iteration 779, loss 0.51466546
iteration 780, loss 0.51436387
iteration 781, loss 0.51440051
iteration 782, loss 0.51432902
iteration 783, loss 0.51425678
iteration 784, loss 0.51417663
iteration 785, loss 0.51388048
iteration 786, loss 0.51360885
iteration 787, loss 0.51339780
iteration 788, loss 0.51378213
iteration 789, loss 0.51327942
iteration 790, loss 0.51304250
iteration 791, loss 0.51286494
iteration 792, loss 0.51276393
iteration 793, loss 0.51230756
iteration 794, loss 0.51244422
iteration 795, loss 0.51217292
iteration 796, loss 0.51209509
iteration 797, loss 0.51179421
iteration 798, loss 0.51221932
iteration 799, loss 0.51179262
iteration 800, loss 0.51147407
iteration 801, loss 0.51130357
iteration 802, loss 0.51098248
iteration 803, loss 0.51080520
iteration 804, loss 0.51077591
iteration 805, loss 0.51109310
iteration 806, loss 0.51028577
iteration 807, loss 0.51011794
iteration 808, loss 0.51019926
iteration 809, loss 0.50969023
iteration 810, loss 0.50971093
iteration 811, loss 0.50959252
iteration 812, loss 0.50942130
iteration 813, loss 0.50919736
iteration 814, loss 0.50901403
iteration 815, loss 0.50892594
iteration 816, loss 0.50868867
iteration 817, loss 0.50866464
iteration 818, loss 0.50860690
iteration 819, loss 0.50809450
iteration 820, loss 0.50812588
iteration 821, loss 0.50804284
iteration 822, loss 0.50777124
iteration 823, loss 0.50789641
iteration 824, loss 0.50742096
iteration 825, loss 0.50727856
iteration 826, loss 0.50709841
iteration 827, loss 0.50699186
iteration 828, loss 0.50691835
iteration 829, loss 0.50666373
iteration 830, loss 0.50678979
iteration 831, loss 0.50679501
iteration 832, loss 0.50652276
iteration 833, loss 0.50632448
iteration 834, loss 0.50633623
iteration 835, loss 0.50593935
iteration 836, loss 0.50542409
iteration 837, loss 0.50537518
iteration 838, loss 0.50557641
iteration 839, loss 0.50526170
iteration 840, loss 0.50508071
iteration 841, loss 0.50482002
iteration 842, loss 0.50517784
iteration 843, loss 0.50447214
iteration 844, loss 0.50456196
iteration 845, loss 0.50431951
iteration 846, loss 0.50431930
iteration 847, loss 0.50398075
iteration 848, loss 0.50374100
iteration 849, loss 0.50401216
iteration 850, loss 0.50368536
iteration 851, loss 0.50306882
iteration 852, loss 0.50318080
iteration 853, loss 0.50308860
iteration 854, loss 0.50295534
iteration 855, loss 0.50303559
iteration 856, loss 0.50279042
iteration 857, loss 0.50284595
iteration 858, loss 0.50240330
iteration 859, loss 0.50234693
iteration 860, loss 0.50212080
iteration 861, loss 0.50175812
iteration 862, loss 0.50160402
iteration 863, loss 0.50150076
iteration 864, loss 0.50166398
iteration 865, loss 0.50133048
iteration 866, loss 0.50122810
iteration 867, loss 0.50122805
iteration 868, loss 0.50099771
iteration 869, loss 0.50084990
iteration 870, loss 0.50076661
iteration 871, loss 0.50050361
iteration 872, loss 0.50038138
iteration 873, loss 0.50027138
iteration 874, loss 0.49995619
iteration 875, loss 0.50013931
iteration 876, loss 0.49977953
iteration 877, loss 0.49978612
iteration 878, loss 0.49982633
iteration 879, loss 0.49980715
iteration 880, loss 0.49952502
iteration 881, loss 0.49910165
iteration 882, loss 0.49909482
iteration 883, loss 0.49916388
iteration 884, loss 0.49883673
iteration 885, loss 0.49856673
iteration 886, loss 0.49843455
iteration 887, loss 0.49823683
iteration 888, loss 0.49859164
iteration 889, loss 0.49796834
iteration 890, loss 0.49790610
iteration 891, loss 0.49747121
iteration 892, loss 0.49756849
iteration 893, loss 0.49733961
iteration 894, loss 0.49738414
iteration 895, loss 0.49741779
iteration 896, loss 0.49656790
iteration 897, loss 0.49677022
iteration 898, loss 0.49650083
iteration 899, loss 0.49668939
iteration 900, loss 0.49616227
iteration 901, loss 0.49660726
iteration 902, loss 0.49645039
iteration 903, loss 0.49603240
iteration 904, loss 0.49599310
iteration 905, loss 0.49604954
iteration 906, loss 0.49580372
iteration 907, loss 0.49560718
iteration 908, loss 0.49553121
iteration 909, loss 0.49529981
iteration 910, loss 0.49488299
iteration 911, loss 0.49498354
iteration 912, loss 0.49481272
iteration 913, loss 0.49457157
iteration 914, loss 0.49474573
iteration 915, loss 0.49442997
iteration 916, loss 0.49421484
iteration 917, loss 0.49422851
iteration 918, loss 0.49383896
iteration 919, loss 0.49397468
iteration 920, loss 0.49384381
iteration 921, loss 0.49362976
iteration 922, loss 0.49341643
iteration 923, loss 0.49325759
iteration 924, loss 0.49326277
iteration 925, loss 0.49315171
iteration 926, loss 0.49333123
iteration 927, loss 0.49307782
iteration 928, loss 0.49294616
iteration 929, loss 0.49274855
iteration 930, loss 0.49262436
iteration 931, loss 0.49250828
iteration 932, loss 0.49252559
iteration 933, loss 0.49252386
iteration 934, loss 0.49204884
iteration 935, loss 0.49202306
iteration 936, loss 0.49190608
iteration 937, loss 0.49155987
iteration 938, loss 0.49154631
iteration 939, loss 0.49153808
iteration 940, loss 0.49113914
iteration 941, loss 0.49096039
iteration 942, loss 0.49165076
iteration 943, loss 0.49110808
iteration 944, loss 0.49080116
iteration 945, loss 0.49061116
iteration 946, loss 0.49083034
iteration 947, loss 0.49022993
iteration 948, loss 0.49064724
iteration 949, loss 0.49014301
iteration 950, loss 0.49001412
iteration 951, loss 0.48998113
iteration 952, loss 0.48970211
iteration 953, loss 0.48968265
iteration 954, loss 0.48971638
iteration 955, loss 0.48941374
iteration 956, loss 0.48936037
iteration 957, loss 0.48937700
iteration 958, loss 0.48910027
iteration 959, loss 0.48898476
iteration 960, loss 0.48878505
iteration 961, loss 0.48842784
iteration 962, loss 0.48860036
iteration 963, loss 0.48831333
iteration 964, loss 0.48789939
iteration 965, loss 0.48840073
iteration 966, loss 0.48799837
iteration 967, loss 0.48748170
iteration 968, loss 0.48770216
iteration 969, loss 0.48747341
iteration 970, loss 0.48748498
iteration 971, loss 0.48750307
iteration 972, loss 0.48776276
iteration 973, loss 0.48719744
iteration 974, loss 0.48700929
iteration 975, loss 0.48714729
iteration 976, loss 0.48700895
iteration 977, loss 0.48667275
iteration 978, loss 0.48662355
iteration 979, loss 0.48644398
iteration 980, loss 0.48642777
iteration 981, loss 0.48664013
iteration 982, loss 0.48635863
iteration 983, loss 0.48621026
iteration 984, loss 0.48588539
iteration 985, loss 0.48570461
iteration 986, loss 0.48601781
iteration 987, loss 0.48572275
iteration 988, loss 0.48567011
iteration 989, loss 0.48544046
iteration 990, loss 0.48549923
iteration 991, loss 0.48519146
iteration 992, loss 0.48509386
iteration 993, loss 0.48478258
iteration 994, loss 0.48477690
iteration 995, loss 0.48446791
iteration 996, loss 0.48424595
iteration 997, loss 0.48478713
iteration 998, loss 0.48432528
iteration 999, loss 0.48473436
iteration 1000, loss 0.48451340
iteration 1001, loss 0.48437919
iteration 1002, loss 0.48378878
iteration 1003, loss 0.48365643
iteration 1004, loss 0.48323396
iteration 1005, loss 0.48347009
iteration 1006, loss 0.48320304
iteration 1007, loss 0.48293595
iteration 1008, loss 0.48278452
iteration 1009, loss 0.48265156
iteration 1010, loss 0.48264946
iteration 1011, loss 0.48264667
iteration 1012, loss 0.48274500
iteration 1013, loss 0.48263004
iteration 1014, loss 0.48266748
iteration 1015, loss 0.48240877
iteration 1016, loss 0.48243798
iteration 1017, loss 0.48226818
iteration 1018, loss 0.48192083
iteration 1019, loss 0.48165024
iteration 1020, loss 0.48169828
iteration 1021, loss 0.48141275
iteration 1022, loss 0.48158310
iteration 1023, loss 0.48163055
iteration 1024, loss 0.48151757
iteration 1025, loss 0.48143648
iteration 1026, loss 0.48104994
iteration 1027, loss 0.48079107
iteration 1028, loss 0.48074703
iteration 1029, loss 0.48061865
iteration 1030, loss 0.48069682
iteration 1031, loss 0.48047416
iteration 1032, loss 0.48015929
iteration 1033, loss 0.48077946
iteration 1034, loss 0.48032650
iteration 1035, loss 0.48024554
iteration 1036, loss 0.48012993
iteration 1037, loss 0.47968535
iteration 1038, loss 0.47955947
iteration 1039, loss 0.47948876
iteration 1040, loss 0.47971690
iteration 1041, loss 0.47947496
iteration 1042, loss 0.47931078
iteration 1043, loss 0.47941416
iteration 1044, loss 0.47924568
iteration 1045, loss 0.47920454
iteration 1046, loss 0.47892927
iteration 1047, loss 0.47876031
iteration 1048, loss 0.47862452
iteration 1049, loss 0.47825571
iteration 1050, loss 0.47821997
iteration 1051, loss 0.47817444
iteration 1052, loss 0.47820865
iteration 1053, loss 0.47815650
iteration 1054, loss 0.47794683
iteration 1055, loss 0.47802327
iteration 1056, loss 0.47775792
iteration 1057, loss 0.47767787
iteration 1058, loss 0.47738127
iteration 1059, loss 0.47736585
iteration 1060, loss 0.47751106
iteration 1061, loss 0.47717925
iteration 1062, loss 0.47689503
iteration 1063, loss 0.47680531
iteration 1064, loss 0.47673495
iteration 1065, loss 0.47664479
iteration 1066, loss 0.47685166
iteration 1067, loss 0.47653491
iteration 1068, loss 0.47627167
iteration 1069, loss 0.47652603
iteration 1070, loss 0.47601971
iteration 1071, loss 0.47617301
iteration 1072, loss 0.47618999
iteration 1073, loss 0.47582196
iteration 1074, loss 0.47594834
iteration 1075, loss 0.47602959
iteration 1076, loss 0.47572896
iteration 1077, loss 0.47550508
iteration 1078, loss 0.47559373
iteration 1079, loss 0.47539868
iteration 1080, loss 0.47517674
iteration 1081, loss 0.47524391
iteration 1082, loss 0.47511477
iteration 1083, loss 0.47492797
iteration 1084, loss 0.47477175
iteration 1085, loss 0.47450784
iteration 1086, loss 0.47450008
iteration 1087, loss 0.47447091
iteration 1088, loss 0.47466292
iteration 1089, loss 0.47448326
iteration 1090, loss 0.47429008
iteration 1091, loss 0.47345305
iteration 1092, loss 0.47373776
iteration 1093, loss 0.47399211
iteration 1094, loss 0.47376899
iteration 1095, loss 0.47364127
iteration 1096, loss 0.47375999
iteration 1097, loss 0.47323554
iteration 1098, loss 0.47348878
iteration 1099, loss 0.47350426
iteration 1100, loss 0.47300631
iteration 1101, loss 0.47279456
iteration 1102, loss 0.47266613
iteration 1103, loss 0.47270426
iteration 1104, loss 0.47254506
iteration 1105, loss 0.47226602
iteration 1106, loss 0.47215456
iteration 1107, loss 0.47217071
iteration 1108, loss 0.47204346
iteration 1109, loss 0.47205524
iteration 1110, loss 0.47187249
iteration 1111, loss 0.47210715
iteration 1112, loss 0.47191924
iteration 1113, loss 0.47171331
iteration 1114, loss 0.47139349
iteration 1115, loss 0.47126078
iteration 1116, loss 0.47162827
iteration 1117, loss 0.47145508
iteration 1118, loss 0.47116108
iteration 1119, loss 0.47090626
iteration 1120, loss 0.47094798
iteration 1121, loss 0.47094022
iteration 1122, loss 0.47060666
iteration 1123, loss 0.47048725
iteration 1124, loss 0.47063416
iteration 1125, loss 0.47026367
iteration 1126, loss 0.47014542
iteration 1127, loss 0.47001477
iteration 1128, loss 0.47018474
iteration 1129, loss 0.46991336
iteration 1130, loss 0.46978541
iteration 1131, loss 0.46953002
iteration 1132, loss 0.46945086
iteration 1133, loss 0.46925848
iteration 1134, loss 0.46933821
iteration 1135, loss 0.46924545
iteration 1136, loss 0.46913747
iteration 1137, loss 0.46904508
iteration 1138, loss 0.46870087
iteration 1139, loss 0.46870304
iteration 1140, loss 0.46862150
iteration 1141, loss 0.46860586
iteration 1142, loss 0.46821528
iteration 1143, loss 0.46822374
iteration 1144, loss 0.46836503
iteration 1145, loss 0.46851629
iteration 1146, loss 0.46819666
iteration 1147, loss 0.46811001
iteration 1148, loss 0.46777336
iteration 1149, loss 0.46757312
iteration 1150, loss 0.46748544
iteration 1151, loss 0.46727817
iteration 1152, loss 0.46712203
iteration 1153, loss 0.46742037
iteration 1154, loss 0.46701764
iteration 1155, loss 0.46703399
iteration 1156, loss 0.46682248
iteration 1157, loss 0.46674204
iteration 1158, loss 0.46670212
iteration 1159, loss 0.46657401
iteration 1160, loss 0.46622491
iteration 1161, loss 0.46609445
iteration 1162, loss 0.46623135
iteration 1163, loss 0.46599907
iteration 1164, loss 0.46622071
iteration 1165, loss 0.46614574
iteration 1166, loss 0.46605361
iteration 1167, loss 0.46564394
iteration 1168, loss 0.46597228
iteration 1169, loss 0.46571748
iteration 1170, loss 0.46527206
iteration 1171, loss 0.46542823
iteration 1172, loss 0.46527706
iteration 1173, loss 0.46499379
iteration 1174, loss 0.46489286
iteration 1175, loss 0.46464397
iteration 1176, loss 0.46459189
iteration 1177, loss 0.46438391
iteration 1178, loss 0.46462978
iteration 1179, loss 0.46449955
iteration 1180, loss 0.46443217
iteration 1181, loss 0.46427426
iteration 1182, loss 0.46430126
iteration 1183, loss 0.46408651
iteration 1184, loss 0.46379748
iteration 1185, loss 0.46386223
iteration 1186, loss 0.46375789
iteration 1187, loss 0.46365192
iteration 1188, loss 0.46339331
iteration 1189, loss 0.46355993
iteration 1190, loss 0.46311487
iteration 1191, loss 0.46325398
iteration 1192, loss 0.46286339
iteration 1193, loss 0.46305579
iteration 1194, loss 0.46291872
iteration 1195, loss 0.46259070
iteration 1196, loss 0.46262782
iteration 1197, loss 0.46232711
iteration 1198, loss 0.46202051
iteration 1199, loss 0.46161628
iteration 1200, loss 0.46239453
iteration 1201, loss 0.46204250
iteration 1202, loss 0.46181082
iteration 1203, loss 0.46148800
iteration 1204, loss 0.46166713
iteration 1205, loss 0.46142844
iteration 1206, loss 0.46129720
iteration 1207, loss 0.46167119
iteration 1208, loss 0.46130986
iteration 1209, loss 0.46111473
iteration 1210, loss 0.46107941
iteration 1211, loss 0.46101432
iteration 1212, loss 0.46077093
iteration 1213, loss 0.46063816
iteration 1214, loss 0.46017249
iteration 1215, loss 0.46046897
iteration 1216, loss 0.46014892
iteration 1217, loss 0.45992060
iteration 1218, loss 0.46025269
iteration 1219, loss 0.45995345
iteration 1220, loss 0.45965582
iteration 1221, loss 0.45952599
iteration 1222, loss 0.45947697
iteration 1223, loss 0.45939565
iteration 1224, loss 0.45942607
iteration 1225, loss 0.45920352
iteration 1226, loss 0.45910145
iteration 1227, loss 0.45915225
iteration 1228, loss 0.45877446
iteration 1229, loss 0.45871475
iteration 1230, loss 0.45906167
iteration 1231, loss 0.45838927
iteration 1232, loss 0.45838465
iteration 1233, loss 0.45809405
iteration 1234, loss 0.45800093
iteration 1235, loss 0.45791880
iteration 1236, loss 0.45792064
iteration 1237, loss 0.45768463
iteration 1238, loss 0.45762220
iteration 1239, loss 0.45740827
iteration 1240, loss 0.45744009
iteration 1241, loss 0.45727089
iteration 1242, loss 0.45702816
iteration 1243, loss 0.45728474
iteration 1244, loss 0.45722662
iteration 1245, loss 0.45704011
iteration 1246, loss 0.45671323
iteration 1247, loss 0.45660611
iteration 1248, loss 0.45659572
iteration 1249, loss 0.45610980
iteration 1250, loss 0.45605114
iteration 1251, loss 0.45618043
iteration 1252, loss 0.45600754
iteration 1253, loss 0.45604533
iteration 1254, loss 0.45587793
iteration 1255, loss 0.45575897
iteration 1256, loss 0.45556967
iteration 1257, loss 0.45568366
iteration 1258, loss 0.45525925
iteration 1259, loss 0.45526173
iteration 1260, loss 0.45516583
iteration 1261, loss 0.45493583
iteration 1262, loss 0.45468453
iteration 1263, loss 0.45474226
iteration 1264, loss 0.45467214
iteration 1265, loss 0.45448685
iteration 1266, loss 0.45462736
iteration 1267, loss 0.45459273
iteration 1268, loss 0.45466695
iteration 1269, loss 0.45412507
iteration 1270, loss 0.45397278
iteration 1271, loss 0.45374158
iteration 1272, loss 0.45386695
iteration 1273, loss 0.45379273
iteration 1274, loss 0.45378069
iteration 1275, loss 0.45342626
iteration 1276, loss 0.45332003
iteration 1277, loss 0.45328774
iteration 1278, loss 0.45320304
iteration 1279, loss 0.45293382
iteration 1280, loss 0.45279860
iteration 1281, loss 0.45259583
iteration 1282, loss 0.45261764
iteration 1283, loss 0.45243499
iteration 1284, loss 0.45227144
iteration 1285, loss 0.45229002
iteration 1286, loss 0.45217440
iteration 1287, loss 0.45214654
iteration 1288, loss 0.45208585
iteration 1289, loss 0.45196996
iteration 1290, loss 0.45160617
iteration 1291, loss 0.45166051
iteration 1292, loss 0.45137630
iteration 1293, loss 0.45127815
iteration 1294, loss 0.45111833
iteration 1295, loss 0.45058745
iteration 1296, loss 0.45058523
iteration 1297, loss 0.45088218
iteration 1298, loss 0.45063199
iteration 1299, loss 0.45074943
iteration 1300, loss 0.45032060
iteration 1301, loss 0.45031764
iteration 1302, loss 0.45014821
iteration 1303, loss 0.45011722
iteration 1304, loss 0.44985216
iteration 1305, loss 0.44961082
iteration 1306, loss 0.44987425
iteration 1307, loss 0.44972364
iteration 1308, loss 0.44933558
iteration 1309, loss 0.44952373
iteration 1310, loss 0.44965668
iteration 1311, loss 0.44914436
iteration 1312, loss 0.44886065
iteration 1313, loss 0.44871122
iteration 1314, loss 0.44871867
iteration 1315, loss 0.44839688
iteration 1316, loss 0.44829698
iteration 1317, loss 0.44847302
iteration 1318, loss 0.44830894
iteration 1319, loss 0.44810772
iteration 1320, loss 0.44824205
iteration 1321, loss 0.44835682
iteration 1322, loss 0.44790942
iteration 1323, loss 0.44778430
iteration 1324, loss 0.44792088
iteration 1325, loss 0.44776374
iteration 1326, loss 0.44754055
iteration 1327, loss 0.44733783
iteration 1328, loss 0.44713308
iteration 1329, loss 0.44679864
iteration 1330, loss 0.44679186
iteration 1331, loss 0.44663566
iteration 1332, loss 0.44672641
iteration 1333, loss 0.44679382
iteration 1334, loss 0.44638468
iteration 1335, loss 0.44639647
iteration 1336, loss 0.44603383
iteration 1337, loss 0.44590465
iteration 1338, loss 0.44619343
iteration 1339, loss 0.44609603
iteration 1340, loss 0.44585145
iteration 1341, loss 0.44543008
iteration 1342, loss 0.44534464
iteration 1343, loss 0.44529533
iteration 1344, loss 0.44512933
iteration 1345, loss 0.44525973
iteration 1346, loss 0.44508168
iteration 1347, loss 0.44483601
iteration 1348, loss 0.44481722
iteration 1349, loss 0.44469905
iteration 1350, loss 0.44452693
iteration 1351, loss 0.44443361
iteration 1352, loss 0.44476624
iteration 1353, loss 0.44463793
iteration 1354, loss 0.44423196
iteration 1355, loss 0.44420570
iteration 1356, loss 0.44397140
iteration 1357, loss 0.44390569
iteration 1358, loss 0.44399223
iteration 1359, loss 0.44356102
iteration 1360, loss 0.44339980
iteration 1361, loss 0.44336992
iteration 1362, loss 0.44307385
iteration 1363, loss 0.44326633
iteration 1364, loss 0.44294873
iteration 1365, loss 0.44296506
iteration 1366, loss 0.44274559
iteration 1367, loss 0.44249759
iteration 1368, loss 0.44264746
iteration 1369, loss 0.44265140
iteration 1370, loss 0.44229951
iteration 1371, loss 0.44204983
iteration 1372, loss 0.44204919
iteration 1373, loss 0.44204148
iteration 1374, loss 0.44184549
iteration 1375, loss 0.44208145
iteration 1376, loss 0.44172023
iteration 1377, loss 0.44159858
iteration 1378, loss 0.44183673
iteration 1379, loss 0.44136996
iteration 1380, loss 0.44152440
iteration 1381, loss 0.44133808
iteration 1382, loss 0.44113372
iteration 1383, loss 0.44098127
iteration 1384, loss 0.44083624
iteration 1385, loss 0.44062354
iteration 1386, loss 0.44046574
iteration 1387, loss 0.44045107
iteration 1388, loss 0.44046331
iteration 1389, loss 0.44022305
iteration 1390, loss 0.44009285
iteration 1391, loss 0.44001735
iteration 1392, loss 0.43983986
iteration 1393, loss 0.43952702
iteration 1394, loss 0.43934142
iteration 1395, loss 0.43904966
iteration 1396, loss 0.43904578
iteration 1397, loss 0.43928076
iteration 1398, loss 0.43891597
iteration 1399, loss 0.43897497
iteration 1400, loss 0.43910735
iteration 1401, loss 0.43886998
iteration 1402, loss 0.43883027
iteration 1403, loss 0.43862882
iteration 1404, loss 0.43836409
iteration 1405, loss 0.43813668
iteration 1406, loss 0.43820982
iteration 1407, loss 0.43842448
iteration 1408, loss 0.43807973
iteration 1409, loss 0.43808865
iteration 1410, loss 0.43779117
iteration 1411, loss 0.43743511
iteration 1412, loss 0.43725794
iteration 1413, loss 0.43747149
iteration 1414, loss 0.43732065
iteration 1415, loss 0.43744040
iteration 1416, loss 0.43717200
iteration 1417, loss 0.43713392
iteration 1418, loss 0.43708387
iteration 1419, loss 0.43677771
iteration 1420, loss 0.43651293
iteration 1421, loss 0.43646890
iteration 1422, loss 0.43668424
iteration 1423, loss 0.43653051
iteration 1424, loss 0.43622615
iteration 1425, loss 0.43604077
iteration 1426, loss 0.43623010
iteration 1427, loss 0.43605678
iteration 1428, loss 0.43604291
iteration 1429, loss 0.43549445
iteration 1430, loss 0.43542072
iteration 1431, loss 0.43557141
iteration 1432, loss 0.43544619
iteration 1433, loss 0.43521089
iteration 1434, loss 0.43494347
iteration 1435, loss 0.43483187
iteration 1436, loss 0.43492848
iteration 1437, loss 0.43478540
iteration 1438, loss 0.43460007
iteration 1439, loss 0.43477725
iteration 1440, loss 0.43462977
iteration 1441, loss 0.43439301
iteration 1442, loss 0.43406902
iteration 1443, loss 0.43408804
iteration 1444, loss 0.43384855
iteration 1445, loss 0.43399391
iteration 1446, loss 0.43368032
iteration 1447, loss 0.43389697
iteration 1448, loss 0.43380931
iteration 1449, loss 0.43361855
iteration 1450, loss 0.43333679
iteration 1451, loss 0.43352879
iteration 1452, loss 0.43316633
iteration 1453, loss 0.43348839
iteration 1454, loss 0.43324285
iteration 1455, loss 0.43313071
iteration 1456, loss 0.43276457
iteration 1457, loss 0.43244085
iteration 1458, loss 0.43249813
iteration 1459, loss 0.43224338
iteration 1460, loss 0.43212644
iteration 1461, loss 0.43202940
iteration 1462, loss 0.43203727
iteration 1463, loss 0.43215372
iteration 1464, loss 0.43203152
iteration 1465, loss 0.43204339
iteration 1466, loss 0.43196840
iteration 1467, loss 0.43172513
iteration 1468, loss 0.43136263
iteration 1469, loss 0.43163068
iteration 1470, loss 0.43152582
iteration 1471, loss 0.43126948
iteration 1472, loss 0.43122614
iteration 1473, loss 0.43128146
iteration 1474, loss 0.43101917
iteration 1475, loss 0.43076242
iteration 1476, loss 0.43054581
iteration 1477, loss 0.43047130
iteration 1478, loss 0.43062730
iteration 1479, loss 0.43042996
iteration 1480, loss 0.43020905
iteration 1481, loss 0.42995110
iteration 1482, loss 0.43000565
iteration 1483, loss 0.43001399
iteration 1484, loss 0.42972151
iteration 1485, loss 0.42962728
iteration 1486, loss 0.42962004
iteration 1487, loss 0.42968055
iteration 1488, loss 0.42947173
iteration 1489, loss 0.42948902
iteration 1490, loss 0.42929917
iteration 1491, loss 0.42913087
iteration 1492, loss 0.42932801
iteration 1493, loss 0.42901189
iteration 1494, loss 0.42879893
iteration 1495, loss 0.42876186
iteration 1496, loss 0.42851333
iteration 1497, loss 0.42855249
iteration 1498, loss 0.42837189
iteration 1499, loss 0.42821072
iteration 1500, loss 0.42809666
iteration 1501, loss 0.42818663
iteration 1502, loss 0.42785451
iteration 1503, loss 0.42793121
iteration 1504, loss 0.42789179
iteration 1505, loss 0.42769688
iteration 1506, loss 0.42752928
iteration 1507, loss 0.42758451
iteration 1508, loss 0.42745014
iteration 1509, loss 0.42745010
iteration 1510, loss 0.42725037
iteration 1511, loss 0.42717517
iteration 1512, loss 0.42686227
iteration 1513, loss 0.42704506
iteration 1514, loss 0.42692524
iteration 1515, loss 0.42694184
iteration 1516, loss 0.42664483
iteration 1517, loss 0.42674111
iteration 1518, loss 0.42636048
iteration 1519, loss 0.42615415
iteration 1520, loss 0.42614366
iteration 1521, loss 0.42614021
iteration 1522, loss 0.42608370
iteration 1523, loss 0.42594511
iteration 1524, loss 0.42595150
iteration 1525, loss 0.42586115
iteration 1526, loss 0.42583386
iteration 1527, loss 0.42549602
iteration 1528, loss 0.42527829
iteration 1529, loss 0.42533499
iteration 1530, loss 0.42525765
iteration 1531, loss 0.42514404
iteration 1532, loss 0.42505326
iteration 1533, loss 0.42514691
iteration 1534, loss 0.42481964
iteration 1535, loss 0.42463882
iteration 1536, loss 0.42469371
iteration 1537, loss 0.42462635
iteration 1538, loss 0.42444332
iteration 1539, loss 0.42426006
iteration 1540, loss 0.42398937
iteration 1541, loss 0.42407868
iteration 1542, loss 0.42407138
iteration 1543, loss 0.42416856
iteration 1544, loss 0.42404756
iteration 1545, loss 0.42382636
iteration 1546, loss 0.42355400
iteration 1547, loss 0.42358743
iteration 1548, loss 0.42342071
iteration 1549, loss 0.42370253
iteration 1550, loss 0.42332830
iteration 1551, loss 0.42312202
iteration 1552, loss 0.42316713
iteration 1553, loss 0.42301354
iteration 1554, loss 0.42295536
iteration 1555, loss 0.42301183
iteration 1556, loss 0.42290791
iteration 1557, loss 0.42270038
iteration 1558, loss 0.42254993
iteration 1559, loss 0.42261775
iteration 1560, loss 0.42250665
iteration 1561, loss 0.42215962
iteration 1562, loss 0.42201147
iteration 1563, loss 0.42211702
iteration 1564, loss 0.42215613
iteration 1565, loss 0.42207771
iteration 1566, loss 0.42200492
iteration 1567, loss 0.42193542
iteration 1568, loss 0.42159287
iteration 1569, loss 0.42141075
iteration 1570, loss 0.42135375
iteration 1571, loss 0.42127948
iteration 1572, loss 0.42146438
iteration 1573, loss 0.42110735
iteration 1574, loss 0.42116493
iteration 1575, loss 0.42111734
iteration 1576, loss 0.42103881
iteration 1577, loss 0.42103712
iteration 1578, loss 0.42083804
iteration 1579, loss 0.42092622
iteration 1580, loss 0.42076667
iteration 1581, loss 0.42054171
iteration 1582, loss 0.42037321
iteration 1583, loss 0.42034174
iteration 1584, loss 0.42020533
iteration 1585, loss 0.42008674
iteration 1586, loss 0.42006601
iteration 1587, loss 0.41995243
iteration 1588, loss 0.41978819
iteration 1589, loss 0.41957893
iteration 1590, loss 0.41945830
iteration 1591, loss 0.41944813
iteration 1592, loss 0.41967169
iteration 1593, loss 0.41944530
iteration 1594, loss 0.41923269
iteration 1595, loss 0.41920602
iteration 1596, loss 0.41933534
iteration 1597, loss 0.41928902
iteration 1598, loss 0.41905723
iteration 1599, loss 0.41876471
iteration 1600, loss 0.41873322
iteration 1601, loss 0.41862843
iteration 1602, loss 0.41859559
iteration 1603, loss 0.41846739
iteration 1604, loss 0.41862250
iteration 1605, loss 0.41835007
iteration 1606, loss 0.41809383
iteration 1607, loss 0.41815361
iteration 1608, loss 0.41798711
iteration 1609, loss 0.41794470
iteration 1610, loss 0.41785751
iteration 1611, loss 0.41780539
iteration 1612, loss 0.41787500
iteration 1613, loss 0.41769642
iteration 1614, loss 0.41744594
iteration 1615, loss 0.41746137
iteration 1616, loss 0.41745631
iteration 1617, loss 0.41725985
iteration 1618, loss 0.41722905
iteration 1619, loss 0.41714298
iteration 1620, loss 0.41715811
iteration 1621, loss 0.41722744
iteration 1622, loss 0.41703138
iteration 1623, loss 0.41682268
iteration 1624, loss 0.41692703
iteration 1625, loss 0.41687953
iteration 1626, loss 0.41656746
iteration 1627, loss 0.41637523
iteration 1628, loss 0.41623091
iteration 1629, loss 0.41627145
iteration 1630, loss 0.41638616
iteration 1631, loss 0.41637189
iteration 1632, loss 0.41607878
iteration 1633, loss 0.41587609
iteration 1634, loss 0.41582724
iteration 1635, loss 0.41575977
iteration 1636, loss 0.41575995
iteration 1637, loss 0.41554978
iteration 1638, loss 0.41579077
iteration 1639, loss 0.41544244
iteration 1640, loss 0.41541692
iteration 1641, loss 0.41551953
iteration 1642, loss 0.41514328
iteration 1643, loss 0.41518968
iteration 1644, loss 0.41510736
iteration 1645, loss 0.41529328
iteration 1646, loss 0.41499310
iteration 1647, loss 0.41501613
iteration 1648, loss 0.41471566
iteration 1649, loss 0.41467889
iteration 1650, loss 0.41441860
iteration 1651, loss 0.41436273
iteration 1652, loss 0.41432936
iteration 1653, loss 0.41436000
iteration 1654, loss 0.41430563
iteration 1655, loss 0.41425996
iteration 1656, loss 0.41426693
iteration 1657, loss 0.41397365
iteration 1658, loss 0.41403184
iteration 1659, loss 0.41380834
iteration 1660, loss 0.41367732
iteration 1661, loss 0.41358693
iteration 1662, loss 0.41352624
iteration 1663, loss 0.41360785
iteration 1664, loss 0.41343989
iteration 1665, loss 0.41331934
iteration 1666, loss 0.41323819
iteration 1667, loss 0.41310285
iteration 1668, loss 0.41313524
iteration 1669, loss 0.41309956
iteration 1670, loss 0.41306952
iteration 1671, loss 0.41296524
iteration 1672, loss 0.41298094
iteration 1673, loss 0.41279720
iteration 1674, loss 0.41278004
iteration 1675, loss 0.41271610
iteration 1676, loss 0.41267603
iteration 1677, loss 0.41257267
iteration 1678, loss 0.41238584
iteration 1679, loss 0.41231406
iteration 1680, loss 0.41215148
iteration 1681, loss 0.41209282
iteration 1682, loss 0.41197063
iteration 1683, loss 0.41195618
iteration 1684, loss 0.41193007
iteration 1685, loss 0.41193540
iteration 1686, loss 0.41164794
iteration 1687, loss 0.41137297
iteration 1688, loss 0.41139947
iteration 1689, loss 0.41153510
iteration 1690, loss 0.41138423
iteration 1691, loss 0.41128381
iteration 1692, loss 0.41118167
iteration 1693, loss 0.41116167
iteration 1694, loss 0.41101776
iteration 1695, loss 0.41108767
iteration 1696, loss 0.41087626
iteration 1697, loss 0.41087807
iteration 1698, loss 0.41072885
iteration 1699, loss 0.41080505
iteration 1700, loss 0.41055770
iteration 1701, loss 0.41058200
iteration 1702, loss 0.41065590
iteration 1703, loss 0.41061653
iteration 1704, loss 0.41045821
iteration 1705, loss 0.41039686
iteration 1706, loss 0.41023057
iteration 1707, loss 0.41008778
iteration 1708, loss 0.40997845
iteration 1709, loss 0.41005975
iteration 1710, loss 0.40998348
iteration 1711, loss 0.40989489
iteration 1712, loss 0.40984806
iteration 1713, loss 0.40973461
iteration 1714, loss 0.40957319
iteration 1715, loss 0.40937535
iteration 1716, loss 0.40930628
iteration 1717, loss 0.40942408
iteration 1718, loss 0.40929688
iteration 1719, loss 0.40931122
iteration 1720, loss 0.40933172
iteration 1721, loss 0.40921945
iteration 1722, loss 0.40898002
iteration 1723, loss 0.40908084
iteration 1724, loss 0.40892486
iteration 1725, loss 0.40881824
iteration 1726, loss 0.40873705
iteration 1727, loss 0.40855234
iteration 1728, loss 0.40866150
iteration 1729, loss 0.40849050
iteration 1730, loss 0.40844280
iteration 1731, loss 0.40821061
iteration 1732, loss 0.40814628
iteration 1733, loss 0.40792404
iteration 1734, loss 0.40782091
iteration 1735, loss 0.40829521
iteration 1736, loss 0.40802547
iteration 1737, loss 0.40781577
iteration 1738, loss 0.40768789
iteration 1739, loss 0.40782514
iteration 1740, loss 0.40768051
iteration 1741, loss 0.40786838
iteration 1742, loss 0.40759324
iteration 1743, loss 0.40740311
iteration 1744, loss 0.40740357
iteration 1745, loss 0.40749520
iteration 1746, loss 0.40733171
iteration 1747, loss 0.40703474
iteration 1748, loss 0.40704928
iteration 1749, loss 0.40693218
iteration 1750, loss 0.40695503
iteration 1751, loss 0.40697064
iteration 1752, loss 0.40682627
iteration 1753, loss 0.40660646
iteration 1754, loss 0.40651952
iteration 1755, loss 0.40642412
iteration 1756, loss 0.40637267
iteration 1757, loss 0.40657013
iteration 1758, loss 0.40660203
iteration 1759, loss 0.40634702
iteration 1760, loss 0.40643507
iteration 1761, loss 0.40653417
iteration 1762, loss 0.40635752
iteration 1763, loss 0.40633201
iteration 1764, loss 0.40626849
iteration 1765, loss 0.40599027
iteration 1766, loss 0.40576883
iteration 1767, loss 0.40565230
iteration 1768, loss 0.40548519
iteration 1769, loss 0.40592845
iteration 1770, loss 0.40579583
iteration 1771, loss 0.40566864
iteration 1772, loss 0.40553254
iteration 1773, loss 0.40541006
iteration 1774, loss 0.40540846
iteration 1775, loss 0.40512631
iteration 1776, loss 0.40527757
iteration 1777, loss 0.40511306
iteration 1778, loss 0.40499345
iteration 1779, loss 0.40516672
iteration 1780, loss 0.40487545
iteration 1781, loss 0.40471804
iteration 1782, loss 0.40472366
iteration 1783, loss 0.40474678
iteration 1784, loss 0.40460424
iteration 1785, loss 0.40463969
iteration 1786, loss 0.40436691
iteration 1787, loss 0.40431604
iteration 1788, loss 0.40442056
iteration 1789, loss 0.40426833
iteration 1790, loss 0.40424642
iteration 1791, loss 0.40407743
iteration 1792, loss 0.40414266
iteration 1793, loss 0.40413105
iteration 1794, loss 0.40403052
iteration 1795, loss 0.40386841
iteration 1796, loss 0.40369183
iteration 1797, loss 0.40363894
iteration 1798, loss 0.40360467
iteration 1799, loss 0.40358716
iteration 1800, loss 0.40371772
iteration 1801, loss 0.40364670
iteration 1802, loss 0.40344654
iteration 1803, loss 0.40341589
iteration 1804, loss 0.40333801
iteration 1805, loss 0.40323534
iteration 1806, loss 0.40308813
iteration 1807, loss 0.40300831
iteration 1808, loss 0.40313850
iteration 1809, loss 0.40285601
iteration 1810, loss 0.40275118
iteration 1811, loss 0.40265035
iteration 1812, loss 0.40271332
iteration 1813, loss 0.40264826
iteration 1814, loss 0.40270919
iteration 1815, loss 0.40277393
iteration 1816, loss 0.40263117
iteration 1817, loss 0.40262396
iteration 1818, loss 0.40251469
iteration 1819, loss 0.40242438
iteration 1820, loss 0.40224872
iteration 1821, loss 0.40234676
iteration 1822, loss 0.40207919
iteration 1823, loss 0.40201112
iteration 1824, loss 0.40211241
iteration 1825, loss 0.40185270
iteration 1826, loss 0.40235221
iteration 1827, loss 0.40187398
iteration 1828, loss 0.40170265
iteration 1829, loss 0.40180557
iteration 1830, loss 0.40164374
iteration 1831, loss 0.40161986
iteration 1832, loss 0.40147581
iteration 1833, loss 0.40132689
iteration 1834, loss 0.40128958
iteration 1835, loss 0.40116273
iteration 1836, loss 0.40106972
iteration 1837, loss 0.40114826
iteration 1838, loss 0.40119600
iteration 1839, loss 0.40114793
iteration 1840, loss 0.40104487
iteration 1841, loss 0.40086479
iteration 1842, loss 0.40066610
iteration 1843, loss 0.40070713
iteration 1844, loss 0.40073677
iteration 1845, loss 0.40084292
iteration 1846, loss 0.40073435
iteration 1847, loss 0.40057129
iteration 1848, loss 0.40067061
iteration 1849, loss 0.40055181
iteration 1850, loss 0.40050274
iteration 1851, loss 0.40043670
iteration 1852, loss 0.40042052
iteration 1853, loss 0.40028718
iteration 1854, loss 0.40011722
iteration 1855, loss 0.40009458
iteration 1856, loss 0.40004181
iteration 1857, loss 0.39999987
iteration 1858, loss 0.39985874
iteration 1859, loss 0.39981682
iteration 1860, loss 0.39969177
iteration 1861, loss 0.39966493
iteration 1862, loss 0.39950169
iteration 1863, loss 0.39964463
iteration 1864, loss 0.39940104
iteration 1865, loss 0.39949127
iteration 1866, loss 0.39944263
iteration 1867, loss 0.39931885
iteration 1868, loss 0.39925221
iteration 1869, loss 0.39928554
iteration 1870, loss 0.39904072
iteration 1871, loss 0.39893339
iteration 1872, loss 0.39896329
iteration 1873, loss 0.39899764
iteration 1874, loss 0.39900258
iteration 1875, loss 0.39874648
iteration 1876, loss 0.39859980
iteration 1877, loss 0.39872299
iteration 1878, loss 0.39877211
iteration 1879, loss 0.39851052
iteration 1880, loss 0.39844532
iteration 1881, loss 0.39853622
iteration 1882, loss 0.39843328
iteration 1883, loss 0.39838406
iteration 1884, loss 0.39842648
iteration 1885, loss 0.39830284
iteration 1886, loss 0.39824432
iteration 1887, loss 0.39816892
iteration 1888, loss 0.39806821
iteration 1889, loss 0.39801274
iteration 1890, loss 0.39790214
iteration 1891, loss 0.39797482
iteration 1892, loss 0.39791902
iteration 1893, loss 0.39793879
iteration 1894, loss 0.39763596
iteration 1895, loss 0.39755713
iteration 1896, loss 0.39758215
iteration 1897, loss 0.39770873
iteration 1898, loss 0.39758424
iteration 1899, loss 0.39752378
iteration 1900, loss 0.39731922
iteration 1901, loss 0.39721005
iteration 1902, loss 0.39726898
iteration 1903, loss 0.39735783
iteration 1904, loss 0.39719320
iteration 1905, loss 0.39703336
iteration 1906, loss 0.39705822
iteration 1907, loss 0.39691632
iteration 1908, loss 0.39696392
iteration 1909, loss 0.39687107
iteration 1910, loss 0.39675115
iteration 1911, loss 0.39669177
iteration 1912, loss 0.39661502
iteration 1913, loss 0.39652892
iteration 1914, loss 0.39645417
iteration 1915, loss 0.39637341
iteration 1916, loss 0.39640639
iteration 1917, loss 0.39650104
iteration 1918, loss 0.39632098
iteration 1919, loss 0.39634660
iteration 1920, loss 0.39626508
iteration 1921, loss 0.39630558
iteration 1922, loss 0.39615347
iteration 1923, loss 0.39618533
iteration 1924, loss 0.39609574
iteration 1925, loss 0.39600873
iteration 1926, loss 0.39588065
iteration 1927, loss 0.39568979
iteration 1928, loss 0.39569683
iteration 1929, loss 0.39565357
iteration 1930, loss 0.39559431
iteration 1931, loss 0.39555835
iteration 1932, loss 0.39552682
iteration 1933, loss 0.39545888
iteration 1934, loss 0.39528042
iteration 1935, loss 0.39530062
iteration 1936, loss 0.39519043
iteration 1937, loss 0.39547154
iteration 1938, loss 0.39531114
iteration 1939, loss 0.39516519
iteration 1940, loss 0.39512748
iteration 1941, loss 0.39497379
iteration 1942, loss 0.39486167
iteration 1943, loss 0.39486118
iteration 1944, loss 0.39475552
iteration 1945, loss 0.39474440
iteration 1946, loss 0.39479367
iteration 1947, loss 0.39476367
iteration 1948, loss 0.39474457
iteration 1949, loss 0.39478370
iteration 1950, loss 0.39472113
iteration 1951, loss 0.39462933
iteration 1952, loss 0.39446192
iteration 1953, loss 0.39438116
iteration 1954, loss 0.39422497
iteration 1955, loss 0.39440182
iteration 1956, loss 0.39413541
iteration 1957, loss 0.39417829
iteration 1958, loss 0.39413173
iteration 1959, loss 0.39408979
iteration 1960, loss 0.39402283
iteration 1961, loss 0.39400921
iteration 1962, loss 0.39389982
iteration 1963, loss 0.39393401
iteration 1964, loss 0.39381100
iteration 1965, loss 0.39373133
iteration 1966, loss 0.39372919
iteration 1967, loss 0.39364320
iteration 1968, loss 0.39369360
iteration 1969, loss 0.39366392
iteration 1970, loss 0.39353588
iteration 1971, loss 0.39354889
iteration 1972, loss 0.39342891
iteration 1973, loss 0.39340608
iteration 1974, loss 0.39333375
iteration 1975, loss 0.39313923
iteration 1976, loss 0.39300039
iteration 1977, loss 0.39297239
iteration 1978, loss 0.39300811
iteration 1979, loss 0.39299326
iteration 1980, loss 0.39286194
iteration 1981, loss 0.39289389
iteration 1982, loss 0.39288724
iteration 1983, loss 0.39276156
iteration 1984, loss 0.39268890
iteration 1985, loss 0.39258280
iteration 1986, loss 0.39266487
iteration 1987, loss 0.39252969
iteration 1988, loss 0.39246514
iteration 1989, loss 0.39246194
iteration 1990, loss 0.39232805
iteration 1991, loss 0.39234178
iteration 1992, loss 0.39211373
iteration 1993, loss 0.39213629
iteration 1994, loss 0.39200442
iteration 1995, loss 0.39211094
iteration 1996, loss 0.39215831
iteration 1997, loss 0.39202586
iteration 1998, loss 0.39218483
iteration 1999, loss 0.39200951
iteration 2000, loss 0.39199986
iteration 3000, loss 0.35768142
iteration 4000, loss 0.34192008
iteration 5000, loss 0.33412721
iteration 6000, loss 0.32961076
iteration 7000, loss 0.32670947
iteration 8000, loss 0.32467983
iteration 9000, loss 0.32318558
iteration 10000, loss 0.32203926
iteration 11000, loss 0.32112353
iteration 12000, loss 0.32038505
iteration 13000, loss 0.31976506
iteration 14000, loss 0.31924594
iteration 15000, loss 0.31880247
iteration 16000, loss 0.31841932
iteration 17000, loss 0.31808413
iteration 18000, loss 0.31778829
iteration 19000, loss 0.31752720
iteration 20000, loss 0.31729272
iteration 21000, loss 0.31708350
iteration 22000, loss 0.31689452
iteration 23000, loss 0.31672255
iteration 24000, loss 0.31656516
iteration 25000, loss 0.31642179
iteration 26000, loss 0.31628986
iteration 27000, loss 0.31616907
iteration 28000, loss 0.31605678
iteration 29000, loss 0.31595343
iteration 30000, loss 0.31585667
iteration 31000, loss 0.31576636
iteration 32000, loss 0.31568221
iteration 33000, loss 0.31560360
iteration 34000, loss 0.31553018
iteration 35000, loss 0.31546043
iteration 36000, loss 0.31539535
iteration 37000, loss 0.31533399
iteration 38000, loss 0.31527580
iteration 39000, loss 0.31522069
iteration 40000, loss 0.31516852
iteration 41000, loss 0.31511902
iteration 42000, loss 0.31507224
iteration 43000, loss 0.31502740
iteration 44000, loss 0.31498480
iteration 45000, loss 0.31494423
iteration 46000, loss 0.31490569
iteration 47000, loss 0.31486857
iteration 48000, loss 0.31483299
iteration 49000, loss 0.31479930
iteration 50000, loss 0.31476690
iteration 51000, loss 0.31473566
iteration 52000, loss 0.31470579
iteration 53000, loss 0.31467704
iteration 54000, loss 0.31464936
iteration 55000, loss 0.31462295
iteration 56000, loss 0.31459741
iteration 57000, loss 0.31457265
iteration 58000, loss 0.31454900
iteration 59000, loss 0.31452603
iteration 60000, loss 0.31450405
iteration 61000, loss 0.31448259
iteration 62000, loss 0.31446195
iteration 63000, loss 0.31444206
iteration 64000, loss 0.31442283
iteration 65000, loss 0.31440404
iteration 66000, loss 0.31438598
iteration 67000, loss 0.31436844
iteration 68000, loss 0.31435139
iteration 69000, loss 0.31433487
iteration 70000, loss 0.31431885
iteration 71000, loss 0.31430335
iteration 72000, loss 0.31428827
iteration 73000, loss 0.31427358
iteration 74000, loss 0.31425938
iteration 75000, loss 0.31424549
iteration 76000, loss 0.31423200
iteration 77000, loss 0.31421883
iteration 78000, loss 0.31420605
iteration 79000, loss 0.31419359
iteration 80000, loss 0.31418144
iteration 81000, loss 0.31416964
iteration 82000, loss 0.31415815
iteration 83000, loss 0.31414691
iteration 84000, loss 0.31413596
iteration 85000, loss 0.31412531
iteration 86000, loss 0.31411478
iteration 87000, loss 0.31410467
iteration 88000, loss 0.31409468
iteration 89000, loss 0.31408500
iteration 90000, loss 0.31407548
iteration 91000, loss 0.31406625
iteration 92000, loss 0.31405717
iteration 93000, loss 0.31404830
iteration 94000, loss 0.31403964
iteration 95000, loss 0.31403116
iteration 96000, loss 0.31402278
iteration 97000, loss 0.31401468
iteration 98000, loss 0.31400670
iteration 99000, loss 0.31399891
