#params: learningRate 0.010, momentum 0.500, numIterations 100000, printEvery 1000, printFirst 2000
iteration 0, loss 0.47672484
iteration 1, loss 0.48611650
iteration 2, loss 0.49512999
iteration 3, loss 0.50386022
iteration 4, loss 0.51186926
iteration 5, loss 0.51941424
iteration 6, loss 0.52650866
iteration 7, loss 0.53335752
iteration 8, loss 0.53946810
iteration 9, loss 0.54527991
iteration 10, loss 0.55065516
iteration 11, loss 0.55572091
iteration 12, loss 0.56067923
iteration 13, loss 0.56495770
iteration 14, loss 0.56897935
iteration 15, loss 0.57282033
iteration 16, loss 0.57641392
iteration 17, loss 0.57968785
iteration 18, loss 0.58301143
iteration 19, loss 0.58576359
iteration 20, loss 0.58847617
iteration 21, loss 0.59104633
iteration 22, loss 0.59346773
iteration 23, loss 0.59570311
iteration 24, loss 0.59775741
iteration 25, loss 0.59969276
iteration 26, loss 0.60155564
iteration 27, loss 0.60334356
iteration 28, loss 0.60486874
iteration 29, loss 0.60641765
iteration 30, loss 0.60784581
iteration 31, loss 0.60923029
iteration 32, loss 0.61048339
iteration 33, loss 0.61168689
iteration 34, loss 0.61278009
iteration 35, loss 0.61381753
iteration 36, loss 0.61481707
iteration 37, loss 0.61575835
iteration 38, loss 0.61663787
iteration 39, loss 0.61748834
iteration 40, loss 0.61827981
iteration 41, loss 0.61902903
iteration 42, loss 0.61979728
iteration 43, loss 0.62040567
iteration 44, loss 0.62102107
iteration 45, loss 0.62161955
iteration 46, loss 0.62220135
iteration 47, loss 0.62274105
iteration 48, loss 0.62325291
iteration 49, loss 0.62374749
iteration 50, loss 0.62419089
iteration 51, loss 0.62466451
iteration 52, loss 0.62505653
iteration 53, loss 0.62546194
iteration 54, loss 0.62583115
iteration 55, loss 0.62614983
iteration 56, loss 0.62650791
iteration 57, loss 0.62694530
iteration 58, loss 0.62713532
iteration 59, loss 0.62746309
iteration 60, loss 0.62766456
iteration 61, loss 0.62796321
iteration 62, loss 0.62822539
iteration 63, loss 0.62841065
iteration 64, loss 0.62866079
iteration 65, loss 0.62887669
iteration 66, loss 0.62904294
iteration 67, loss 0.62927645
iteration 68, loss 0.62942434
iteration 69, loss 0.62962125
iteration 70, loss 0.62990568
iteration 71, loss 0.62994844
iteration 72, loss 0.63014537
iteration 73, loss 0.63024692
iteration 74, loss 0.63035976
iteration 75, loss 0.63049364
iteration 76, loss 0.63061770
iteration 77, loss 0.63075051
iteration 78, loss 0.63085619
iteration 79, loss 0.63095559
iteration 80, loss 0.63105459
iteration 81, loss 0.63114103
iteration 82, loss 0.63123599
iteration 83, loss 0.63133225
iteration 84, loss 0.63143387
iteration 85, loss 0.63148634
iteration 86, loss 0.63163556
iteration 87, loss 0.63167111
iteration 88, loss 0.63171987
iteration 89, loss 0.63180143
iteration 90, loss 0.63183909
iteration 91, loss 0.63191407
iteration 92, loss 0.63196233
iteration 93, loss 0.63201574
iteration 94, loss 0.63207588
iteration 95, loss 0.63210849
iteration 96, loss 0.63218367
iteration 97, loss 0.63220495
iteration 98, loss 0.63225248
iteration 99, loss 0.63229275
iteration 100, loss 0.63231941
iteration 101, loss 0.63239757
iteration 102, loss 0.63239089
iteration 103, loss 0.63243200
iteration 104, loss 0.63250128
iteration 105, loss 0.63252521
iteration 106, loss 0.63252363
iteration 107, loss 0.63264575
iteration 108, loss 0.63259720
iteration 109, loss 0.63258945
iteration 110, loss 0.63260925
iteration 111, loss 0.63264881
iteration 112, loss 0.63271307
iteration 113, loss 0.63268419
iteration 114, loss 0.63271458
iteration 115, loss 0.63279010
iteration 116, loss 0.63274983
iteration 117, loss 0.63276651
iteration 118, loss 0.63277389
iteration 119, loss 0.63279316
iteration 120, loss 0.63281209
iteration 121, loss 0.63281053
iteration 122, loss 0.63287040
iteration 123, loss 0.63286362
iteration 124, loss 0.63284750
iteration 125, loss 0.63289249
iteration 126, loss 0.63301205
iteration 127, loss 0.63287539
iteration 128, loss 0.63288496
iteration 129, loss 0.63289833
iteration 130, loss 0.63289887
iteration 131, loss 0.63291071
iteration 132, loss 0.63293623
iteration 133, loss 0.63292654
iteration 134, loss 0.63292788
iteration 135, loss 0.63294592
iteration 136, loss 0.63298147
iteration 137, loss 0.63308506
iteration 138, loss 0.63295619
iteration 139, loss 0.63296293
iteration 140, loss 0.63297597
iteration 141, loss 0.63296741
iteration 142, loss 0.63311500
iteration 143, loss 0.63297241
iteration 144, loss 0.63301363
iteration 145, loss 0.63297964
iteration 146, loss 0.63298966
iteration 147, loss 0.63305190
iteration 148, loss 0.63298018
iteration 149, loss 0.63312300
iteration 150, loss 0.63312358
iteration 151, loss 0.63301698
iteration 152, loss 0.63300514
iteration 153, loss 0.63299477
iteration 154, loss 0.63303171
iteration 155, loss 0.63299368
iteration 156, loss 0.63302442
iteration 157, loss 0.63299881
iteration 158, loss 0.63307059
iteration 159, loss 0.63303064
iteration 160, loss 0.63300821
iteration 161, loss 0.63300842
iteration 162, loss 0.63306269
iteration 163, loss 0.63313315
iteration 164, loss 0.63300175
iteration 165, loss 0.63300162
iteration 166, loss 0.63299500
iteration 167, loss 0.63300629
iteration 168, loss 0.63308902
iteration 169, loss 0.63305600
iteration 170, loss 0.63313722
iteration 171, loss 0.63300355
iteration 172, loss 0.63301354
iteration 173, loss 0.63298899
iteration 174, loss 0.63301195
iteration 175, loss 0.63298823
iteration 176, loss 0.63312245
iteration 177, loss 0.63300233
iteration 178, loss 0.63311904
iteration 179, loss 0.63297324
iteration 180, loss 0.63313717
iteration 181, loss 0.63310504
iteration 182, loss 0.63298053
iteration 183, loss 0.63298072
iteration 184, loss 0.63299177
iteration 185, loss 0.63312662
iteration 186, loss 0.63295382
iteration 187, loss 0.63295587
iteration 188, loss 0.63295182
iteration 189, loss 0.63295360
iteration 190, loss 0.63294863
iteration 191, loss 0.63297035
iteration 192, loss 0.63300686
iteration 193, loss 0.63310404
iteration 194, loss 0.63294570
iteration 195, loss 0.63293068
iteration 196, loss 0.63295526
iteration 197, loss 0.63293872
iteration 198, loss 0.63295845
iteration 199, loss 0.63292145
iteration 200, loss 0.63291191
iteration 201, loss 0.63292256
iteration 202, loss 0.63292842
iteration 203, loss 0.63290399
iteration 204, loss 0.63293340
iteration 205, loss 0.63291857
iteration 206, loss 0.63289237
iteration 207, loss 0.63288791
iteration 208, loss 0.63295462
iteration 209, loss 0.63290023
iteration 210, loss 0.63290798
iteration 211, loss 0.63291796
iteration 212, loss 0.63287519
iteration 213, loss 0.63287379
iteration 214, loss 0.63287399
iteration 215, loss 0.63286743
iteration 216, loss 0.63285688
iteration 217, loss 0.63291916
iteration 218, loss 0.63284687
iteration 219, loss 0.63284238
iteration 220, loss 0.63285092
iteration 221, loss 0.63287494
iteration 222, loss 0.63289394
iteration 223, loss 0.63289088
iteration 224, loss 0.63284347
iteration 225, loss 0.63283108
iteration 226, loss 0.63280951
iteration 227, loss 0.63281290
iteration 228, loss 0.63280373
iteration 229, loss 0.63296639
iteration 230, loss 0.63284883
iteration 231, loss 0.63282167
iteration 232, loss 0.63278884
iteration 233, loss 0.63281326
iteration 234, loss 0.63277959
iteration 235, loss 0.63277245
iteration 236, loss 0.63286304
iteration 237, loss 0.63277322
iteration 238, loss 0.63275087
iteration 239, loss 0.63275739
iteration 240, loss 0.63288295
iteration 241, loss 0.63276547
iteration 242, loss 0.63274329
iteration 243, loss 0.63275734
iteration 244, loss 0.63272580
iteration 245, loss 0.63274170
iteration 246, loss 0.63271437
iteration 247, loss 0.63272425
iteration 248, loss 0.63272897
iteration 249, loss 0.63270470
iteration 250, loss 0.63269620
iteration 251, loss 0.63270716
iteration 252, loss 0.63267762
iteration 253, loss 0.63268239
iteration 254, loss 0.63269305
iteration 255, loss 0.63265709
iteration 256, loss 0.63265070
iteration 257, loss 0.63266305
iteration 258, loss 0.63264616
iteration 259, loss 0.63263644
iteration 260, loss 0.63262810
iteration 261, loss 0.63262751
iteration 262, loss 0.63264592
iteration 263, loss 0.63260046
iteration 264, loss 0.63262841
iteration 265, loss 0.63259462
iteration 266, loss 0.63258609
iteration 267, loss 0.63271415
iteration 268, loss 0.63258518
iteration 269, loss 0.63256958
iteration 270, loss 0.63263008
iteration 271, loss 0.63262170
iteration 272, loss 0.63255694
iteration 273, loss 0.63253619
iteration 274, loss 0.63255064
iteration 275, loss 0.63252185
iteration 276, loss 0.63252819
iteration 277, loss 0.63257397
iteration 278, loss 0.63256216
iteration 279, loss 0.63250537
iteration 280, loss 0.63254537
iteration 281, loss 0.63261407
iteration 282, loss 0.63248077
iteration 283, loss 0.63252682
iteration 284, loss 0.63251917
iteration 285, loss 0.63244639
iteration 286, loss 0.63244513
iteration 287, loss 0.63242537
iteration 288, loss 0.63242884
iteration 289, loss 0.63242831
iteration 290, loss 0.63253834
iteration 291, loss 0.63240350
iteration 292, loss 0.63238311
iteration 293, loss 0.63242039
iteration 294, loss 0.63240506
iteration 295, loss 0.63242798
iteration 296, loss 0.63235823
iteration 297, loss 0.63235704
iteration 298, loss 0.63233202
iteration 299, loss 0.63239051
iteration 300, loss 0.63233808
iteration 301, loss 0.63237607
iteration 302, loss 0.63237913
iteration 303, loss 0.63233122
iteration 304, loss 0.63227070
iteration 305, loss 0.63226002
iteration 306, loss 0.63226414
iteration 307, loss 0.63225760
iteration 308, loss 0.63226839
iteration 309, loss 0.63236362
iteration 310, loss 0.63223008
iteration 311, loss 0.63220761
iteration 312, loss 0.63220552
iteration 313, loss 0.63218850
iteration 314, loss 0.63223182
iteration 315, loss 0.63216111
iteration 316, loss 0.63215828
iteration 317, loss 0.63220963
iteration 318, loss 0.63213598
iteration 319, loss 0.63214867
iteration 320, loss 0.63210507
iteration 321, loss 0.63216211
iteration 322, loss 0.63222527
iteration 323, loss 0.63209298
iteration 324, loss 0.63208353
iteration 325, loss 0.63207661
iteration 326, loss 0.63214001
iteration 327, loss 0.63204366
iteration 328, loss 0.63205156
iteration 329, loss 0.63205537
iteration 330, loss 0.63213341
iteration 331, loss 0.63201155
iteration 332, loss 0.63198342
iteration 333, loss 0.63198342
iteration 334, loss 0.63195165
iteration 335, loss 0.63206681
iteration 336, loss 0.63191176
iteration 337, loss 0.63190794
iteration 338, loss 0.63196163
iteration 339, loss 0.63190271
iteration 340, loss 0.63186480
iteration 341, loss 0.63192038
iteration 342, loss 0.63184952
iteration 343, loss 0.63184369
iteration 344, loss 0.63184179
iteration 345, loss 0.63186444
iteration 346, loss 0.63179086
iteration 347, loss 0.63177137
iteration 348, loss 0.63182328
iteration 349, loss 0.63175393
iteration 350, loss 0.63186716
iteration 351, loss 0.63178761
iteration 352, loss 0.63175640
iteration 353, loss 0.63174960
iteration 354, loss 0.63166957
iteration 355, loss 0.63164581
iteration 356, loss 0.63166369
iteration 357, loss 0.63175418
iteration 358, loss 0.63161383
iteration 359, loss 0.63168609
iteration 360, loss 0.63157910
iteration 361, loss 0.63155444
iteration 362, loss 0.63153693
iteration 363, loss 0.63166887
iteration 364, loss 0.63151968
iteration 365, loss 0.63149936
iteration 366, loss 0.63154378
iteration 367, loss 0.63147508
iteration 368, loss 0.63143502
iteration 369, loss 0.63142167
iteration 370, loss 0.63142271
iteration 371, loss 0.63138961
iteration 372, loss 0.63136587
iteration 373, loss 0.63135465
iteration 374, loss 0.63137503
iteration 375, loss 0.63133638
iteration 376, loss 0.63136631
iteration 377, loss 0.63130034
iteration 378, loss 0.63125060
iteration 379, loss 0.63123916
iteration 380, loss 0.63135545
iteration 381, loss 0.63126635
iteration 382, loss 0.63126209
iteration 383, loss 0.63116282
iteration 384, loss 0.63117223
iteration 385, loss 0.63113594
iteration 386, loss 0.63115600
iteration 387, loss 0.63114830
iteration 388, loss 0.63105328
iteration 389, loss 0.63110823
iteration 390, loss 0.63101493
iteration 391, loss 0.63099558
iteration 392, loss 0.63107039
iteration 393, loss 0.63101518
iteration 394, loss 0.63096839
iteration 395, loss 0.63104792
iteration 396, loss 0.63095381
iteration 397, loss 0.63088599
iteration 398, loss 0.63097427
iteration 399, loss 0.63087672
iteration 400, loss 0.63085872
iteration 401, loss 0.63079965
iteration 402, loss 0.63075414
iteration 403, loss 0.63080036
iteration 404, loss 0.63070686
iteration 405, loss 0.63070631
iteration 406, loss 0.63065365
iteration 407, loss 0.63062170
iteration 408, loss 0.63060135
iteration 409, loss 0.63060859
iteration 410, loss 0.63055332
iteration 411, loss 0.63056485
iteration 412, loss 0.63050618
iteration 413, loss 0.63047438
iteration 414, loss 0.63052755
iteration 415, loss 0.63049470
iteration 416, loss 0.63040982
iteration 417, loss 0.63038390
iteration 418, loss 0.63034801
iteration 419, loss 0.63031848
iteration 420, loss 0.63029693
iteration 421, loss 0.63026839
iteration 422, loss 0.63024067
iteration 423, loss 0.63022814
iteration 424, loss 0.63019063
iteration 425, loss 0.63016307
iteration 426, loss 0.63012200
iteration 427, loss 0.63008988
iteration 428, loss 0.63021565
iteration 429, loss 0.63005802
iteration 430, loss 0.63002535
iteration 431, loss 0.62998029
iteration 432, loss 0.62995072
iteration 433, loss 0.62990975
iteration 434, loss 0.62987724
iteration 435, loss 0.62984407
iteration 436, loss 0.62983825
iteration 437, loss 0.62985889
iteration 438, loss 0.62976056
iteration 439, loss 0.62975789
iteration 440, loss 0.62969582
iteration 441, loss 0.62965404
iteration 442, loss 0.62971155
iteration 443, loss 0.62963247
iteration 444, loss 0.62960535
iteration 445, loss 0.62960640
iteration 446, loss 0.62955483
iteration 447, loss 0.62953009
iteration 448, loss 0.62942414
iteration 449, loss 0.62941499
iteration 450, loss 0.62935362
iteration 451, loss 0.62937369
iteration 452, loss 0.62928945
iteration 453, loss 0.62927205
iteration 454, loss 0.62927320
iteration 455, loss 0.62917844
iteration 456, loss 0.62912480
iteration 457, loss 0.62909797
iteration 458, loss 0.62909843
iteration 459, loss 0.62905529
iteration 460, loss 0.62897924
iteration 461, loss 0.62895295
iteration 462, loss 0.62890625
iteration 463, loss 0.62889608
iteration 464, loss 0.62881790
iteration 465, loss 0.62879799
iteration 466, loss 0.62889330
iteration 467, loss 0.62871837
iteration 468, loss 0.62871834
iteration 469, loss 0.62860762
iteration 470, loss 0.62859488
iteration 471, loss 0.62854146
iteration 472, loss 0.62851540
iteration 473, loss 0.62845510
iteration 474, loss 0.62840866
iteration 475, loss 0.62844074
iteration 476, loss 0.62845652
iteration 477, loss 0.62843783
iteration 478, loss 0.62826403
iteration 479, loss 0.62818966
iteration 480, loss 0.62815204
iteration 481, loss 0.62809120
iteration 482, loss 0.62804501
iteration 483, loss 0.62798242
iteration 484, loss 0.62803277
iteration 485, loss 0.62789615
iteration 486, loss 0.62799588
iteration 487, loss 0.62784118
iteration 488, loss 0.62777138
iteration 489, loss 0.62777671
iteration 490, loss 0.62769031
iteration 491, loss 0.62761128
iteration 492, loss 0.62756683
iteration 493, loss 0.62756855
iteration 494, loss 0.62748797
iteration 495, loss 0.62741143
iteration 496, loss 0.62735399
iteration 497, loss 0.62744524
iteration 498, loss 0.62731677
iteration 499, loss 0.62726306
iteration 500, loss 0.62721560
iteration 501, loss 0.62707572
iteration 502, loss 0.62702904
iteration 503, loss 0.62701093
iteration 504, loss 0.62691691
iteration 505, loss 0.62689633
iteration 506, loss 0.62681136
iteration 507, loss 0.62676046
iteration 508, loss 0.62671519
iteration 509, loss 0.62670943
iteration 510, loss 0.62664837
iteration 511, loss 0.62653219
iteration 512, loss 0.62647018
iteration 513, loss 0.62639677
iteration 514, loss 0.62638607
iteration 515, loss 0.62629324
iteration 516, loss 0.62622704
iteration 517, loss 0.62616413
iteration 518, loss 0.62614779
iteration 519, loss 0.62605926
iteration 520, loss 0.62612605
iteration 521, loss 0.62592167
iteration 522, loss 0.62587071
iteration 523, loss 0.62580440
iteration 524, loss 0.62582005
iteration 525, loss 0.62567383
iteration 526, loss 0.62561957
iteration 527, loss 0.62554410
iteration 528, loss 0.62560823
iteration 529, loss 0.62539598
iteration 530, loss 0.62548294
iteration 531, loss 0.62530978
iteration 532, loss 0.62518916
iteration 533, loss 0.62521049
iteration 534, loss 0.62510699
iteration 535, loss 0.62500436
iteration 536, loss 0.62493524
iteration 537, loss 0.62485774
iteration 538, loss 0.62479494
iteration 539, loss 0.62471186
iteration 540, loss 0.62466626
iteration 541, loss 0.62456768
iteration 542, loss 0.62449593
iteration 543, loss 0.62442229
iteration 544, loss 0.62434850
iteration 545, loss 0.62429882
iteration 546, loss 0.62425370
iteration 547, loss 0.62415364
iteration 548, loss 0.62403956
iteration 549, loss 0.62398673
iteration 550, loss 0.62388601
iteration 551, loss 0.62379536
iteration 552, loss 0.62387080
iteration 553, loss 0.62369346
iteration 554, loss 0.62364612
iteration 555, loss 0.62353726
iteration 556, loss 0.62343502
iteration 557, loss 0.62334645
iteration 558, loss 0.62332047
iteration 559, loss 0.62320226
iteration 560, loss 0.62315634
iteration 561, loss 0.62315215
iteration 562, loss 0.62291918
iteration 563, loss 0.62283482
iteration 564, loss 0.62279475
iteration 565, loss 0.62271049
iteration 566, loss 0.62262270
iteration 567, loss 0.62265466
iteration 568, loss 0.62241980
iteration 569, loss 0.62232626
iteration 570, loss 0.62224587
iteration 571, loss 0.62217159
iteration 572, loss 0.62202648
iteration 573, loss 0.62195482
iteration 574, loss 0.62185303
iteration 575, loss 0.62177144
iteration 576, loss 0.62178512
iteration 577, loss 0.62175202
iteration 578, loss 0.62152515
iteration 579, loss 0.62155396
iteration 580, loss 0.62138611
iteration 581, loss 0.62125524
iteration 582, loss 0.62118654
iteration 583, loss 0.62104321
iteration 584, loss 0.62094395
iteration 585, loss 0.62084720
iteration 586, loss 0.62077918
iteration 587, loss 0.62074702
iteration 588, loss 0.62057757
iteration 589, loss 0.62053452
iteration 590, loss 0.62037790
iteration 591, loss 0.62027000
iteration 592, loss 0.62020143
iteration 593, loss 0.62008138
iteration 594, loss 0.61997570
iteration 595, loss 0.61986947
iteration 596, loss 0.61975794
iteration 597, loss 0.61973102
iteration 598, loss 0.61956716
iteration 599, loss 0.61948039
iteration 600, loss 0.61934641
iteration 601, loss 0.61921152
iteration 602, loss 0.61912869
iteration 603, loss 0.61903240
iteration 604, loss 0.61896771
iteration 605, loss 0.61890426
iteration 606, loss 0.61871266
iteration 607, loss 0.61857902
iteration 608, loss 0.61845869
iteration 609, loss 0.61841779
iteration 610, loss 0.61826213
iteration 611, loss 0.61815761
iteration 612, loss 0.61808693
iteration 613, loss 0.61795492
iteration 614, loss 0.61782361
iteration 615, loss 0.61771345
iteration 616, loss 0.61760361
iteration 617, loss 0.61746025
iteration 618, loss 0.61736017
iteration 619, loss 0.61723970
iteration 620, loss 0.61716944
iteration 621, loss 0.61704995
iteration 622, loss 0.61693266
iteration 623, loss 0.61682439
iteration 624, loss 0.61664918
iteration 625, loss 0.61651631
iteration 626, loss 0.61640069
iteration 627, loss 0.61630743
iteration 628, loss 0.61629809
iteration 629, loss 0.61615232
iteration 630, loss 0.61604649
iteration 631, loss 0.61578743
iteration 632, loss 0.61562196
iteration 633, loss 0.61556662
iteration 634, loss 0.61545214
iteration 635, loss 0.61530874
iteration 636, loss 0.61514400
iteration 637, loss 0.61499245
iteration 638, loss 0.61486660
iteration 639, loss 0.61476765
iteration 640, loss 0.61460886
iteration 641, loss 0.61449284
iteration 642, loss 0.61447177
iteration 643, loss 0.61430748
iteration 644, loss 0.61423339
iteration 645, loss 0.61402217
iteration 646, loss 0.61396617
iteration 647, loss 0.61373581
iteration 648, loss 0.61365692
iteration 649, loss 0.61362839
iteration 650, loss 0.61340554
iteration 651, loss 0.61336892
iteration 652, loss 0.61309135
iteration 653, loss 0.61295520
iteration 654, loss 0.61285388
iteration 655, loss 0.61271491
iteration 656, loss 0.61257934
iteration 657, loss 0.61238058
iteration 658, loss 0.61220142
iteration 659, loss 0.61215109
iteration 660, loss 0.61202658
iteration 661, loss 0.61185028
iteration 662, loss 0.61184182
iteration 663, loss 0.61155106
iteration 664, loss 0.61137256
iteration 665, loss 0.61125348
iteration 666, loss 0.61109389
iteration 667, loss 0.61097142
iteration 668, loss 0.61086397
iteration 669, loss 0.61069468
iteration 670, loss 0.61052591
iteration 671, loss 0.61039145
iteration 672, loss 0.61029732
iteration 673, loss 0.61025727
iteration 674, loss 0.60993756
iteration 675, loss 0.60979915
iteration 676, loss 0.60963793
iteration 677, loss 0.60948961
iteration 678, loss 0.60937112
iteration 679, loss 0.60918496
iteration 680, loss 0.60904300
iteration 681, loss 0.60888957
iteration 682, loss 0.60876657
iteration 683, loss 0.60863682
iteration 684, loss 0.60848463
iteration 685, loss 0.60841150
iteration 686, loss 0.60819138
iteration 687, loss 0.60800871
iteration 688, loss 0.60784078
iteration 689, loss 0.60768094
iteration 690, loss 0.60750031
iteration 691, loss 0.60739598
iteration 692, loss 0.60721035
iteration 693, loss 0.60709490
iteration 694, loss 0.60707973
iteration 695, loss 0.60677253
iteration 696, loss 0.60659110
iteration 697, loss 0.60637721
iteration 698, loss 0.60631416
iteration 699, loss 0.60611382
iteration 700, loss 0.60596804
iteration 701, loss 0.60578681
iteration 702, loss 0.60564406
iteration 703, loss 0.60549742
iteration 704, loss 0.60532201
iteration 705, loss 0.60510060
iteration 706, loss 0.60492146
iteration 707, loss 0.60480461
iteration 708, loss 0.60467665
iteration 709, loss 0.60452540
iteration 710, loss 0.60451583
iteration 711, loss 0.60424628
iteration 712, loss 0.60408442
iteration 713, loss 0.60389692
iteration 714, loss 0.60374041
iteration 715, loss 0.60352733
iteration 716, loss 0.60334681
iteration 717, loss 0.60319110
iteration 718, loss 0.60300206
iteration 719, loss 0.60284088
iteration 720, loss 0.60272292
iteration 721, loss 0.60252999
iteration 722, loss 0.60240126
iteration 723, loss 0.60219336
iteration 724, loss 0.60201429
iteration 725, loss 0.60181830
iteration 726, loss 0.60165573
iteration 727, loss 0.60146948
iteration 728, loss 0.60131471
iteration 729, loss 0.60121636
iteration 730, loss 0.60115004
iteration 731, loss 0.60084277
iteration 732, loss 0.60073499
iteration 733, loss 0.60053187
iteration 734, loss 0.60036045
iteration 735, loss 0.60021332
iteration 736, loss 0.59995833
iteration 737, loss 0.59981508
iteration 738, loss 0.59974802
iteration 739, loss 0.59939287
iteration 740, loss 0.59931982
iteration 741, loss 0.59910235
iteration 742, loss 0.59893522
iteration 743, loss 0.59890138
iteration 744, loss 0.59855478
iteration 745, loss 0.59842317
iteration 746, loss 0.59825711
iteration 747, loss 0.59801049
iteration 748, loss 0.59782318
iteration 749, loss 0.59769036
iteration 750, loss 0.59752844
iteration 751, loss 0.59731329
iteration 752, loss 0.59719555
iteration 753, loss 0.59707097
iteration 754, loss 0.59685266
iteration 755, loss 0.59662703
iteration 756, loss 0.59642701
iteration 757, loss 0.59625751
iteration 758, loss 0.59607147
iteration 759, loss 0.59588393
iteration 760, loss 0.59583443
iteration 761, loss 0.59548968
iteration 762, loss 0.59532655
iteration 763, loss 0.59513843
iteration 764, loss 0.59499045
iteration 765, loss 0.59478004
iteration 766, loss 0.59461353
iteration 767, loss 0.59453507
iteration 768, loss 0.59436064
iteration 769, loss 0.59413458
iteration 770, loss 0.59397653
iteration 771, loss 0.59372419
iteration 772, loss 0.59366964
iteration 773, loss 0.59334181
iteration 774, loss 0.59317051
iteration 775, loss 0.59301659
iteration 776, loss 0.59281912
iteration 777, loss 0.59271840
iteration 778, loss 0.59249322
iteration 779, loss 0.59228760
iteration 780, loss 0.59206298
iteration 781, loss 0.59190945
iteration 782, loss 0.59179472
iteration 783, loss 0.59155443
iteration 784, loss 0.59140938
iteration 785, loss 0.59114123
iteration 786, loss 0.59098018
iteration 787, loss 0.59079526
iteration 788, loss 0.59067052
iteration 789, loss 0.59038119
iteration 790, loss 0.59030677
iteration 791, loss 0.59005342
iteration 792, loss 0.58994461
iteration 793, loss 0.58972579
iteration 794, loss 0.58951444
iteration 795, loss 0.58934027
iteration 796, loss 0.58917271
iteration 797, loss 0.58898315
iteration 798, loss 0.58894417
iteration 799, loss 0.58868255
iteration 800, loss 0.58840090
iteration 801, loss 0.58819486
iteration 802, loss 0.58801203
iteration 803, loss 0.58783923
iteration 804, loss 0.58769572
iteration 805, loss 0.58766627
iteration 806, loss 0.58722572
iteration 807, loss 0.58703140
iteration 808, loss 0.58704808
iteration 809, loss 0.58672748
iteration 810, loss 0.58656213
iteration 811, loss 0.58636843
iteration 812, loss 0.58618930
iteration 813, loss 0.58600021
iteration 814, loss 0.58582396
iteration 815, loss 0.58566021
iteration 816, loss 0.58543692
iteration 817, loss 0.58520365
iteration 818, loss 0.58512397
iteration 819, loss 0.58487783
iteration 820, loss 0.58463477
iteration 821, loss 0.58456114
iteration 822, loss 0.58425643
iteration 823, loss 0.58428196
iteration 824, loss 0.58390700
iteration 825, loss 0.58369353
iteration 826, loss 0.58355525
iteration 827, loss 0.58332838
iteration 828, loss 0.58321654
iteration 829, loss 0.58298055
iteration 830, loss 0.58282001
iteration 831, loss 0.58257604
iteration 832, loss 0.58237746
iteration 833, loss 0.58214972
iteration 834, loss 0.58213108
iteration 835, loss 0.58182906
iteration 836, loss 0.58164244
iteration 837, loss 0.58146945
iteration 838, loss 0.58132477
iteration 839, loss 0.58104031
iteration 840, loss 0.58084730
iteration 841, loss 0.58063640
iteration 842, loss 0.58065429
iteration 843, loss 0.58032162
iteration 844, loss 0.58022520
iteration 845, loss 0.57998866
iteration 846, loss 0.57974250
iteration 847, loss 0.57957903
iteration 848, loss 0.57937301
iteration 849, loss 0.57927566
iteration 850, loss 0.57912273
iteration 851, loss 0.57882583
iteration 852, loss 0.57870718
iteration 853, loss 0.57859558
iteration 854, loss 0.57833197
iteration 855, loss 0.57813826
iteration 856, loss 0.57788565
iteration 857, loss 0.57790687
iteration 858, loss 0.57757429
iteration 859, loss 0.57749751
iteration 860, loss 0.57725462
iteration 861, loss 0.57701480
iteration 862, loss 0.57680346
iteration 863, loss 0.57664920
iteration 864, loss 0.57647500
iteration 865, loss 0.57625865
iteration 866, loss 0.57606040
iteration 867, loss 0.57599925
iteration 868, loss 0.57574321
iteration 869, loss 0.57554172
iteration 870, loss 0.57537025
iteration 871, loss 0.57515547
iteration 872, loss 0.57501919
iteration 873, loss 0.57480710
iteration 874, loss 0.57464351
iteration 875, loss 0.57445947
iteration 876, loss 0.57416143
iteration 877, loss 0.57403341
iteration 878, loss 0.57401894
iteration 879, loss 0.57376878
iteration 880, loss 0.57359895
iteration 881, loss 0.57333340
iteration 882, loss 0.57315149
iteration 883, loss 0.57306550
iteration 884, loss 0.57279763
iteration 885, loss 0.57256719
iteration 886, loss 0.57249492
iteration 887, loss 0.57227084
iteration 888, loss 0.57221387
iteration 889, loss 0.57181079
iteration 890, loss 0.57169268
iteration 891, loss 0.57142293
iteration 892, loss 0.57128135
iteration 893, loss 0.57110256
iteration 894, loss 0.57099747
iteration 895, loss 0.57091272
iteration 896, loss 0.57056949
iteration 897, loss 0.57043523
iteration 898, loss 0.57018293
iteration 899, loss 0.57003129
iteration 900, loss 0.56977197
iteration 901, loss 0.56984729
iteration 902, loss 0.56951508
iteration 903, loss 0.56921533
iteration 904, loss 0.56908530
iteration 905, loss 0.56892934
iteration 906, loss 0.56874117
iteration 907, loss 0.56856928
iteration 908, loss 0.56842079
iteration 909, loss 0.56820971
iteration 910, loss 0.56794058
iteration 911, loss 0.56788740
iteration 912, loss 0.56767109
iteration 913, loss 0.56750376
iteration 914, loss 0.56739493
iteration 915, loss 0.56718040
iteration 916, loss 0.56698854
iteration 917, loss 0.56686516
iteration 918, loss 0.56661015
iteration 919, loss 0.56664695
iteration 920, loss 0.56635994
iteration 921, loss 0.56605647
iteration 922, loss 0.56587692
iteration 923, loss 0.56568799
iteration 924, loss 0.56558485
iteration 925, loss 0.56537258
iteration 926, loss 0.56522172
iteration 927, loss 0.56502485
iteration 928, loss 0.56484533
iteration 929, loss 0.56467465
iteration 930, loss 0.56459964
iteration 931, loss 0.56437785
iteration 932, loss 0.56438234
iteration 933, loss 0.56422538
iteration 934, loss 0.56390174
iteration 935, loss 0.56367552
iteration 936, loss 0.56364271
iteration 937, loss 0.56327365
iteration 938, loss 0.56317950
iteration 939, loss 0.56299573
iteration 940, loss 0.56276296
iteration 941, loss 0.56256732
iteration 942, loss 0.56269755
iteration 943, loss 0.56230160
iteration 944, loss 0.56208620
iteration 945, loss 0.56191079
iteration 946, loss 0.56186808
iteration 947, loss 0.56165429
iteration 948, loss 0.56148715
iteration 949, loss 0.56124550
iteration 950, loss 0.56107049
iteration 951, loss 0.56093169
iteration 952, loss 0.56075918
iteration 953, loss 0.56059868
iteration 954, loss 0.56052172
iteration 955, loss 0.56030156
iteration 956, loss 0.56017305
iteration 957, loss 0.55987216
iteration 958, loss 0.55969771
iteration 959, loss 0.55956493
iteration 960, loss 0.55932948
iteration 961, loss 0.55911112
iteration 962, loss 0.55909444
iteration 963, loss 0.55890677
iteration 964, loss 0.55864092
iteration 965, loss 0.55864617
iteration 966, loss 0.55845076
iteration 967, loss 0.55815269
iteration 968, loss 0.55805247
iteration 969, loss 0.55785004
iteration 970, loss 0.55783552
iteration 971, loss 0.55756025
iteration 972, loss 0.55768869
iteration 973, loss 0.55732073
iteration 974, loss 0.55703536
iteration 975, loss 0.55696808
iteration 976, loss 0.55674710
iteration 977, loss 0.55657955
iteration 978, loss 0.55646978
iteration 979, loss 0.55621022
iteration 980, loss 0.55601723
iteration 981, loss 0.55600118
iteration 982, loss 0.55573927
iteration 983, loss 0.55566013
iteration 984, loss 0.55548045
iteration 985, loss 0.55526192
iteration 986, loss 0.55512399
iteration 987, loss 0.55495856
iteration 988, loss 0.55489613
iteration 989, loss 0.55468195
iteration 990, loss 0.55470344
iteration 991, loss 0.55454648
iteration 992, loss 0.55425650
iteration 993, loss 0.55400122
iteration 994, loss 0.55387174
iteration 995, loss 0.55361020
iteration 996, loss 0.55346705
iteration 997, loss 0.55340495
iteration 998, loss 0.55321914
iteration 999, loss 0.55324229
iteration 1000, loss 0.55311291
iteration 1001, loss 0.55285481
iteration 1002, loss 0.55255219
iteration 1003, loss 0.55252320
iteration 1004, loss 0.55210063
iteration 1005, loss 0.55207698
iteration 1006, loss 0.55185712
iteration 1007, loss 0.55168495
iteration 1008, loss 0.55151518
iteration 1009, loss 0.55139133
iteration 1010, loss 0.55120670
iteration 1011, loss 0.55107867
iteration 1012, loss 0.55103625
iteration 1013, loss 0.55079782
iteration 1014, loss 0.55075429
iteration 1015, loss 0.55056557
iteration 1016, loss 0.55043980
iteration 1017, loss 0.55046193
iteration 1018, loss 0.55008669
iteration 1019, loss 0.54980556
iteration 1020, loss 0.54977940
iteration 1021, loss 0.54956625
iteration 1022, loss 0.54946629
iteration 1023, loss 0.54949200
iteration 1024, loss 0.54925138
iteration 1025, loss 0.54912097
iteration 1026, loss 0.54879424
iteration 1027, loss 0.54862645
iteration 1028, loss 0.54844177
iteration 1029, loss 0.54828684
iteration 1030, loss 0.54827931
iteration 1031, loss 0.54811945
iteration 1032, loss 0.54793903
iteration 1033, loss 0.54800086
iteration 1034, loss 0.54768962
iteration 1035, loss 0.54753657
iteration 1036, loss 0.54735713
iteration 1037, loss 0.54720918
iteration 1038, loss 0.54705621
iteration 1039, loss 0.54693652
iteration 1040, loss 0.54679496
iteration 1041, loss 0.54658721
iteration 1042, loss 0.54645091
iteration 1043, loss 0.54639305
iteration 1044, loss 0.54618202
iteration 1045, loss 0.54611986
iteration 1046, loss 0.54591489
iteration 1047, loss 0.54571142
iteration 1048, loss 0.54562936
iteration 1049, loss 0.54539507
iteration 1050, loss 0.54531205
iteration 1051, loss 0.54514118
iteration 1052, loss 0.54513446
iteration 1053, loss 0.54485701
iteration 1054, loss 0.54466459
iteration 1055, loss 0.54459797
iteration 1056, loss 0.54450792
iteration 1057, loss 0.54444417
iteration 1058, loss 0.54408910
iteration 1059, loss 0.54404203
iteration 1060, loss 0.54388987
iteration 1061, loss 0.54363374
iteration 1062, loss 0.54350746
iteration 1063, loss 0.54337843
iteration 1064, loss 0.54322907
iteration 1065, loss 0.54314221
iteration 1066, loss 0.54302494
iteration 1067, loss 0.54288127
iteration 1068, loss 0.54268574
iteration 1069, loss 0.54273556
iteration 1070, loss 0.54241122
iteration 1071, loss 0.54243445
iteration 1072, loss 0.54226581
iteration 1073, loss 0.54200461
iteration 1074, loss 0.54183444
iteration 1075, loss 0.54186249
iteration 1076, loss 0.54166222
iteration 1077, loss 0.54149913
iteration 1078, loss 0.54138395
iteration 1079, loss 0.54127040
iteration 1080, loss 0.54101369
iteration 1081, loss 0.54100735
iteration 1082, loss 0.54073832
iteration 1083, loss 0.54060679
iteration 1084, loss 0.54047553
iteration 1085, loss 0.54034209
iteration 1086, loss 0.54039809
iteration 1087, loss 0.54018637
iteration 1088, loss 0.54013351
iteration 1089, loss 0.53983540
iteration 1090, loss 0.53983331
iteration 1091, loss 0.53937227
iteration 1092, loss 0.53933066
iteration 1093, loss 0.53931034
iteration 1094, loss 0.53916635
iteration 1095, loss 0.53900391
iteration 1096, loss 0.53901656
iteration 1097, loss 0.53870824
iteration 1098, loss 0.53881511
iteration 1099, loss 0.53854323
iteration 1100, loss 0.53827586
iteration 1101, loss 0.53812635
iteration 1102, loss 0.53799822
iteration 1103, loss 0.53788547
iteration 1104, loss 0.53775512
iteration 1105, loss 0.53760275
iteration 1106, loss 0.53747786
iteration 1107, loss 0.53738930
iteration 1108, loss 0.53731181
iteration 1109, loss 0.53706810
iteration 1110, loss 0.53699325
iteration 1111, loss 0.53703178
iteration 1112, loss 0.53680316
iteration 1113, loss 0.53673706
iteration 1114, loss 0.53645897
iteration 1115, loss 0.53637545
iteration 1116, loss 0.53638263
iteration 1117, loss 0.53616266
iteration 1118, loss 0.53598313
iteration 1119, loss 0.53579721
iteration 1120, loss 0.53577214
iteration 1121, loss 0.53577647
iteration 1122, loss 0.53554187
iteration 1123, loss 0.53537164
iteration 1124, loss 0.53536722
iteration 1125, loss 0.53503174
iteration 1126, loss 0.53506842
iteration 1127, loss 0.53479174
iteration 1128, loss 0.53470011
iteration 1129, loss 0.53459124
iteration 1130, loss 0.53445334
iteration 1131, loss 0.53423911
iteration 1132, loss 0.53414600
iteration 1133, loss 0.53400631
iteration 1134, loss 0.53394353
iteration 1135, loss 0.53378868
iteration 1136, loss 0.53359471
iteration 1137, loss 0.53343332
iteration 1138, loss 0.53331972
iteration 1139, loss 0.53321024
iteration 1140, loss 0.53314856
iteration 1141, loss 0.53301465
iteration 1142, loss 0.53279011
iteration 1143, loss 0.53270416
iteration 1144, loss 0.53281663
iteration 1145, loss 0.53267945
iteration 1146, loss 0.53243761
iteration 1147, loss 0.53230429
iteration 1148, loss 0.53205988
iteration 1149, loss 0.53195444
iteration 1150, loss 0.53180121
iteration 1151, loss 0.53166205
iteration 1152, loss 0.53157837
iteration 1153, loss 0.53155438
iteration 1154, loss 0.53133186
iteration 1155, loss 0.53123775
iteration 1156, loss 0.53116575
iteration 1157, loss 0.53102949
iteration 1158, loss 0.53093074
iteration 1159, loss 0.53079776
iteration 1160, loss 0.53062968
iteration 1161, loss 0.53040710
iteration 1162, loss 0.53032037
iteration 1163, loss 0.53025663
iteration 1164, loss 0.53026638
iteration 1165, loss 0.53019331
iteration 1166, loss 0.52997316
iteration 1167, loss 0.52977621
iteration 1168, loss 0.52977862
iteration 1169, loss 0.52957991
iteration 1170, loss 0.52925569
iteration 1171, loss 0.52930050
iteration 1172, loss 0.52921516
iteration 1173, loss 0.52906299
iteration 1174, loss 0.52902737
iteration 1175, loss 0.52876159
iteration 1176, loss 0.52871984
iteration 1177, loss 0.52850563
iteration 1178, loss 0.52855960
iteration 1179, loss 0.52847536
iteration 1180, loss 0.52833385
iteration 1181, loss 0.52832935
iteration 1182, loss 0.52823349
iteration 1183, loss 0.52803569
iteration 1184, loss 0.52779931
iteration 1185, loss 0.52781537
iteration 1186, loss 0.52767261
iteration 1187, loss 0.52754681
iteration 1188, loss 0.52736054
iteration 1189, loss 0.52739399
iteration 1190, loss 0.52703747
iteration 1191, loss 0.52716989
iteration 1192, loss 0.52688945
iteration 1193, loss 0.52682608
iteration 1194, loss 0.52667783
iteration 1195, loss 0.52647911
iteration 1196, loss 0.52646361
iteration 1197, loss 0.52622523
iteration 1198, loss 0.52606433
iteration 1199, loss 0.52584159
iteration 1200, loss 0.52612021
iteration 1201, loss 0.52580326
iteration 1202, loss 0.52558013
iteration 1203, loss 0.52541906
iteration 1204, loss 0.52552734
iteration 1205, loss 0.52535078
iteration 1206, loss 0.52505036
iteration 1207, loss 0.52526452
iteration 1208, loss 0.52493818
iteration 1209, loss 0.52483545
iteration 1210, loss 0.52474624
iteration 1211, loss 0.52467673
iteration 1212, loss 0.52452369
iteration 1213, loss 0.52457819
iteration 1214, loss 0.52426383
iteration 1215, loss 0.52419806
iteration 1216, loss 0.52387945
iteration 1217, loss 0.52374748
iteration 1218, loss 0.52387330
iteration 1219, loss 0.52378532
iteration 1220, loss 0.52352588
iteration 1221, loss 0.52332969
iteration 1222, loss 0.52332679
iteration 1223, loss 0.52318316
iteration 1224, loss 0.52329006
iteration 1225, loss 0.52315431
iteration 1226, loss 0.52289073
iteration 1227, loss 0.52282815
iteration 1228, loss 0.52270577
iteration 1229, loss 0.52253574
iteration 1230, loss 0.52255873
iteration 1231, loss 0.52219243
iteration 1232, loss 0.52234924
iteration 1233, loss 0.52213501
iteration 1234, loss 0.52197720
iteration 1235, loss 0.52195779
iteration 1236, loss 0.52182090
iteration 1237, loss 0.52165322
iteration 1238, loss 0.52152484
iteration 1239, loss 0.52144283
iteration 1240, loss 0.52141591
iteration 1241, loss 0.52128272
iteration 1242, loss 0.52112284
iteration 1243, loss 0.52117112
iteration 1244, loss 0.52094309
iteration 1245, loss 0.52098275
iteration 1246, loss 0.52063515
iteration 1247, loss 0.52052748
iteration 1248, loss 0.52065662
iteration 1249, loss 0.52030911
iteration 1250, loss 0.52019841
iteration 1251, loss 0.52022607
iteration 1252, loss 0.52005593
iteration 1253, loss 0.52000320
iteration 1254, loss 0.51987255
iteration 1255, loss 0.51982677
iteration 1256, loss 0.51957157
iteration 1257, loss 0.51957644
iteration 1258, loss 0.51933668
iteration 1259, loss 0.51927968
iteration 1260, loss 0.51921681
iteration 1261, loss 0.51904596
iteration 1262, loss 0.51894347
iteration 1263, loss 0.51894346
iteration 1264, loss 0.51870414
iteration 1265, loss 0.51860890
iteration 1266, loss 0.51878507
iteration 1267, loss 0.51855789
iteration 1268, loss 0.51852045
iteration 1269, loss 0.51829209
iteration 1270, loss 0.51822386
iteration 1271, loss 0.51806036
iteration 1272, loss 0.51796221
iteration 1273, loss 0.51788371
iteration 1274, loss 0.51779632
iteration 1275, loss 0.51766554
iteration 1276, loss 0.51749204
iteration 1277, loss 0.51747312
iteration 1278, loss 0.51737613
iteration 1279, loss 0.51714767
iteration 1280, loss 0.51698948
iteration 1281, loss 0.51683278
iteration 1282, loss 0.51677522
iteration 1283, loss 0.51667813
iteration 1284, loss 0.51663914
iteration 1285, loss 0.51651118
iteration 1286, loss 0.51637633
iteration 1287, loss 0.51643120
iteration 1288, loss 0.51634837
iteration 1289, loss 0.51625978
iteration 1290, loss 0.51609717
iteration 1291, loss 0.51597422
iteration 1292, loss 0.51583073
iteration 1293, loss 0.51571849
iteration 1294, loss 0.51565800
iteration 1295, loss 0.51535841
iteration 1296, loss 0.51531229
iteration 1297, loss 0.51535848
iteration 1298, loss 0.51519558
iteration 1299, loss 0.51532196
iteration 1300, loss 0.51500748
iteration 1301, loss 0.51498597
iteration 1302, loss 0.51478520
iteration 1303, loss 0.51475549
iteration 1304, loss 0.51457681
iteration 1305, loss 0.51441227
iteration 1306, loss 0.51456305
iteration 1307, loss 0.51426127
iteration 1308, loss 0.51405557
iteration 1309, loss 0.51417188
iteration 1310, loss 0.51406967
iteration 1311, loss 0.51393791
iteration 1312, loss 0.51374455
iteration 1313, loss 0.51351236
iteration 1314, loss 0.51356425
iteration 1315, loss 0.51338111
iteration 1316, loss 0.51325034
iteration 1317, loss 0.51334472
iteration 1318, loss 0.51333869
iteration 1319, loss 0.51309463
iteration 1320, loss 0.51302321
iteration 1321, loss 0.51307831
iteration 1322, loss 0.51280577
iteration 1323, loss 0.51274899
iteration 1324, loss 0.51282321
iteration 1325, loss 0.51263439
iteration 1326, loss 0.51255516
iteration 1327, loss 0.51242989
iteration 1328, loss 0.51222887
iteration 1329, loss 0.51199247
iteration 1330, loss 0.51193346
iteration 1331, loss 0.51177891
iteration 1332, loss 0.51181787
iteration 1333, loss 0.51175009
iteration 1334, loss 0.51155936
iteration 1335, loss 0.51151437
iteration 1336, loss 0.51123701
iteration 1337, loss 0.51122320
iteration 1338, loss 0.51130791
iteration 1339, loss 0.51111940
iteration 1340, loss 0.51104006
iteration 1341, loss 0.51083043
iteration 1342, loss 0.51075660
iteration 1343, loss 0.51074321
iteration 1344, loss 0.51056029
iteration 1345, loss 0.51050147
iteration 1346, loss 0.51039500
iteration 1347, loss 0.51030651
iteration 1348, loss 0.51022631
iteration 1349, loss 0.51012572
iteration 1350, loss 0.51004564
iteration 1351, loss 0.50997628
iteration 1352, loss 0.51005255
iteration 1353, loss 0.50989325
iteration 1354, loss 0.50964526
iteration 1355, loss 0.50969876
iteration 1356, loss 0.50949537
iteration 1357, loss 0.50946951
iteration 1358, loss 0.50945486
iteration 1359, loss 0.50926602
iteration 1360, loss 0.50917416
iteration 1361, loss 0.50896874
iteration 1362, loss 0.50886682
iteration 1363, loss 0.50896491
iteration 1364, loss 0.50886236
iteration 1365, loss 0.50879152
iteration 1366, loss 0.50848884
iteration 1367, loss 0.50833229
iteration 1368, loss 0.50844711
iteration 1369, loss 0.50838570
iteration 1370, loss 0.50825458
iteration 1371, loss 0.50804622
iteration 1372, loss 0.50799576
iteration 1373, loss 0.50793893
iteration 1374, loss 0.50779482
iteration 1375, loss 0.50785168
iteration 1376, loss 0.50750722
iteration 1377, loss 0.50745044
iteration 1378, loss 0.50759201
iteration 1379, loss 0.50732620
iteration 1380, loss 0.50748276
iteration 1381, loss 0.50723398
iteration 1382, loss 0.50712523
iteration 1383, loss 0.50707985
iteration 1384, loss 0.50700544
iteration 1385, loss 0.50674097
iteration 1386, loss 0.50659559
iteration 1387, loss 0.50659214
iteration 1388, loss 0.50670506
iteration 1389, loss 0.50648354
iteration 1390, loss 0.50634494
iteration 1391, loss 0.50621264
iteration 1392, loss 0.50616739
iteration 1393, loss 0.50599770
iteration 1394, loss 0.50590793
iteration 1395, loss 0.50570602
iteration 1396, loss 0.50563756
iteration 1397, loss 0.50585309
iteration 1398, loss 0.50562370
iteration 1399, loss 0.50544215
iteration 1400, loss 0.50540820
iteration 1401, loss 0.50536745
iteration 1402, loss 0.50527005
iteration 1403, loss 0.50513896
iteration 1404, loss 0.50505777
iteration 1405, loss 0.50496935
iteration 1406, loss 0.50505796
iteration 1407, loss 0.50500720
iteration 1408, loss 0.50473279
iteration 1409, loss 0.50466202
iteration 1410, loss 0.50442771
iteration 1411, loss 0.50426323
iteration 1412, loss 0.50416028
iteration 1413, loss 0.50430321
iteration 1414, loss 0.50406493
iteration 1415, loss 0.50407458
iteration 1416, loss 0.50393687
iteration 1417, loss 0.50397282
iteration 1418, loss 0.50391725
iteration 1419, loss 0.50381596
iteration 1420, loss 0.50359532
iteration 1421, loss 0.50355860
iteration 1422, loss 0.50356707
iteration 1423, loss 0.50350134
iteration 1424, loss 0.50330392
iteration 1425, loss 0.50323606
iteration 1426, loss 0.50314624
iteration 1427, loss 0.50305362
iteration 1428, loss 0.50291035
iteration 1429, loss 0.50265260
iteration 1430, loss 0.50263247
iteration 1431, loss 0.50267657
iteration 1432, loss 0.50268675
iteration 1433, loss 0.50244041
iteration 1434, loss 0.50233404
iteration 1435, loss 0.50220048
iteration 1436, loss 0.50221217
iteration 1437, loss 0.50210254
iteration 1438, loss 0.50196754
iteration 1439, loss 0.50211609
iteration 1440, loss 0.50197531
iteration 1441, loss 0.50178493
iteration 1442, loss 0.50165948
iteration 1443, loss 0.50153755
iteration 1444, loss 0.50135463
iteration 1445, loss 0.50156163
iteration 1446, loss 0.50133504
iteration 1447, loss 0.50139423
iteration 1448, loss 0.50134603
iteration 1449, loss 0.50110656
iteration 1450, loss 0.50098991
iteration 1451, loss 0.50107012
iteration 1452, loss 0.50069056
iteration 1453, loss 0.50100458
iteration 1454, loss 0.50070582
iteration 1455, loss 0.50066749
iteration 1456, loss 0.50045620
iteration 1457, loss 0.50028753
iteration 1458, loss 0.50028984
iteration 1459, loss 0.50012560
iteration 1460, loss 0.50010803
iteration 1461, loss 0.49998488
iteration 1462, loss 0.50002742
iteration 1463, loss 0.49998959
iteration 1464, loss 0.49978967
iteration 1465, loss 0.49974832
iteration 1466, loss 0.49967741
iteration 1467, loss 0.49962533
iteration 1468, loss 0.49942864
iteration 1469, loss 0.49969024
iteration 1470, loss 0.49947959
iteration 1471, loss 0.49928442
iteration 1472, loss 0.49927052
iteration 1473, loss 0.49926596
iteration 1474, loss 0.49906385
iteration 1475, loss 0.49881420
iteration 1476, loss 0.49867852
iteration 1477, loss 0.49867726
iteration 1478, loss 0.49867534
iteration 1479, loss 0.49853100
iteration 1480, loss 0.49835427
iteration 1481, loss 0.49835007
iteration 1482, loss 0.49830392
iteration 1483, loss 0.49830985
iteration 1484, loss 0.49813600
iteration 1485, loss 0.49803145
iteration 1486, loss 0.49802796
iteration 1487, loss 0.49803278
iteration 1488, loss 0.49787031
iteration 1489, loss 0.49779141
iteration 1490, loss 0.49772384
iteration 1491, loss 0.49764864
iteration 1492, loss 0.49768062
iteration 1493, loss 0.49736560
iteration 1494, loss 0.49731515
iteration 1495, loss 0.49726336
iteration 1496, loss 0.49713494
iteration 1497, loss 0.49706271
iteration 1498, loss 0.49704398
iteration 1499, loss 0.49692712
iteration 1500, loss 0.49688273
iteration 1501, loss 0.49680514
iteration 1502, loss 0.49662380
iteration 1503, loss 0.49656189
iteration 1504, loss 0.49650283
iteration 1505, loss 0.49633569
iteration 1506, loss 0.49623256
iteration 1507, loss 0.49634680
iteration 1508, loss 0.49618374
iteration 1509, loss 0.49618445
iteration 1510, loss 0.49601775
iteration 1511, loss 0.49601993
iteration 1512, loss 0.49581228
iteration 1513, loss 0.49589703
iteration 1514, loss 0.49574936
iteration 1515, loss 0.49569889
iteration 1516, loss 0.49554698
iteration 1517, loss 0.49568239
iteration 1518, loss 0.49537474
iteration 1519, loss 0.49517406
iteration 1520, loss 0.49514715
iteration 1521, loss 0.49510632
iteration 1522, loss 0.49504855
iteration 1523, loss 0.49494117
iteration 1524, loss 0.49495398
iteration 1525, loss 0.49492722
iteration 1526, loss 0.49488411
iteration 1527, loss 0.49466783
iteration 1528, loss 0.49451102
iteration 1529, loss 0.49453116
iteration 1530, loss 0.49445903
iteration 1531, loss 0.49452742
iteration 1532, loss 0.49439070
iteration 1533, loss 0.49435699
iteration 1534, loss 0.49412998
iteration 1535, loss 0.49403251
iteration 1536, loss 0.49405936
iteration 1537, loss 0.49401539
iteration 1538, loss 0.49380935
iteration 1539, loss 0.49375135
iteration 1540, loss 0.49350627
iteration 1541, loss 0.49348689
iteration 1542, loss 0.49343508
iteration 1543, loss 0.49353048
iteration 1544, loss 0.49342410
iteration 1545, loss 0.49330494
iteration 1546, loss 0.49308322
iteration 1547, loss 0.49307801
iteration 1548, loss 0.49292756
iteration 1549, loss 0.49313026
iteration 1550, loss 0.49286191
iteration 1551, loss 0.49275716
iteration 1552, loss 0.49271934
iteration 1553, loss 0.49266750
iteration 1554, loss 0.49264541
iteration 1555, loss 0.49261642
iteration 1556, loss 0.49259491
iteration 1557, loss 0.49238342
iteration 1558, loss 0.49237273
iteration 1559, loss 0.49239767
iteration 1560, loss 0.49217208
iteration 1561, loss 0.49195126
iteration 1562, loss 0.49185370
iteration 1563, loss 0.49186404
iteration 1564, loss 0.49196349
iteration 1565, loss 0.49187515
iteration 1566, loss 0.49185708
iteration 1567, loss 0.49173281
iteration 1568, loss 0.49164386
iteration 1569, loss 0.49147858
iteration 1570, loss 0.49132988
iteration 1571, loss 0.49129968
iteration 1572, loss 0.49128593
iteration 1573, loss 0.49107037
iteration 1574, loss 0.49105873
iteration 1575, loss 0.49101536
iteration 1576, loss 0.49102917
iteration 1577, loss 0.49100902
iteration 1578, loss 0.49082578
iteration 1579, loss 0.49093930
iteration 1580, loss 0.49068868
iteration 1581, loss 0.49053029
iteration 1582, loss 0.49035605
iteration 1583, loss 0.49041767
iteration 1584, loss 0.49031377
iteration 1585, loss 0.49030946
iteration 1586, loss 0.49034118
iteration 1587, loss 0.49023871
iteration 1588, loss 0.49011644
iteration 1589, loss 0.48998227
iteration 1590, loss 0.48985920
iteration 1591, loss 0.48982477
iteration 1592, loss 0.48994048
iteration 1593, loss 0.48970469
iteration 1594, loss 0.48952285
iteration 1595, loss 0.48950759
iteration 1596, loss 0.48956962
iteration 1597, loss 0.48953303
iteration 1598, loss 0.48931660
iteration 1599, loss 0.48917054
iteration 1600, loss 0.48916487
iteration 1601, loss 0.48903759
iteration 1602, loss 0.48908097
iteration 1603, loss 0.48898506
iteration 1604, loss 0.48905878
iteration 1605, loss 0.48873188
iteration 1606, loss 0.48854068
iteration 1607, loss 0.48875105
iteration 1608, loss 0.48860008
iteration 1609, loss 0.48854311
iteration 1610, loss 0.48831384
iteration 1611, loss 0.48836772
iteration 1612, loss 0.48840881
iteration 1613, loss 0.48825870
iteration 1614, loss 0.48806172
iteration 1615, loss 0.48806341
iteration 1616, loss 0.48806952
iteration 1617, loss 0.48785861
iteration 1618, loss 0.48781952
iteration 1619, loss 0.48775363
iteration 1620, loss 0.48770187
iteration 1621, loss 0.48778780
iteration 1622, loss 0.48761667
iteration 1623, loss 0.48756984
iteration 1624, loss 0.48769543
iteration 1625, loss 0.48758733
iteration 1626, loss 0.48735898
iteration 1627, loss 0.48707852
iteration 1628, loss 0.48703236
iteration 1629, loss 0.48706251
iteration 1630, loss 0.48702043
iteration 1631, loss 0.48712008
iteration 1632, loss 0.48686505
iteration 1633, loss 0.48681163
iteration 1634, loss 0.48666013
iteration 1635, loss 0.48653206
iteration 1636, loss 0.48664583
iteration 1637, loss 0.48642517
iteration 1638, loss 0.48648886
iteration 1639, loss 0.48635197
iteration 1640, loss 0.48633192
iteration 1641, loss 0.48636559
iteration 1642, loss 0.48604310
iteration 1643, loss 0.48627186
iteration 1644, loss 0.48607877
iteration 1645, loss 0.48618927
iteration 1646, loss 0.48591514
iteration 1647, loss 0.48589990
iteration 1648, loss 0.48571738
iteration 1649, loss 0.48572510
iteration 1650, loss 0.48549044
iteration 1651, loss 0.48539129
iteration 1652, loss 0.48542209
iteration 1653, loss 0.48546622
iteration 1654, loss 0.48535778
iteration 1655, loss 0.48532157
iteration 1656, loss 0.48535312
iteration 1657, loss 0.48511727
iteration 1658, loss 0.48520068
iteration 1659, loss 0.48501080
iteration 1660, loss 0.48490998
iteration 1661, loss 0.48476567
iteration 1662, loss 0.48470196
iteration 1663, loss 0.48475506
iteration 1664, loss 0.48453894
iteration 1665, loss 0.48456077
iteration 1666, loss 0.48455184
iteration 1667, loss 0.48437710
iteration 1668, loss 0.48433700
iteration 1669, loss 0.48428460
iteration 1670, loss 0.48434587
iteration 1671, loss 0.48433231
iteration 1672, loss 0.48425003
iteration 1673, loss 0.48400355
iteration 1674, loss 0.48396049
iteration 1675, loss 0.48392779
iteration 1676, loss 0.48386680
iteration 1677, loss 0.48379499
iteration 1678, loss 0.48365803
iteration 1679, loss 0.48356053
iteration 1680, loss 0.48351495
iteration 1681, loss 0.48354573
iteration 1682, loss 0.48330479
iteration 1683, loss 0.48335409
iteration 1684, loss 0.48332938
iteration 1685, loss 0.48333165
iteration 1686, loss 0.48311859
iteration 1687, loss 0.48283999
iteration 1688, loss 0.48285280
iteration 1689, loss 0.48299816
iteration 1690, loss 0.48292273
iteration 1691, loss 0.48281395
iteration 1692, loss 0.48274343
iteration 1693, loss 0.48269544
iteration 1694, loss 0.48241766
iteration 1695, loss 0.48262240
iteration 1696, loss 0.48236125
iteration 1697, loss 0.48240116
iteration 1698, loss 0.48225221
iteration 1699, loss 0.48229765
iteration 1700, loss 0.48200624
iteration 1701, loss 0.48212365
iteration 1702, loss 0.48222667
iteration 1703, loss 0.48212969
iteration 1704, loss 0.48201998
iteration 1705, loss 0.48194762
iteration 1706, loss 0.48183165
iteration 1707, loss 0.48186259
iteration 1708, loss 0.48169152
iteration 1709, loss 0.48170477
iteration 1710, loss 0.48164703
iteration 1711, loss 0.48149708
iteration 1712, loss 0.48159244
iteration 1713, loss 0.48141100
iteration 1714, loss 0.48114768
iteration 1715, loss 0.48113733
iteration 1716, loss 0.48108612
iteration 1717, loss 0.48120198
iteration 1718, loss 0.48098753
iteration 1719, loss 0.48095995
iteration 1720, loss 0.48106451
iteration 1721, loss 0.48090513
iteration 1722, loss 0.48074466
iteration 1723, loss 0.48085751
iteration 1724, loss 0.48067623
iteration 1725, loss 0.48058718
iteration 1726, loss 0.48047672
iteration 1727, loss 0.48035200
iteration 1728, loss 0.48045087
iteration 1729, loss 0.48026266
iteration 1730, loss 0.48026785
iteration 1731, loss 0.48002604
iteration 1732, loss 0.47998381
iteration 1733, loss 0.47976658
iteration 1734, loss 0.47969642
iteration 1735, loss 0.48013716
iteration 1736, loss 0.47987240
iteration 1737, loss 0.47962325
iteration 1738, loss 0.47954411
iteration 1739, loss 0.47966165
iteration 1740, loss 0.47946647
iteration 1741, loss 0.47958884
iteration 1742, loss 0.47942898
iteration 1743, loss 0.47929579
iteration 1744, loss 0.47937432
iteration 1745, loss 0.47934772
iteration 1746, loss 0.47928506
iteration 1747, loss 0.47896178
iteration 1748, loss 0.47895118
iteration 1749, loss 0.47880583
iteration 1750, loss 0.47879267
iteration 1751, loss 0.47894374
iteration 1752, loss 0.47874437
iteration 1753, loss 0.47858775
iteration 1754, loss 0.47853711
iteration 1755, loss 0.47845794
iteration 1756, loss 0.47832172
iteration 1757, loss 0.47844732
iteration 1758, loss 0.47853147
iteration 1759, loss 0.47831046
iteration 1760, loss 0.47842707
iteration 1761, loss 0.47846434
iteration 1762, loss 0.47830112
iteration 1763, loss 0.47837252
iteration 1764, loss 0.47821732
iteration 1765, loss 0.47795252
iteration 1766, loss 0.47774768
iteration 1767, loss 0.47766189
iteration 1768, loss 0.47754409
iteration 1769, loss 0.47785983
iteration 1770, loss 0.47774695
iteration 1771, loss 0.47766110
iteration 1772, loss 0.47745166
iteration 1773, loss 0.47732927
iteration 1774, loss 0.47734146
iteration 1775, loss 0.47718835
iteration 1776, loss 0.47732311
iteration 1777, loss 0.47713251
iteration 1778, loss 0.47702444
iteration 1779, loss 0.47709059
iteration 1780, loss 0.47683962
iteration 1781, loss 0.47678737
iteration 1782, loss 0.47681437
iteration 1783, loss 0.47684447
iteration 1784, loss 0.47671821
iteration 1785, loss 0.47669011
iteration 1786, loss 0.47639832
iteration 1787, loss 0.47643555
iteration 1788, loss 0.47650236
iteration 1789, loss 0.47633869
iteration 1790, loss 0.47633812
iteration 1791, loss 0.47610660
iteration 1792, loss 0.47632429
iteration 1793, loss 0.47619923
iteration 1794, loss 0.47615789
iteration 1795, loss 0.47588406
iteration 1796, loss 0.47571994
iteration 1797, loss 0.47571971
iteration 1798, loss 0.47572586
iteration 1799, loss 0.47562609
iteration 1800, loss 0.47581275
iteration 1801, loss 0.47580898
iteration 1802, loss 0.47560245
iteration 1803, loss 0.47554798
iteration 1804, loss 0.47542392
iteration 1805, loss 0.47525571
iteration 1806, loss 0.47513849
iteration 1807, loss 0.47501303
iteration 1808, loss 0.47528144
iteration 1809, loss 0.47497013
iteration 1810, loss 0.47489003
iteration 1811, loss 0.47483304
iteration 1812, loss 0.47489533
iteration 1813, loss 0.47483118
iteration 1814, loss 0.47487861
iteration 1815, loss 0.47487524
iteration 1816, loss 0.47472187
iteration 1817, loss 0.47464214
iteration 1818, loss 0.47460192
iteration 1819, loss 0.47451247
iteration 1820, loss 0.47433495
iteration 1821, loss 0.47449703
iteration 1822, loss 0.47424374
iteration 1823, loss 0.47417955
iteration 1824, loss 0.47424916
iteration 1825, loss 0.47402922
iteration 1826, loss 0.47441515
iteration 1827, loss 0.47403722
iteration 1828, loss 0.47388414
iteration 1829, loss 0.47392469
iteration 1830, loss 0.47378131
iteration 1831, loss 0.47378396
iteration 1832, loss 0.47362755
iteration 1833, loss 0.47344137
iteration 1834, loss 0.47341993
iteration 1835, loss 0.47329518
iteration 1836, loss 0.47317481
iteration 1837, loss 0.47317007
iteration 1838, loss 0.47341984
iteration 1839, loss 0.47333195
iteration 1840, loss 0.47313123
iteration 1841, loss 0.47293211
iteration 1842, loss 0.47278105
iteration 1843, loss 0.47278555
iteration 1844, loss 0.47294786
iteration 1845, loss 0.47304847
iteration 1846, loss 0.47287596
iteration 1847, loss 0.47280297
iteration 1848, loss 0.47273951
iteration 1849, loss 0.47266942
iteration 1850, loss 0.47263558
iteration 1851, loss 0.47258465
iteration 1852, loss 0.47260894
iteration 1853, loss 0.47234973
iteration 1854, loss 0.47224131
iteration 1855, loss 0.47217347
iteration 1856, loss 0.47225387
iteration 1857, loss 0.47213530
iteration 1858, loss 0.47203726
iteration 1859, loss 0.47184890
iteration 1860, loss 0.47175051
iteration 1861, loss 0.47170129
iteration 1862, loss 0.47162787
iteration 1863, loss 0.47177398
iteration 1864, loss 0.47145849
iteration 1865, loss 0.47151306
iteration 1866, loss 0.47144081
iteration 1867, loss 0.47143698
iteration 1868, loss 0.47140246
iteration 1869, loss 0.47129045
iteration 1870, loss 0.47106267
iteration 1871, loss 0.47097425
iteration 1872, loss 0.47104428
iteration 1873, loss 0.47114723
iteration 1874, loss 0.47105770
iteration 1875, loss 0.47072830
iteration 1876, loss 0.47059717
iteration 1877, loss 0.47082277
iteration 1878, loss 0.47085478
iteration 1879, loss 0.47058946
iteration 1880, loss 0.47054838
iteration 1881, loss 0.47057817
iteration 1882, loss 0.47043864
iteration 1883, loss 0.47037779
iteration 1884, loss 0.47045269
iteration 1885, loss 0.47016841
iteration 1886, loss 0.47024799
iteration 1887, loss 0.47018101
iteration 1888, loss 0.47000419
iteration 1889, loss 0.47002206
iteration 1890, loss 0.46989545
iteration 1891, loss 0.46992931
iteration 1892, loss 0.46970341
iteration 1893, loss 0.46991543
iteration 1894, loss 0.46955123
iteration 1895, loss 0.46958576
iteration 1896, loss 0.46955106
iteration 1897, loss 0.46963603
iteration 1898, loss 0.46947019
iteration 1899, loss 0.46948529
iteration 1900, loss 0.46933840
iteration 1901, loss 0.46913338
iteration 1902, loss 0.46915430
iteration 1903, loss 0.46925786
iteration 1904, loss 0.46913619
iteration 1905, loss 0.46887130
iteration 1906, loss 0.46901118
iteration 1907, loss 0.46887920
iteration 1908, loss 0.46863127
iteration 1909, loss 0.46876837
iteration 1910, loss 0.46855201
iteration 1911, loss 0.46861176
iteration 1912, loss 0.46848026
iteration 1913, loss 0.46836441
iteration 1914, loss 0.46830508
iteration 1915, loss 0.46817975
iteration 1916, loss 0.46833215
iteration 1917, loss 0.46832253
iteration 1918, loss 0.46812186
iteration 1919, loss 0.46811042
iteration 1920, loss 0.46811892
iteration 1921, loss 0.46806032
iteration 1922, loss 0.46790562
iteration 1923, loss 0.46796403
iteration 1924, loss 0.46788741
iteration 1925, loss 0.46777529
iteration 1926, loss 0.46758025
iteration 1927, loss 0.46744791
iteration 1928, loss 0.46733999
iteration 1929, loss 0.46728652
iteration 1930, loss 0.46722375
iteration 1931, loss 0.46724027
iteration 1932, loss 0.46718577
iteration 1933, loss 0.46718163
iteration 1934, loss 0.46689964
iteration 1935, loss 0.46693277
iteration 1936, loss 0.46681753
iteration 1937, loss 0.46726346
iteration 1938, loss 0.46694360
iteration 1939, loss 0.46678426
iteration 1940, loss 0.46675465
iteration 1941, loss 0.46656869
iteration 1942, loss 0.46647204
iteration 1943, loss 0.46650784
iteration 1944, loss 0.46634093
iteration 1945, loss 0.46634784
iteration 1946, loss 0.46636796
iteration 1947, loss 0.46638039
iteration 1948, loss 0.46628461
iteration 1949, loss 0.46627912
iteration 1950, loss 0.46623571
iteration 1951, loss 0.46618741
iteration 1952, loss 0.46592745
iteration 1953, loss 0.46583872
iteration 1954, loss 0.46571032
iteration 1955, loss 0.46590646
iteration 1956, loss 0.46562649
iteration 1957, loss 0.46563326
iteration 1958, loss 0.46566046
iteration 1959, loss 0.46567749
iteration 1960, loss 0.46549368
iteration 1961, loss 0.46545846
iteration 1962, loss 0.46536243
iteration 1963, loss 0.46539547
iteration 1964, loss 0.46510285
iteration 1965, loss 0.46508115
iteration 1966, loss 0.46507365
iteration 1967, loss 0.46500436
iteration 1968, loss 0.46504724
iteration 1969, loss 0.46498425
iteration 1970, loss 0.46488389
iteration 1971, loss 0.46484955
iteration 1972, loss 0.46471397
iteration 1973, loss 0.46480852
iteration 1974, loss 0.46471549
iteration 1975, loss 0.46433057
iteration 1976, loss 0.46423209
iteration 1977, loss 0.46415533
iteration 1978, loss 0.46424027
iteration 1979, loss 0.46429066
iteration 1980, loss 0.46403307
iteration 1981, loss 0.46404120
iteration 1982, loss 0.46410569
iteration 1983, loss 0.46391499
iteration 1984, loss 0.46381184
iteration 1985, loss 0.46366344
iteration 1986, loss 0.46388658
iteration 1987, loss 0.46366833
iteration 1988, loss 0.46353790
iteration 1989, loss 0.46351144
iteration 1990, loss 0.46341004
iteration 1991, loss 0.46333347
iteration 1992, loss 0.46314279
iteration 1993, loss 0.46315665
iteration 1994, loss 0.46296007
iteration 1995, loss 0.46299339
iteration 1996, loss 0.46321594
iteration 1997, loss 0.46313616
iteration 1998, loss 0.46316331
iteration 1999, loss 0.46301325
iteration 2000, loss 0.46296198
iteration 3000, loss 0.40595511
iteration 4000, loss 0.37720099
iteration 5000, loss 0.35989632
iteration 6000, loss 0.34853128
iteration 7000, loss 0.34121835
iteration 8000, loss 0.33629703
iteration 9000, loss 0.33280913
iteration 10000, loss 0.33021651
iteration 11000, loss 0.32820617
iteration 12000, loss 0.32662617
iteration 13000, loss 0.32533808
iteration 14000, loss 0.32428033
iteration 15000, loss 0.32339671
iteration 16000, loss 0.32264469
iteration 17000, loss 0.32199656
iteration 18000, loss 0.32143103
iteration 19000, loss 0.32093665
iteration 20000, loss 0.32049617
iteration 21000, loss 0.32010601
iteration 22000, loss 0.31975574
iteration 23000, loss 0.31943862
iteration 24000, loss 0.31914942
iteration 25000, loss 0.31888699
iteration 26000, loss 0.31864613
iteration 27000, loss 0.31842570
iteration 28000, loss 0.31822214
iteration 29000, loss 0.31803432
iteration 30000, loss 0.31785935
iteration 31000, loss 0.31769618
iteration 32000, loss 0.31754415
iteration 33000, loss 0.31740241
iteration 34000, loss 0.31727012
iteration 35000, loss 0.31714489
iteration 36000, loss 0.31702770
iteration 37000, loss 0.31691746
iteration 38000, loss 0.31681305
iteration 39000, loss 0.31671419
iteration 40000, loss 0.31662073
iteration 41000, loss 0.31653197
iteration 42000, loss 0.31644819
iteration 43000, loss 0.31636805
iteration 44000, loss 0.31629186
iteration 45000, loss 0.31621931
iteration 46000, loss 0.31615043
iteration 47000, loss 0.31608417
iteration 48000, loss 0.31602063
iteration 49000, loss 0.31596046
iteration 50000, loss 0.31590267
iteration 51000, loss 0.31584689
iteration 52000, loss 0.31579370
iteration 53000, loss 0.31574251
iteration 54000, loss 0.31569319
iteration 55000, loss 0.31564611
iteration 56000, loss 0.31560067
iteration 57000, loss 0.31555664
iteration 58000, loss 0.31551452
iteration 59000, loss 0.31547373
iteration 60000, loss 0.31543455
iteration 61000, loss 0.31539648
iteration 62000, loss 0.31535981
iteration 63000, loss 0.31532441
iteration 64000, loss 0.31529024
iteration 65000, loss 0.31525694
iteration 66000, loss 0.31522487
iteration 67000, loss 0.31519374
iteration 68000, loss 0.31516352
iteration 69000, loss 0.31513426
iteration 70000, loss 0.31510584
iteration 71000, loss 0.31507832
iteration 72000, loss 0.31505163
iteration 73000, loss 0.31502565
iteration 74000, loss 0.31500044
iteration 75000, loss 0.31497590
iteration 76000, loss 0.31495204
iteration 77000, loss 0.31492875
iteration 78000, loss 0.31490613
iteration 79000, loss 0.31488411
iteration 80000, loss 0.31486266
iteration 81000, loss 0.31484179
iteration 82000, loss 0.31482149
iteration 83000, loss 0.31480165
iteration 84000, loss 0.31478229
iteration 85000, loss 0.31476350
iteration 86000, loss 0.31474495
iteration 87000, loss 0.31472708
iteration 88000, loss 0.31470949
iteration 89000, loss 0.31469239
iteration 90000, loss 0.31467563
iteration 91000, loss 0.31465935
iteration 92000, loss 0.31464334
iteration 93000, loss 0.31462769
iteration 94000, loss 0.31461248
iteration 95000, loss 0.31459754
iteration 96000, loss 0.31458279
iteration 97000, loss 0.31456852
iteration 98000, loss 0.31455452
iteration 99000, loss 0.31454081
